<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Importance of Random Slopes in Mixed Models for Bayesian Hypothesis Testing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Klaus</forename><surname>Oberauer</surname></persName>
							<email>k.oberauer@psychologie.uzh.ch</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">Department of Psychology</orgName>
								<orgName type="institution" key="instit1">University of Zurich</orgName>
								<orgName type="institution" key="instit2">University of Zurich</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The Importance of Random Slopes in Mixed Models for Bayesian Hypothesis Testing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E1648CA3D8DF0649F5C4989C397285DB</idno>
					<idno type="DOI">10.1177/09567976211046884</idno>
					<note type="submission">Received 1/31/21; Revision accepted 8/20/21</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-05-20T20:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>mixed models</term>
					<term>multilevel models</term>
					<term>Bayesian models</term>
					<term>Bayes factor</term>
					<term>random effects</term>
					<term>random slopes</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Mixed models are gaining popularity in psychology. For frequentist mixed models, previous research showed that excluding random slopes-differences between individuals in the direction and size of an effect-from a model when they are in the data can lead to a substantial increase in false-positive conclusions in null-hypothesis tests. Here, I demonstrated through five simulations that the same is true for Bayesian hypothesis testing with mixed models, which often yield Bayes factors reflecting very strong evidence for a mean effect on the population level even if there was no such effect. Including random slopes in the model largely eliminates the risk of strong false positives but reduces the chance of obtaining strong evidence for true effects. I recommend starting analysis by testing the support for random slopes in the data and removing them from the models only if there is clear evidence against them.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Mixed models (also known as mixed-effects models, multilevel models, or hierarchical models) are becoming popular in psychology and the social sciences. Mixed models are statistical models describing data on two or more levels of analysis. The most common case in experimental psychology is probably the analysis of within-subjects (or repeated measures) designs with the individual person at the lower level of analysis and the population at the higher level. Mixed models are characterized by a combination of fixed effects and random effects. Fixed effects are effects on the higher level that are assumed to be constant (fixed) for every unit on the lower level. For instance, the main effect of an experimental manipulation is conceptualized as a fixed effect that holds for the entire population. Random effects are effects describing differences between the units on the lower level. When those units are persons, random effects describe individual differences. Random effects can be broken down into three kinds. Random intercepts are individual differences in the mean across all conditions (i.e., in the model intercept). Random slopes are individual differences in the effect of a predictor: The size and direction of an experimental effect could differ across individuals. Finally, correlations between random effects are model parameters describing dependencies between random intercepts and slopes.</p><p>For classical frequentist statistics, <ref type="bibr" target="#b0">Barr et al. (2013)</ref> demonstrated through analysis and simulations that neglecting random effects can lead to a serious inflation of Type I errors, or false positives (i.e., obtaining a significant result for an effect that is zero). In particular, if there are true individual differences in the effects of predictors in the data, but the model does not specify them as random slopes, false-alarm rates increase substantially above the nominal alpha level. Conversely, including random effects that are not warranted by the data does not jeopardize the validity of statistical inferences. <ref type="bibr" target="#b0">Barr et al. (2013)</ref> therefore recommended keeping mixed models "maximal" by default, that is, to include all random effects and their correlations. <ref type="bibr" target="#b8">Matuschek et al. (2017)</ref> took a more nuanced stance, arguing that maximal models can incur a loss of statistical power.</p><p>They recommended using model selection to test which random effects are warranted by the data and to keep those random effects that are supported.</p><p>Here, I am concerned with the role of random slopes in Bayesian hypothesis testing based on comparisons of mixed models. Specifically, I am interested in the kind of hypothesis test most prevalent in psychology and other social sciences: Testing the hypothesis that a fixed effect exists against the null hypothesis that it does not exist. Whereas in frequentist statistics, modelcomparison techniques on mixed models (e.g., likelihoodratio tests, model comparisons through Akaike information criterion or Bayesian information criterion) are one class of inference methods among others suitable for this purpose (e.g., F tests in analysis of variance <ref type="bibr">[ANOVA]</ref>), for Bayesian null-hypothesis testing, there is currently no alternative to model comparison with mixed models. 1 In particular, the Bayesian ANOVA developed by <ref type="bibr" target="#b11">Rouder et al. (2012)</ref> builds on a set of pairwise comparisons of mixed models, as does the "anovaBF" function in the BayesFactor package <ref type="bibr" target="#b9">(Morey &amp; Rouder, 2015)</ref> for R and the "ANOVA" function in the Bayesian statistical software JASP <ref type="bibr">( JASP Team, 2020</ref>). Yet the role of random effects has not been investigated for Bayesian hypothesis tests, and many researchers doing Bayesian model comparisons specify random intercepts but omit random slopes and correlations.</p><p>The present study was motivated by my worry that omitting random slopes and correlations in Bayesian mixed models could have similarly distorting effects on statistical inference about the existence of fixed effects as doing so in frequentist models <ref type="bibr" target="#b0">(Barr et al., 2013)</ref>. I will present five simulation studies for simple withinsubjects designs in which I varied the presence and size of a main effect of interest and the presence and size of random slopes. I tested the main effect of interest through model comparison with the Bayes factor (BF; <ref type="bibr" target="#b1">Berger, 2006)</ref>. I did this once using models omitting random slopes and then again with models that included random slopes (and, in Simulation 3, correlations between random slopes). All simulation code is available on OSF (<ref type="url" target="https://osf.io/h4gcy/">https://osf.io/h4gcy/</ref>).</p><p>The question I asked is, Which model comparison is best suited to maximize our chance of drawing correct inferences about the existence of a fixed effect in question while minimizing the risk of obtaining misleading evidence? In particular, I was interested in two questions. First, does the omission of random slopes lead to an increase in false positives when the effect of interest is actually zero? Second, does the inclusion of random slopes reduce the chance of obtaining compelling evidence for the effect of interest if that effect is truly different from zero? To preview the results-unfortunately, the answer to both questions is yes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation 1: ANOVA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>The first simulation used a 2 × 2 within-subjects ANOVA design with 20 subjects and 30 trials per subject and design cell. I simulated data from the following mixedeffects model:</p><formula xml:id="formula_0">y i,j,k,r ~ N(m i,j,k , sd), m i,j,k = µ i + b i,1 C 1 + b i,2 C 2 , µ i ~ N(0, σ), b i,1 ~ N(B 1 , σ), b i,2 ~ N(B 2 , σ).</formula><p>Here, y i,j,k,r is the observation of trial r in the design cell <ref type="bibr">[ j,k]</ref> of subject i ( j and k are indices for the condition of Independent Variables 1 and 2, respectively). Each observation is sampled from a normal distribution with mean m i,j,k and standard deviation (sd) of 1. The subject's mean in design cell <ref type="bibr">[ j,k]</ref> is a linear combination of the subject's intercept, or mean over all conditions, μ i , and the subject's effects of the two independent variables. The independent variables are contrast coded <ref type="bibr">[-0.5, +0.5]</ref>, where C 1 and C 2 represent the contrast value of Independent Variables 1 and 2, respectively. The effect sizes of subject i for the two main effects are b i,1 and b i,2 , respectively. 2 Each subject's intercept is</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statement of Relevance</head><p>Psychological scientists increasingly use Bayesian inference methods to supplement or replace frequentist null-hypothesis testing. Bayesian tests of an alternative hypothesis against a null hypothesis are usually carried out through comparison of mixed-effects models using Bayes factors. Whenever the study design includes at least one withinsubjects (or repeated measures) variation, the question arises whether mixed-effects models should include random slopes, that is, random variability between subjects in the size of the effect. Some popular routines for computing Bayes factors omit random slopes by design. The present simulations show that omitting random slopes when the data warrant them often leads to strongly misleading results: Large, and sometimes extremely large, Bayes factors can be obtained in favor of an effect that is not there. Avoiding such misleading results is critical for minimizing false-positive reports.</p><p>drawn from a normal distribution with mean of zero and standard deviation σ. The effects of the two predictor variables are drawn from normal distributions with means B 1 and B 2 and the same standard deviation σ. In mixed-model terms, the fixed effects are B 1 and B 2 . They describe the population means of the effects of the predictors and are therefore called population-level effects in Bayesian statistics. The random effects are μ i , b i,1 , and b i,2 . They describe the deviation of each subject i from the population mean and are therefore called subject-level effects in the Bayesian terminology.</p><p>The simulation varied the effect size of the predictor of interest (Independent Variable 1) over four levels: B 1 = 0, 0.25, 0.5, or 0.75. The second predictor had a constant effect size of 0.5. I also varied the size of the random effects over four levels of σ: .1, .25, .5, or 1. For each combination of B 1 and σ, I ran 50 replications of the simulation.</p><p>The simulated data were analyzed on two levels of aggregation: unaggregated (i.e., the model predicted each individual trial), and aggregated on the level of the design cell (i.e., the model predicted each person's mean in each design cell). For each level of aggregation, I applied four versions of an additive linear mixed model: The "RS" version included a random intercept and random slopes for both predictors as free parameters; the "no RS" version included only a random intercept. The "RS 1" version included a random slope only for Independent Variable 1 (i.e., the effect of interest), and the "RS 2 version" included a random slope only for Independent Variable 2. The models were run with the "lmBF" function of the BayesFactor package (Version 0.9.12.2; <ref type="bibr" target="#b9">Morey &amp; Rouder, 2015)</ref> for R (Version 3.6.2; R Core Team, 2020). I used the default prior settings of "lmBF" (i.e., Cauchy priors with scale = 0.5 for fixed effects and scale = 1 for random effects) and ran 100,000 Markov chain Monte Carlo (MCMC) iterations.</p><p>I gauged the evidence for the effect of interest by comparing the model including both predictors (Model 1) with a constrained model (Model 0) in which the predictor of interest (Independent Variable 1) was removed as a fixed effect. In the RS and RS 1 versions of the model, the constrained model still included the random effect of Predictor 1 because that model represents the null hypothesis that the population-level effect is zero, which does not necessarily mean that the effect is zero for each person.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>I first focus on results from the conditions in which the true effect of interest was zero. Figure <ref type="figure" target="#fig_0">1</ref> shows the BFs for the four model versions, for unaggregated data (left) and aggregated data (right), as a function of the true size of the random effects. Most BFs show evidence against the effect-these are the points below the red line in Figure <ref type="figure" target="#fig_0">1</ref>. However, for the models that did not include a random slope for the effect of interest (i.e., no RS and RS 2), a substantial number of BFs reflected strong evidence in favor of the effect. The incidence and size of these BFs became larger as the true standard deviation of random effects increased. With unaggregated data, some of them were so large that I could fit them into the figure only by using a log 10 scale. With aggregated data, BFs were much less extreme, reflecting less evidence both for and against the effect.</p><p>BFs estimate the strength of evidence for one model over another on a continuous scale, and there is no justifiable threshold for when to reach a conclusion in favor of one model or the other. Nevertheless, researchers often rely on rules of thumb for interpreting BFs in terms of categories of evidence strength. For instance, <ref type="bibr" target="#b7">Kass and Raftery (1995)</ref>, following <ref type="bibr" target="#b6">Jeffreys (1961)</ref>, proposed to interpret BFs between 3 and 10 as "substantial" evidence, and BFs between 10 and 100 as "strong" evidence. We can therefore ask what proportion of incorrect decisions researchers would be expected to make if they followed these recommendations for their conclusions.</p><p>The proportion of false positives-BFs reflecting evidence for a nonexistent effect-is given in Table <ref type="table" target="#tab_0">1</ref>, separately for mild false positives (BF &gt; 3) and severe false positives (BF &gt; 10). The proportions reflect the pattern in Figure <ref type="figure" target="#fig_0">1</ref>: With unaggregated data, false positives were frequently observed when random slopes were omitted from the model and hardly ever when they were included. Aggregating the data flattened that effect, yielding intermediate rates of false positives, reduced only mildly by the inclusion of random slopes. The last row of the table shows the proportion of false positives when I followed the recommendation of <ref type="bibr" target="#b8">Matuschek et al. (2017)</ref>: For each simulation, I evaluated which random-effects structure (i.e., model versions RS 1, RS 2, RS, or no RS) was best supported by the data and kept the BF for the effect of interest from the best-supported model version. This approach was more successful in avoiding false positives than always omitting random slopes, although it was not as good as always including them.</p><p>Figure <ref type="figure">2</ref> presents a more fine-grained analysis of the BFs when the true effect was zero. Because of sampling noise, the sample effect deviated from the true effect, and the more it did, the more the BF was pushed in the direction of evidence for the effect. This bias was much stronger when random slopes were not included in the model. This effect can be understood as follows. When the size of the effect differs between subjects, then sampling noise is driven in part by these individual differences: For instance, when the sample happens to predominantly include subjects with positive effects, the sample effect will be positive. A model including random slopes represents this sampling noise adequately, whereas a model without a random slope tends to misattribute it to the fixed effect of the predictor and, therefore, yields false evidence for that effect.</p><p>The reason why aggregation substantially mitigates the bias is this: In the unaggregated data, the deviation of a subject's effect from the mean effect in the population is reflected by n data points per design cell. This sets the systematic deviation of that subject from the mean clearly apart from random measurement error (i.e., trial-by-trial variation). In contrast, in the aggregated data, the variability of the effect between subjects is represented by only one data point per cell for each subject and, thus, is barely distinguishable from withinsubjects measurement error. 3 The within-subjects measurement error is accommodated in the model by the standard deviation of the normal distribution of individual observations. It provides sufficient variability to accommodate the between-subjects variability of effects in the aggregated data. In the unaggregated data, the standard deviation is bound to reflect only the trial-bytrial variability within each subject, missing the betweensubjects variation.</p><p>True Effect = 0, Unaggregated Data  Note: For each model, results are shown separately for unaggregated data and aggregated data. Within each type of data, probabilities are further broken down for mild false positives (BF &gt; 3) and severe false positives (BF &gt; 10). The "no RS" model version included no random slopes, the "RS 1" version included random slopes for the effect of interest, the "RS 2" version included random slopes for the other effect, and the "RS" version included random slopes for both effects.</p><p>For the "RS (evidence)" version, the inclusion of random effects was conditional on evidence supporting them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Oberauer</head><p>Turning now to the simulations in which there was a true effect, I show in Figure <ref type="figure">3</ref> the BFs for each model version as a function of the size of the true effect. Unsurprisingly, the BFs increased with the true effect size. For unaggregated data, the BFs were much larger in model versions excluding the random slope of the effect of interest-in fact, for the largest effect size, most of them were so large that they exceeded the figure boundary. With aggregated data, all the BFs were in a more modest range.</p><p>Table <ref type="table" target="#tab_1">2</ref> shows the proportion of simulations returning a miss (i.e., a BF &lt; 3, which is ambiguous evidence) or a false negative (i.e., a BF &lt; 0.33, which is evidence for the null hypothesis), on the assumption that researchers interpret evidence that is at least "substantial" <ref type="bibr" target="#b7">(Kass &amp; Raftery, 1995)</ref> to reach a conclusion in favor of a hypothesis. In the unaggregated data, misses and false negatives occurred more often when random slopes for the effect of interest were included (RS 1 and RS models). However, when the inclusion of random effects was conditional on evidence supporting them-"RS (evidence)" model-their prevalence was cut in half. In the aggregated data, the inclusion or omission of random slopes made less of a difference: Compared with the unaggregated data, there were more misses without random slopes in the models and fewer with them; false negatives were rare.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Simulation 1 showed that the pernicious effect of random slopes in misspecified models that <ref type="bibr" target="#b0">Barr et al. (2013)</ref> pointed out for frequentist mixed models also applies to Bayesian mixed models. When there are true individual differences in the effects of interest, and these individual differences are not represented in the models as random slopes, there is a high risk of false positives, including BFs of a size that is considered to be decisive evidence. This risk can be mitigated in two ways. The first and most effective solution is to include the random slopes in the data, at least when there is evidence for them. The second, less effective solution is to aggregate the data within design cells. Both solutions come with a price: They increase the chance of missing a true effect and of even obtaining evidence against such an effect (i.e., a false negative), although that evidence was hardly ever strong (i.e., BFs &lt; 0.1 were very rare). The best compromise appears to be to use unaggregated data and to include random slopes in the models only if a separate model comparison provides evidence for them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation 2: ANOVA With Many Design Cells</head><p>Simulation 1 showed that the problem of false positives when ignoring random slopes is mitigated substantially with aggregated data. The reason for that mitigation was that, with the aggregated data, each subject was represented with only two data points at each level of the predictor of interest-one mean for each level of the other predictor. Therefore, the aggregated data did not contain much evidence for distinguishing the random slopes from measurement noise.  Note: For each model, results are shown separately for unaggregated data and aggregated data. Within each type of data, probabilities are further broken down for simulations returning a miss (i.e., a BF &lt; 3, which is weak evidence for the effect, or a BF &lt; 1, reflecting weak evidence against the effect) or a false negative (i.e., a BF &lt; 0.33, which is evidence for the null hypothesis). The "no RS" model version included no random slopes, the "RS 1" version included random slopes for the effect of interest, the "RS 2" version included random slopes for the other effect, and the "RS" version included random slopes for both effects. For the "RS (evidence)" version, the inclusion of random effects was conditional on evidence supporting them.</p><p>Simulation 1 but varied the number of levels of Independent Variable 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Simulation 2 was like Simulation 1, with one important modification: I varied the number of levels of Independent Variable 2 over four levels: two, four, six, and 10. The variable of interest, Independent Variable 1, still had two levels. To simplify the simulations, I used only one level of true random slopes, σ = .5, and only one level of a true effect, effect size = 0.5. Each simulation was run with 20 subjects and with 30 trials per design cell.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Figure <ref type="figure" target="#fig_3">4</ref> shows the BFs for the simulations in which the true effect was zero. As in Simulation 1, there was a sizable number of BFs in favor of an effect when random slopes of the variable of interest (Predictor 1) were omitted. As expected, the prevalence and size of these BFs increased as the number of levels of Independent Variable 2 increased. This led to a nonnegligible number of false positives also in the aggregated data, as shown in Table <ref type="table" target="#tab_2">3</ref>.</p><p>Figure <ref type="figure" target="#fig_4">5</ref> shows the BFs for the simulation runs in which the true effect was 0.5. In the unaggregated data, the models omitting the random slopes of Predictor 1 produced BFs so huge that they were off the figure's scale.</p><p>The proportion of misses and false negatives is given in Table <ref type="table" target="#tab_3">4</ref>. This proportion was lower than in Simulation 1 for two reasons: Simulation 2 did not include the small effect size of 0.25, and it included simulations of designs with more cells; more cells led to more trials to inform the effect of interest because I held the number of trials per cell constant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The take-home message from Simulation 2 is that, even with aggregated data, the risk of false positives when true random slopes are omitted from the model becomes </p><formula xml:id="formula_1">n(Levels) IV 2 No RS RS 1 RS 2 R S No RS RS 1 RS 2 R S</formula><p>True Effect = 0, Unaggregated Data True Effect = 0, Aggregated Data uncomfortably high when the experimental design becomes more complex (i.e., each level of the predictor of interest is represented by a larger number of design cells).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation 3: Multilevel Regression</head><p>With this simulation, I aimed to answer two questions.</p><p>First, what is the effect of omitting random slopes of continuous predictors in regression models from a model when such effects are actually in the data? Second, what is the effect of omitting correlations between random slopes when such correlations are in the data?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>I simulated a within-subjects design with two predictor variables that varied over five levels on a continuous dimension, such as five list lengths combined with five retention intervals in a memory experiment. This means that the scale was at least ordinal, and the five levels were ordered from the smallest to the largest. The two predictors were not fully crossed but, rather, varied randomly and independently across the 150 trials simulated for each subject, with the constraint that for each  predictor, each value was realized equally often (i.e., 30 times). For both the data-generating model and the model fitted to the data, I used z-standardized variables with five equidistant values as predictors, so that the effect size was standardized. The effect size of the first predictor-the predictor of interest in the model comparisons-was either 0 or 0.25. The effect size for the second predictor was always 0.25. Two variables were varied across simulations: the standard deviation of the random slopes of both predictors (σ = .1, .25, .5, or 1) and the correlation between the two predictors across subjects (r = 0, .2, .5, or .7). For each combination of these variables, I ran 40 replications of the simulation with 20 subjects each. 4  For each simulation, I tested the effect of the first predictor by comparing a model including both predictors as fixed effects with one in which the first predictor's fixed effect was removed. This was done for three model versions: The "no RS" version included no random slopes, the "RS" version included uncorrelated random slopes for the two predictors, and the "RS + Corr" version included the two random slopes and their correlation as free parameters. The models were applied only to unaggregated data because this is the situation in which Simulation 1 revealed the larger effect of random slopes. Because the BayesFactor package does not support random slopes for continuous (numerical) predictors, I used the brms package (Version 2.15.0; <ref type="bibr" target="#b3">Bürkner, 2017)</ref> for running the models and the bridgesampling package (Version 1.1-2; <ref type="bibr" target="#b4">Gronau et al., 2020)</ref> for estimating the BFs. The models were run with three chains of 10,000 iterations each (including 1,000 warm-up iterations). The priors for the standardized effect sizes were default Cauchy priors with scale 0.5 <ref type="bibr" target="#b11">(Rouder et al., 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Figure <ref type="figure" target="#fig_5">6</ref> shows the BFs for the simulations in which the true effect of interest was zero. As in Simulation 1, when random slopes were omitted from the models, there was a nonnegligible proportion of simulations that produced huge BFs in favor of the effect. The proportion of false positives is given in Table <ref type="table" target="#tab_4">5</ref>. The prevalence and size of BFs in favor of an effect increased as σ, the standard deviation of the true random slopes, increased. 5 When random slopes were included in the models, these false positives were strongly mitigated. This was the case regardless of whether a correlation between the random slopes was included.</p><p>Figure <ref type="figure" target="#fig_6">7</ref> shows the same BFs as a function of the true size of the correlation: This variable had no discernible effect on the false-positive rate or size. Table <ref type="table" target="#tab_4">5</ref> summarizes the proportion of false positives for the three model versions, and Table <ref type="table" target="#tab_5">6</ref> shows the proportion of misses and of false negatives. They show again that including random slopes in the models reduces the false-positive rate but at the cost of increasing misses of true effects and even increasing false negatives (although the latter still remained at a low level). Whether or not the correlation was included did not matter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Simulation 3 confirmed what was already shown in the previous two simulations: In mixed regression models, just as in ANOVA models, omitting random slopes from models when they are in the data increases the risk of false positives with potentially enormous BFs in favor Within each type of data, probabilities are further broken down for simulations returning a miss (i.e., a BF &lt; 3, which is weak evidence for the effect, or a BF &lt; 1, reflecting weak evidence against the effect) or a false negative (i.e., a BF &lt; 0.33, which is evidence for the null hypothesis). The "no RS" model version included no random slopes, the "RS 1" version included random slopes for the effect of interest, the "RS 2" version included random slopes for the other effect, and the "RS" version included random slopes for both effects. For the "RS (evidence)" version, the inclusion of random effects was conditional on evidence supporting them.</p><p>of a nonexistent effect. The new result of Simulation 3 is that omitting the correlations between random slopes when they are in the data is innocuous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation 4: Effects of Sample Size and Number of Trials</head><p>For this simulation, I returned to an ANOVA design and addressed a question that probably every experimenter who has read this far has wondered about: How does the number of subjects, and the number of trials per subject, affect the results from the previous simulations?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Simulation 4 repeated the basic 2 × 2 ANOVA design of Simulation 1, with the following changes. I orthogonally varied the sample size (N = 20, 30, 40, or 50) and the number of trials per design cell (n = 20, 30, 40, 60, or 90). The true size of random slopes was held constant, σ = .5. For true effects, I simulated only an effect size of 0.25 because a relatively small effect size should be most informative about how N and n affect the risk of misses or false negatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The distribution of BFs for simulations in which the true effect was zero is shown in Figure <ref type="figure" target="#fig_8">8</ref> as a function of sample size and in Figure <ref type="figure" target="#fig_10">9</ref> as a function of the number of trials. Table <ref type="table" target="#tab_6">7</ref> gives the proportions of false positives. It is clear that neither increasing the sample size nor increasing the number of trials has a mitigating effect on the prevalence or the size of false positives. If anything, more data makes the problem worse, although the effect is modest at best. Figures 10 and 11 present the BFs for simulations with a true effect, and Table <ref type="table" target="#tab_7">8</ref> summarizes the proportion of misses and of false negatives from these simulations. As in Simulations 1 to 3, including random slopes of the effect of interest increased the probability of missing the true effect and of even obtaining  (modest) evidence against it. In analogy to the effect of sample size on statistical power in frequentist significance testing, we should expect sample size, and probably also the number of trials, to reduce that risk. This is indeed the case, as shown in Table <ref type="table" target="#tab_8">9</ref>, which breaks down the proportion of misses by sample size and number of trials. The proportion of missesdefined here as BF &lt; 1-in models that include random slopes is clearly reduced with increasing sample size. The number of trials appears to matter less. However, when one looks at the scenario in which the random-effects structure of the model is determined empirically, including only those random slopes that are supported by the data (lower half of Table <ref type="table" target="#tab_8">9</ref>), increasing the number of trials noticeably reduces the proportion of misses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>More data can fix many statistical problems but not the one identified here: When there are true individual differences in the effect of interest, but random slopes of that effect are omitted from the model, there is a substantial risk of BFs reflecting strong but wrong evidence for the effect. Neither increasing the sample size nor increasing the number of trials reduces that risk. That said, increasing the sample size reduces the risk of missing a true effect. Increasing the number of trials can achieve that as well, although this benefit appears to be best leveraged when the random-effects structure of the model is determined empirically rather than always including all random slopes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation 5: BF Calibration</head><p>The final simulation addressed the question of whether the BFs estimated for a two-factorial ANOVA design are well calibrated, as opposed to biased, for three modelcomparison approaches: always omitting random slopes, always including random slopes, and a parsimonious approach, including random slopes only if there is  Note: For each model, probabilities are shown separately for simulations returning a miss (i.e., a BF &lt; 3, which is weak evidence for the effect, or a BF &lt; 1, reflecting weak evidence against the effect) or a false negative (i.e., a BF &lt; 0.33, which is evidence for the null hypothesis). The "no RS" model version included no random slopes, the "RS" version included random slopes for both effects, and the "RS + Corr" version included random slopes for both effects and the correlation between them.</p><p>evidence for them. This simulation was inspired by the recent work of <ref type="bibr" target="#b12">Schad et al. (2022)</ref> and followed their procedure.</p><p>In each simulation run, I sampled one of two modelsthe null model and the alternative model-according to the prior probability of each model. I sampled parameter values from the parameter priors of the chosen model, simulated data from it, and then estimated the BF for the effect of interest according to each of the three model-comparison approaches. From the BF, I computed the posterior probability of each model. If the BF is well calibrated, the posterior probabilities, averaged over all simulation runs, should closely approximate the models' prior probabilities. In a simulation for a one-factorial design, <ref type="bibr" target="#b12">Schad et al. (2022)</ref> found that the BF was well calibrated for models that included random slopes but was biased in favor of the alternative model if they did not, mirroring the present results. I expected to find the same result here. The question of most interest was whether the parsimonious model-comparison approach, including random slopes only if there is evidence for them in the data, would yield a well-calibrated BF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>I used a 2 × 2 within-subjects ANOVA design as in Simulation 1, with 20 subjects and 30 trials per design cell. In each of 1,000 simulation runs, the null model or the alternative model was chosen with its prior probability, which I set to .5 for both models. Different from Simulation 1, the model parameters were not varied factorially but sampled from the parameter priors of the model. The parameter priors were those implemented in the BayesFactor package and described by <ref type="bibr" target="#b11">Rouder et al. (2012)</ref>, with one exception described below. When the alternative model was chosen, the fixed effects of both independent variables were drawn from the default prior on standardized effect sizes (i.e., Cauchy priors with scale = 0.5). When the null model was chosen, the fixed effect of the independent variable of interest was set to 0. </p><formula xml:id="formula_2">N No RS RS 1 RS 2 R S N o RS RS 1 RS 2 R S</formula><p>True Effect = 0, Unaggregated Data True Effect = 0, Aggregated Data I simulated data from the chosen model with the sampled parameter values and then estimated the BF for the effect of interest with the BayesFactor package in three ways: always omitting random slopes (no RS), always including random slopes (RS), and using the most parsimonious model justified by the data (RS evidence). For the latter, I first tested for the random slopes by comparing the full model with a model excluding the random slopes of both independent variables. If the BF for random slopes exceeded 1, the subsequent test for the fixed effect of interest included those random slopes in the models; otherwise, it omitted the random slopes. The analyses were always conducted on unaggregated data.</p><p>Sampling the standard deviation of the random slopes from the prior proposed by <ref type="bibr" target="#b11">Rouder et al. (2012)</ref> generated unrealistically large values, so that the BFs in favor of keeping the random slopes in the model were always huge. As a consequence, the parsimonious modelcomparison approach could not be evaluated because random slopes would never be omitted. Therefore, I sampled the standard deviations of random slopes from a gamma prior with a shape of 2 and rate of 10 (implying a mean of 0.2), which yielded random slopes that were detected about half of the time. From the BF estimated with each of the three model-comparison approaches, </p><formula xml:id="formula_3">No RS RS 1 RS 2 R S N o RS RS 1 RS 2 R S</formula><p>True Effect = 0, Unaggregated Data True Effect = 0, Aggregated Data  .17 .14 .04 .01</p><p>Note: For each model, results are shown separately for unaggregated data and aggregated data. Within each type of data, probabilities are further broken down for mild false positives (BF &gt; 3) and severe false positives (BF &gt; 10). The "no RS" model version included no random slopes, the "RS 1" version included random slopes for the effect of interest, the "RS 2" version included random slopes for the other effect, and the "RS" version included random slopes for both effects.</p><p>For the "RS (evidence)" version, the inclusion of random effects was conditional on evidence supporting them.</p><p>I computed the posterior probabilities of the models as follows:</p><formula xml:id="formula_4">p (M1|D)/p(M0|D) = BF 10 p(M1)/p(M0); p M D p M D p M D p M D p M D ( | ) | | | ( )/ ( ) ( )/ ( ) 1 | = + 1 0 1 0 1 p(M0|D) = 1 -p(M1|D).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The model-comparison approach omitting random slopes was not well calibrated: It returned an overly high posterior probability of the alternative model, p(M1|D) = .53, 95% confidence interval (CI) = [.50, .57].</p><p>The approach always including random slopes was well calibrated, p(M1|D) = .50, 95% CI = [.46, .53], as was the parsimonious approach including random slopes only when there was evidence for them, p(M1|D) = .51, 95% CI = [.48, .54]. Table <ref type="table" target="#tab_9">10</ref> gives a breakdown of the posterior model probabilities by the true model generating the data. It shows that the bias in model comparisons always omitting random slopes comes from overestimating the posterior probability of M1 when the null model was true.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The simulation-based calibration confirmed that always omitting random slopes results in a biased BF if random slopes are part of the data-generating process. The bias reflected in the averaged model posteriors might appear benign. This is in part because the standard deviations of the random slopes tended to be smaller than in the previous simulations. Nevertheless, there were still 7.4% false positives with BF greater than 10. Always including random slopes, as well as using the parsimonious model-comparison approach, yielded wellcalibrated BFs at least for one common design. This is no guarantee that BFs for other designs or other experimental parameters (e.g., number of subjects and trials) are also well calibrated. To be sure that they are, researchers might consider running calibration simulations for their design.</p><p>Random Slopes in brms, BayesFactor, and JASP</p><p>On the practical side, including random slopes in Bayesian mixed models is not always straightforward.  Within each type of data, probabilities are further broken down for simulations returning a miss (i.e., a BF &lt; 3, which is weak evidence for the effect, or a BF &lt; 1, reflecting weak evidence against the effect) or a false negative (i.e., a BF &lt; 0.33, which is evidence for the null hypothesis). The "no RS" model version included no random slopes, the "RS 1" version included random slopes for the effect of interest, the "RS 2" version included random slopes for the other effect, and the "RS" version included random slopes for both effects. For the "RS (evidence)" version, the inclusion of random effects was conditional on evidence supporting them.</p><p>To the best of my knowledge, the three most popular software tools for running such models in psychology are the R packages brms <ref type="bibr" target="#b3">(Bürkner, 2017)</ref> and Bayes-Factor <ref type="bibr" target="#b9">(Morey &amp; Rouder, 2015)</ref> and the free stand-alone application JASP ( JASP Team, 2020).</p><p>The brms package gives users maximal flexibility in specifying their model, including the random-effects structure. The core function, "brm," takes as the first argument a formula in the standard language of R, in which random effects can be specified. For instance, the following formula-using the general formula language for mixed models in R-describes a model with two main effects as fixed effects, together with the random intercept, and the random slopes of both predictors:</p><formula xml:id="formula_5">brm(formula = dv ~ iv1 + iv2 + (1 + iv1 + iv2 || id), . . .)</formula><p>In plain English, the dependent variable ("dv") is a function of the additive fixed effects of Independent Variables 1 and 2 ("iv1" and "iv2"). The random effects are added in parentheses, and the variable identifying the subject ("id") is the unit of random variation. The expression before the double bar specifies a random intercept (1) and random slopes of the effects of iv1 and iv2. The double bar excludes correlations between random effects; a single bar is used to include them.</p><p>In the BayesFactor package, the "lmBF" function offers the same functionality for linear mixed models. The following code specifies the same model as above: lmBF(formula = dv ~ iv1 + iv2 + id + id:iv1 + id:iv2, whichRandom="id", . . .)</p><p>Here, the random effects are included in the formula in the same way as fixed effects, and the argument "whichRandom" is used to specify which predictors are to be treated as the units of random variation. One limitation of "lmBF" is that it does not reliably support random slopes of continuous predictors (i.e., predictors that are numerical variables rather than factors in R). This is why I could not run Simulation 3 with the Bayes-Factor package. The "anovaBF" function in the Bayes-Factor package is dedicated to ANOVA models. It includes random intercepts but no random slopes, and there is no option for the user to include the latter. Therefore, using the "anovaBF" function incurs a substantial risk of false positives, especially when the design has many within-subjects cells.</p><p>In JASP, users can choose between Bayesian ANOVAs and Bayesian mixed models. The "mixed models" function enables users to choose their random-effects structure. By default, random slopes and their correlations are included for all predictors. The "ANOVA" function, by contrast, includes only random intercepts, without any flexibility. The required data format enforces aggregation of data within each design cell; therefore, the risk of hugely inflated false-positive BFs is small. Nevertheless, running Bayesian within-subjects ANOVAs in JASP entails a nonnegligible risk of false-positive BFs, especially when the design has many cells. To confirm this conjecture, I ran a simple simulation of a 2 × 6 ANOVA design with the same specifications as Simulation 2 and  a true effect of zero. Out of 100 simulated data sets, 32 yielded a BF greater than 3 for the effect, and 19 of them yielded a BF greater than 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>As Bayesian statistics is gaining ground, we need to become aware of the potential pitfalls involved in using it. One potential pitfall is to use mixed-effects models to test hypotheses about effects on the population level without including random slopes in the model. If there are true individual differences in the effect of interest, this can lead to massively inflated evidence in favor of the effect on the population level, even if no such effect exists.</p><p>This result mirrors the one that <ref type="bibr" target="#b0">Barr et al. (2013)</ref> reported for mixed-model comparisons in frequentist statistics, but the problem is more pervasive for Bayesian than for frequentist hypothesis testing. In frequentist statistics, the main tool for null-hypothesis testing in within-subjects designs is the within-subjects (or repeated measures) ANOVA. The F test for this ANOVA includes the variance generated by random slopestogether with measurement error-in the error term and thereby automatically accounts for their effect. Therefore, significance testing based on the F statistic from within-subjects ANOVA does not lead to inflated false-positive rates. By contrast, hypothesis testing with Bayesian ANOVAs <ref type="bibr" target="#b11">(Rouder et al., 2012)</ref>, as built into the BayesFactor package and JASP, relies on model comparisons and therefore gives rise to a substantial risk of exaggerated evidence for nonexistent effects.</p><p>Readers might think that the results of the present simulations are trivial because they merely show that using misspecified models leads to erroneous conclusions. It is not that simple. Except in the idealized environment of a simulated ground truth, models are always simplified descriptions of reality, and yet they are often useful for inferences <ref type="bibr" target="#b2">(Box, 1979)</ref>. For instance, the comparison of a linear model with a null model is useful to detect a monotonic trend even if it is nonlinear. We need to find out which simplifications we can afford without undercutting their usefulness. It turns out that we cannot afford to simplify away random slopes. It could have turned out otherwise: A comparison of two models omitting random slopes that are actually warranted by the data is not obviously biased a priori because both models suffer the same misspecification.</p><p>What can we do to minimize the risk of exaggerated evidence for nonexistent effects? One obvious solution is to always include random slopes in the models that we compare. This comes with two costs. One is that the chance of obtaining convincing evidence (i.e., large BFs) for a true effect is reduced substantially. The other is that the models run much longer. A compromise could be to include only those random slopes that are warranted by the data. The rationale behind this approach is to first search for the most parsimonious model of the random effects in the data, thereby culling any excess flexibility in the model, before turning to model comparisons testing the fixed effects of interest <ref type="bibr" target="#b8">(Matuschek et al., 2017)</ref>. This approach reduces the risk of false positives, but not as much as always including random slopes (this became most apparent in Simulations 2 and 4). It also reduces the potential of misses, but again, not as much as never including random slopes. Simulation 5 showed that the BFs and posterior model probabilities obtained with the parsimonious approach are well calibrated for a typical ANOVA design. The advantage of testing the evidence for random slopes in the data is probably underestimated in the present simulations, as the data-generating model always included random slopes, and in Simulations 2 and 4, their size was held constant. Therefore, in real data, we can expect more variability in the true size of individual differences of effects, including many situations in which they are actually negligible. Testing the evidence for random slopes as a first step will enable researchers to identify many of those cases and remove unnecessary random slopes from the models.</p><p>Another compromise solution, at least for ANOVA designs, would be to aggregate the data at the designcell level. This strongly shrinks BFs toward 1 compared with unaggregated data, leading to fewer-and far less extreme-false positives but also to more misses of true effects (for a discussion of why this happens, see <ref type="bibr" target="#b13">Singmann et al., 2021)</ref>. In addition, aggregation is less helpful in suppressing false positives when the within-subjects design has many cells.</p><p>The risk of missing a true effect, or even obtaining evidence against it (i.e., BF &lt; 0.33), is a manageable one: The BFs that the simulations yielded in such cases rarely reflected strong evidence for a wrong conclusion. In most cases, one would conclude that the evidence is ambiguous or moderately in favor of the null hypotheses. The matter would not be regarded as settled. The rational step for researchers in that situation-if resources are available-is to increase the sample size, which reduces the potential for misses and false negatives. By contrast, the risk of false positives revealed in the present simulations is less manageable because many false positives show up as BFs that would usually be regarded as very strong and even decisive (i.e., BF &gt; 100; <ref type="bibr" target="#b7">Kass &amp; Raftery, 1995)</ref>. This makes an erroneous conclusion in favor of an effect much harder to overturn.</p><p>I therefore recommend to err on the side of caution: When analyzing unaggregated data, one should always start with a model including the random slopes corresponding to all fixed effects. Researchers could test whether all random slopes are warranted by the data by comparing the full model with a model that has a reduced random-effects structure. If the BF unambiguously supports the reduced model, it should be fairly safe to continue testing fixed effects in models using the reduced random-effects structure. When one analyzes aggregated data, doing so without random slopes should be reasonably safe with simple designs. For more complex within-subjects designs that have many design cells, I recommend starting with a model that includes the random slopes and excluding them only if the evidence speaks unambiguously against them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transparency</head><p>Action Editor: Sachiko Kinoshita Editor: Patricia J. Bauer Author Contributions K. Oberauer is the sole author of this article and is responsible for its content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflicting Interests</head><p>The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open Practices</head><p>All simulation code has been made publicly available via OSF and can be accessed at <ref type="url" target="https://osf.io/h4gcy/">https://osf.io/h4gcy/</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Simulation 1: Bayes factors (BFs) for the effect of interest when the true effect is zero, as a function of model version and standard deviation of random effects, σ. Results are shown separately for unaggregated data (left) and aggregated data (right). The "no RS" model version included no random slopes, the "RS 1" version included random slopes for the effect of interest, the "RS 2" version included random slopes for the other effect, and the "RS" version included random slopes for both effects. Each point is a BF from one simulation run. BFs are plotted on a log 10 scale for visibility. BFs above the red line indicate evidence for the effect; those below the red line indicate evidence against the effect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Simulation 1: Bayes factors (BFs) from simulations in which the effect of interest was zero, as a function of sample effect size and model version. Results are shown separately for unaggregated data (left) and aggregated data (right). The "no RS" model version included no random slopes, and the "RS" version included random slopes for both effects. Note the scale difference of the y-axis between graphs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.4. Simulation 2: Bayes factors (BFs) for the effect of interest when the true effect is zero, as a function of model version and number of levels of Independent Variable (IV) 2. Results are shown separately for unaggregated data (left) and aggregated data (right). The "no RS" model version included no random slopes, the "RS 1" version included random slopes for the effect of interest, the "RS 2" version included random slopes for the other effect, and the "RS" version included random slopes for both effects. Each point is a BF from one simulation run. BFs are plotted on a log 10 scale for visibility (some extreme values are cut off at the top). BFs above the red line indicate evidence for the effect; those below the red line indicate evidence against the effect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5. Simulation 2: Bayes factors (BFs) from simulations in which the effect of interest was greater than 0, as a function of model version and number of levels of Independent Variable (IV) 2. Results are shown separately for unaggregated data (left) and aggregated data (right). The "no RS" model version included no random slopes, the "RS 1" version included random slopes for the effect of interest, the "RS 2" version included random slopes for the other effect, and the "RS" version included random slopes for both effects. Each point is a BF from one simulation run. BFs are plotted on a log 10 scale for visibility (some extreme values are cut off at the top). BFs above the red line indicate evidence for the effect; those below the red line indicate evidence against the effect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. Simulation 3: Bayes factors (BFs) for the effect of interest when the true effect is zero, as a function of model version and standard deviation of random effects, σ. The "no RS" model version included no random slopes, the "RS" version included random slopes for both effects, and the "RS + Corr" version included random slopes for both effects and the correlation between them. Each point is a BF from one simulation run. BFs are plotted on a log 10 scale for visibility (some extreme values are cut off at the top). BFs above the red line indicate evidence for the effect; those below the red line indicate evidence against the effect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig.7. Simulation 3: Bayes factors (BFs) for the effect of interest when the true effect is zero, as a function of model version and the size of the correlation between the random slopes of the two independent variables. The "no RS" model version included no random slopes, the "RS" version included random slopes for both effects, and the "RS + Corr" version included random slopes for both effects and the correlation between them. Each point is a BF from one simulation run. BFs are plotted on a log 10 scale for visibility. BFs above the red line indicate evidence for the effect; those below the red line indicate evidence against the effect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Simulation 4: Bayes factors (BFs) for the effect of interest when the true effect is zero, as a function of model version and sample size, N. Results are shown separately for unaggregated data (left) and aggregated data (right).The "no RS" model version included no random slopes, the "RS 1" version included random slopes for the effect of interest, the "RS 2" version included random slopes for the other effect, and the "RS" version included random slopes for both effects. Each point is a BF from one simulation run. BFs are plotted on a log 10 scale for visibility (some extreme values are cut off at the top). BFs above the red line indicate evidence for the effect; those below the red line indicate evidence against the effect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. Simulation 4: Bayes factors (BFs) for the effect of interest when the true effect is zero, as a function of model version and number of trials per subject. Results are shown separately for unaggregated data (left) and aggregated data (right). The "no RS" model version included no random slopes, the "RS 1" version included random slopes for the effect of interest, the "RS 2" version included random slopes for the other effect, and the "RS" version included random slopes for both effects. Each point is a BF from one simulation run. BFs are plotted on a log 10 scale for visibility (some extreme values are cut off at the top). BFs above the red line indicate evidence for the effect; those below the red line indicate evidence against the effect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Simulation 4: Bayes factors (BFs) for the effect of interest when the true effect is 0.25, as a function of model version and sample size, N. Results are shown separately for unaggregated data (left) and aggregated data (right).The "no RS" model version included no random slopes, the "RS 1" version included random slopes for the effect of interest, the "RS 2" version included random slopes for the other effect, and the "RS" version included random slopes for both effects. Each point is a BF from one simulation run. BFs are plotted on a log 10 scale for visibility (some extreme values are cut off at the top). BFs above the red line indicate evidence for the effect; those below the red line indicate evidence against the effect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Simulation 4: Bayes factors (BFs) for the effect of interest when the true effect is 0.25, as a function of model version and number of trials per subject. Results are shown separately for unaggregated data (left) and aggregated data (right). The "no RS" model version included no random slopes, the "RS 1" version included random slopes for the effect of interest, the "RS 2" version included random slopes for the other effect, and the "RS" version included random slopes for both effects. Each point is a BF from one simulation run. BFs are plotted on a log 10 scale for visibility (some extreme values are cut off at the top). BFs above the red line indicate evidence for the effect; those below the red line indicate evidence against the effect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Proportion</figDesc><table><row><cell></cell><cell cols="4">of Bayes Factors (BFs) in Simulation 1</cell></row><row><cell cols="5">Reflecting Evidence for the Effect of Interest When the True</cell></row><row><cell>Effect Was Zero</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Unaggregated data</cell><cell cols="2">Aggregated data</cell></row><row><cell>Model version</cell><cell>BF &gt; 3</cell><cell>BF &gt; 10</cell><cell>BF &gt; 3</cell><cell>BF &gt; 10</cell></row><row><cell>No RS</cell><cell>.23</cell><cell>.21</cell><cell>.03</cell><cell>.01</cell></row><row><cell>RS 1</cell><cell>0</cell><cell>0</cell><cell>.01</cell><cell>0</cell></row><row><cell>RS 2</cell><cell>.23</cell><cell>.22</cell><cell>.07</cell><cell>.02</cell></row><row><cell>RS</cell><cell>0</cell><cell>0</cell><cell>.02</cell><cell>.01</cell></row><row><cell>RS (evidence)</cell><cell>.13</cell><cell>.01</cell><cell>.05</cell><cell>.01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Proportion of Bayes Factors (BFs)  in Simulation 1 Reflecting Ambiguous Evidence or Evidence Against the Effect of Interest When There Was a True Effect (Effect Sizes = 0.25, 0.5, and 0.75 Combined)</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Unaggregated data</cell><cell></cell><cell cols="2">Aggregated data</cell></row><row><cell>Model version</cell><cell>BF &lt; 3</cell><cell>BF &lt; 1</cell><cell>BF &lt; 0.33</cell><cell>BF &lt; 3</cell><cell>BF &lt; 1</cell><cell>BF &lt; 0.33</cell></row><row><cell>No RS</cell><cell>.06</cell><cell>.04</cell><cell>.03</cell><cell>.17</cell><cell>.12</cell><cell>.05</cell></row><row><cell>RS 1</cell><cell>.35</cell><cell>.27</cell><cell>.09</cell><cell>.23</cell><cell>.14</cell><cell>.01</cell></row><row><cell>RS 2</cell><cell>.05</cell><cell>.04</cell><cell>.03</cell><cell>.13</cell><cell>.10</cell><cell>.04</cell></row><row><cell>RS</cell><cell>.35</cell><cell>.20</cell><cell>.09</cell><cell>.23</cell><cell>.13</cell><cell>.00</cell></row><row><cell>RS (evidence)</cell><cell>.18</cell><cell>.11</cell><cell>.06</cell><cell>.18</cell><cell>.11</cell><cell>.02</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Proportion of Bayes Factors (BFs) in Simulation 2Reflecting Evidence for the Effect of Interest When the True Effect Was Zero For each model, results are shown separately for unaggregated data and aggregated data. Within each type of data, probabilities are further broken down for mild false positives (BF &gt; 3) and severe false positives (BF &gt; 10). The "no RS" model version included no random slopes, the "RS 1" version included random slopes for the effect of interest, the "RS 2" version included random slopes for the other effect, and the "RS" version included random slopes for both effects. For the "RS (evidence)" version, the inclusion of random effects was conditional on evidence supporting them.</figDesc><table><row><cell></cell><cell cols="2">Unaggregated data</cell><cell cols="2">Aggregated data</cell></row><row><cell>Model version</cell><cell>BF &gt; 3</cell><cell>BF &gt; 10</cell><cell>BF &gt; 3</cell><cell>BF &gt; 10</cell></row><row><cell>No RS</cell><cell>.49</cell><cell>.46</cell><cell>.21</cell><cell>.14</cell></row><row><cell>RS 1</cell><cell>0</cell><cell>0</cell><cell>.01</cell><cell>.01</cell></row><row><cell>RS 2</cell><cell>.50</cell><cell>.47</cell><cell>.26</cell><cell>.18</cell></row><row><cell>RS</cell><cell>.01</cell><cell>0</cell><cell>.02</cell><cell>.01</cell></row><row><cell>RS (evidence)</cell><cell>.16</cell><cell>.15</cell><cell>.06</cell><cell>.03</cell></row><row><cell>Note:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Proportion of Bayes Factors (BFs) in Simulation 2 Reflecting Ambiguous Evidence or Evidence Against the Effect of Interest When There Was a True Effect (Effect Size = 0.5)</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Unaggregated data</cell><cell></cell><cell cols="2">Aggregated data</cell></row><row><cell>Model version</cell><cell>BF &lt; 3</cell><cell>BF &lt; 1</cell><cell>BF &lt; 0.33</cell><cell>BF &lt; 3</cell><cell>BF &lt; 1</cell><cell>BF &lt; 0.33</cell></row><row><cell>No RS</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>RS 1</cell><cell>.15</cell><cell>.03</cell><cell>.01</cell><cell>.06</cell><cell>.01</cell><cell>0</cell></row><row><cell>RS 2</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>RS</cell><cell>.14</cell><cell>.03</cell><cell>.01</cell><cell>.06</cell><cell>0</cell><cell>0</cell></row><row><cell>RS (evidence)</cell><cell>.09</cell><cell>.02</cell><cell>0</cell><cell>.05</cell><cell>.01</cell><cell>0</cell></row><row><cell cols="7">Note: For each model, results are shown separately for unaggregated data and aggregated data.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Proportion of Bayes Factors (BFs) in Simulation 3 Reflecting Evidence for the Effect of Interest When the True</figDesc><table><row><cell>Effect Was Zero</cell><cell></cell><cell></cell></row><row><cell>Model version</cell><cell>BF &gt; 3</cell><cell>BF &gt; 10</cell></row><row><cell>No RS</cell><cell>.34</cell><cell>.29</cell></row><row><cell>RS</cell><cell>.01</cell><cell>0</cell></row><row><cell>RS + Corr</cell><cell>.02</cell><cell>.01</cell></row></table><note><p>Note: For each model, probabilities are shown separately for mild false positives (BF &gt; 3) and severe false positives (BF &gt; 10). The "no RS" model version included no random slopes, the "RS" version included random slopes for both effects, and the "RS + Corr" version included random slopes for both effects and the correlation between them.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .</head><label>6</label><figDesc>Proportion of Bayes Factors (BFs) in Simulation 3 Reflecting Ambiguous Evidence or Evidence Against the Effect of Interest When the True Effect Was 0.25</figDesc><table><row><cell>Model</cell><cell></cell><cell></cell><cell></cell></row><row><cell>version</cell><cell>BF &lt; 3</cell><cell>BF &lt; 1</cell><cell>BF &lt; 0.33</cell></row><row><cell>No RS</cell><cell>.07</cell><cell>.06</cell><cell>.03</cell></row><row><cell>RS</cell><cell>.41</cell><cell>.30</cell><cell>.07</cell></row><row><cell>RS + Corr</cell><cell>.44</cell><cell>.33</cell><cell>.07</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 .</head><label>7</label><figDesc>Proportion of Bayes Factors (BFs) in Simulation 4 Reflecting Evidence for the Effect of Interest When the True</figDesc><table><row><cell>Effect Was Zero</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Unaggregated data</cell><cell cols="2">Aggregated data</cell></row><row><cell>Model version</cell><cell>BF &gt; 3</cell><cell>BF &gt; 10</cell><cell>BF &gt; 3</cell><cell>BF &gt; 10</cell></row><row><cell>No RS</cell><cell>.35</cell><cell>.29</cell><cell>.03</cell><cell>.01</cell></row><row><cell>RS 1</cell><cell>.00</cell><cell>0</cell><cell>.01</cell><cell>.00</cell></row><row><cell>RS 2</cell><cell>.36</cell><cell>.30</cell><cell>.06</cell><cell>.02</cell></row><row><cell>RS</cell><cell>.00</cell><cell>0</cell><cell>.02</cell><cell>.01</cell></row><row><cell>RS (evidence)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 .</head><label>8</label><figDesc>Proportion of Bayes Factors (BFs) in Simulation 4 Reflecting Ambiguous Evidence or Evidence Against the Effect of Interest When There Was a True Effect (Effect Size = 0.25)</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Unaggregated data</cell><cell></cell><cell cols="2">Aggregated data</cell></row><row><cell>Model version</cell><cell>BF &lt; 3</cell><cell>BF &lt; 1</cell><cell>BF &lt; 0.33</cell><cell>BF &lt; 3</cell><cell>BF &lt; 1</cell><cell>BF &lt; 0.33</cell></row><row><cell>No RS</cell><cell>.06</cell><cell>.05</cell><cell>.04</cell><cell>.25</cell><cell>.15</cell><cell>.05</cell></row><row><cell>RS 1</cell><cell>.61</cell><cell>.39</cell><cell>.15</cell><cell>.43</cell><cell>.20</cell><cell>.03</cell></row><row><cell>RS 2</cell><cell>.06</cell><cell>.04</cell><cell>.04</cell><cell>.12</cell><cell>.11</cell><cell>.04</cell></row><row><cell>RS</cell><cell>.60</cell><cell>.37</cell><cell>.15</cell><cell>.39</cell><cell>.15</cell><cell>.01</cell></row><row><cell>RS (evidence)</cell><cell>.35</cell><cell>.23</cell><cell>.11</cell><cell>.32</cell><cell>.15</cell><cell>.02</cell></row></table><note><p>Note: For each model, results are shown separately for unaggregated data and aggregated data.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9 .</head><label>9</label><figDesc>Proportion of Bayes Factors Less Than 1 in Simulation 4 When There Was a True Effect, as a Function of Sample Size and Number of Trials</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Sample size</cell><cell></cell></row><row><cell>Model version and</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>number of trials</cell><cell>20</cell><cell>30</cell><cell>40</cell><cell>50</cell></row><row><cell>RS</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>80</cell><cell>.60</cell><cell>.32</cell><cell>.40</cell><cell>.20</cell></row><row><cell>120</cell><cell>.56</cell><cell>.44</cell><cell>.46</cell><cell>.20</cell></row><row><cell>160</cell><cell>.64</cell><cell>.46</cell><cell>.28</cell><cell>.20</cell></row><row><cell>240</cell><cell>.62</cell><cell>.36</cell><cell>.24</cell><cell>.16</cell></row><row><cell>360</cell><cell>.50</cell><cell>.32</cell><cell>.28</cell><cell>.14</cell></row><row><cell>RS (evidence)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>80</cell><cell>.40</cell><cell>.24</cell><cell>.26</cell><cell>.18</cell></row><row><cell>120</cell><cell>.36</cell><cell>.28</cell><cell>.26</cell><cell>.08</cell></row><row><cell>160</cell><cell>.42</cell><cell>.36</cell><cell>.20</cell><cell>.14</cell></row><row><cell>240</cell><cell>.40</cell><cell>.20</cell><cell>.16</cell><cell>.08</cell></row><row><cell>360</cell><cell>.28</cell><cell>.18</cell><cell>.08</cell><cell>.12</cell></row><row><cell cols="4">Note: Results are from unaggregated data. The "RS" model version</cell><cell></cell></row><row><cell cols="4">included random slopes for both effects. In the "RS (evidence)"</cell><cell></cell></row><row><cell cols="5">version, the inclusion of random slopes was determined empirically</cell></row><row><cell>through model comparison.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 10 .</head><label>10</label><figDesc>Mean Posterior Model Probabilities in Simulation 5 as a Function of the True Model (M0 or M1) and the Model-Comparison Approach</figDesc><table><row><cell></cell><cell cols="2">No RS</cell><cell>RS</cell><cell></cell><cell cols="2">RS (evidence)</cell></row><row><cell>Model</cell><cell>p(M0|D)</cell><cell>p(M1|D)</cell><cell>p(M0|D)</cell><cell>p(M1|D)</cell><cell>p(M0|D)</cell><cell>p(M1|D)</cell></row><row><cell>M0</cell><cell>.77</cell><cell>.23</cell><cell>.86</cell><cell>.14</cell><cell>.84</cell><cell>.16</cell></row><row><cell>M1</cell><cell>.10</cell><cell>.90</cell><cell>.18</cell><cell>.82</cell><cell>.15</cell><cell>.85</cell></row></table><note><p>Note: Probabilities are shown separately for when the null model (M0) is true and when the alternative model (M1) is true. The "no RS" model version included no random slopes, and the "RS" version included random slopes for both effects. For the "RS (evidence)" version, the inclusion of random effects was conditional on evidence supporting them.</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>I am grateful to <rs type="person">Mirko Thalmann</rs>, <rs type="person">Marcel Niklaus</rs>, <rs type="person">Gidon Frischkorn</rs>, <rs type="person">Jeff Rouder</rs>, <rs type="person">E.-J. Wagenmakers</rs>, and <rs type="person">Richard Morey</rs> for many discussions on the topic of this article.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notes</head><p>1. Testing the hypothesis that an effect exists in the population against the null hypothesis that it does not comes down to testing a model that includes the effect as a free parameter with a null model in which that parameter is fixed to 0. Estimating the posterior probability of the effect is no alternative: The posterior's density at zero is not the probability that the effect is zero. The question of whether the 95% credible interval of the posterior excludes zero is not an adequate alternative either <ref type="bibr" target="#b1">(Berger, 2006;</ref><ref type="bibr" target="#b14">Wagenmakers et al., 2021)</ref>. 2. Because I set the standard deviation to 1, these effect sizes are standardized. 3. It is still distinguishable because of the second independent variable, so that for each main effect, there are two data points per condition. Without the second predictor, the random slope could not be estimated at all, and the model would not run. 4. Because running brms models takes a long time, I could not run more replications or more MCMC samples. Simulation 3 already took several months of computation time. 5. Some of the BFs for the condition with σ of 1 were cut off in Figure <ref type="figure">6</ref> because they went up to 10 120 .</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Random effects structure for confirmatory hypothesis testing: Keep it maximal</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Scheepers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Tily</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="255" to="278" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bayes factor</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of statistical sciences</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Kotz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Balakrishnan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Read</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Vidakovic</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</editor>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="378" to="386" />
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robustness in the strategy of scientific model building</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E P</forename><surname>Box</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robustness in statistics</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Launer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Wilkinson</surname></persName>
		</editor>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1979">1979</date>
			<biblScope unit="page" from="201" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">brms: An R package for Bayesian multilevel models using Stan</title>
		<author>
			<persName><forename type="first">P.-C</forename><surname>Bürkner</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v080.i01</idno>
		<ptr target="https://doi.org/10.18637/jss.v080.i01" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">bridgesampling: An R package for estimating normalizing constants</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">F</forename><surname>Gronau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Singmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v092.i10</idno>
		<ptr target="https://doi.org/10.18637/jss.v092.i10" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<orgName type="collaboration">JASP Team</orgName>
		</author>
		<ptr target="https://jasp-stats.org" />
	</analytic>
	<monogr>
		<title level="j">JASP</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="issue">14</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Computer software</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The theory of probability</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jeffreys</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1961">1961</date>
			<publisher>Clarendon Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bayes factors</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="773" to="795" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Balancing Type I error and power in linear mixed models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Matuschek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kliegl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vasishth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Baayen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Bates</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jml.2017.01.001</idno>
		<ptr target="https://doi.org/10.1016/j.jml.2017.01.001" />
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="305" to="315" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">BayesFactor: Computation of Bayes Factors for Common designs (Version 0</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Morey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<ptr target="http://cran.at.r-project.org/web/packages/BayesFactor/index.html" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing</title>
		<author>
			<persName><forename type="first">Team</forename><surname>Core</surname></persName>
		</author>
		<ptr target="http://www.R-project.org" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Version 3.6.2. Computer software</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Default Bayes factors for ANOVA designs</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Morey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Speckman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Province</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="356" to="374" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Workflow techniques for the robust use of Bayes factors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Schad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nicenboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-C</forename><surname>Bürkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Betancourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vasishth</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000472</idno>
		<ptr target="https://doi.org/10.1037/met0000472" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Advance online</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Singmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kellen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Chandramouli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Davis-Stober</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">F</forename><surname>Gronau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kalish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Mcmullin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Shiffrin</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/kxhfu</idno>
		<ptr target="https://doi.org/10.31234/osf.io/kxhfu" />
		<title level="m">Statistics in the service of science: Don&apos;t let the tail wag the dog</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">PsyArXiv</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The principle of predictive irrelevance or why intervals should not be used for model comparison featuring a point null hypothesis</title>
		<author>
			<persName><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Morey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">The theory of statistics in psychology</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Gruber</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="111" to="124" />
			<date type="published" when="2021">2021</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>Annals of theoretical psychology</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
