<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pupillary Responses to Words That Convey a Sense of Brightness or Darkness</title>
				<funder ref="#_FsXBHvk #_PWHSjvF">
					<orgName type="full">Marie Curie Action 302807</orgName>
				</funder>
				<funder ref="#_x4bWtXT">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_BJ2UTmq">
					<orgName type="full">Marie Curie Action 622738 and Nederlandse Organisatie voor Wetenschappelijk Onderzoek VENI</orgName>
				</funder>
				<funder>
					<orgName type="full">Agence Nationale de la Recherche</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Sebastiaan</forename><surname>Mathôt</surname></persName>
							<email>s.mathot@cogsci.nl</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Experimental Psychology</orgName>
								<orgName type="institution">University of Groningen</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Laboratoire de Psychologie Cognitive</orgName>
								<orgName type="institution">Unité Mixte de Recherche (UMR)</orgName>
								<address>
									<addrLine>7290</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jonathan</forename><surname>Grainger</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">Laboratoire de Psychologie Cognitive</orgName>
								<orgName type="institution">Unité Mixte de Recherche (UMR)</orgName>
								<address>
									<addrLine>7290</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kristof</forename><surname>Strijkers</surname></persName>
							<affiliation key="aff3">
								<orgName type="laboratory" key="lab1">Laboratoire Parole et Langage</orgName>
								<orgName type="laboratory" key="lab2">UMR 7309</orgName>
								<orgName type="institution" key="instit1">Centre National de la Recherche Scientifique (CNRS)</orgName>
								<orgName type="institution" key="instit2">Aix-Marseille University</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">Aix-Marseille University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Experimental Psychology</orgName>
								<orgName type="institution" key="instit1">University of Groningen</orgName>
								<orgName type="institution" key="instit2">Grote</orgName>
								<address>
									<addrLine>Kruisstraat 2/1</addrLine>
									<postCode>9712 TS</postCode>
									<settlement>Groningen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pupillary Responses to Words That Convey a Sense of Brightness or Darkness</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A402DC200E96995311D4728B7C296BF3</idno>
					<idno type="DOI">10.1177/0956797617702699</idno>
					<note type="submission">Received 7/26/16; Revision accepted 3/13/17</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-06-02T09:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>pupillometry</term>
					<term>language comprehension</term>
					<term>embodied cognition</term>
					<term>pupillary light response</term>
					<term>open data</term>
					<term>open materials</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Theories about embodiment of language hold that when you process a word's meaning, you automatically simulate associated sensory input (e.g., perception of brightness when you process lamp) and prepare associated actions (e.g., finger movements when you process typing). To test this latter prediction, we measured pupillary responses to single words that conveyed a sense of brightness (e.g., day) or darkness (e.g., night) or were neutral (e.g., house).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Theories about embodiment of language hold that when people process a word's meaning-at least for words that refer to concrete actions or objects-they mentally simulate what they can do with the word's referent and what this referent looks, smells, and feels like. For example, according to such theories, when people read the word keyboard, they mentally simulate a typing action, and when they read the word sun, they simulate the perception of a bright ball of fire in the sky. Theories positing strong embodiment of language hold that such simulations are necessary for comprehension; that is, to understand what sun means, people would need a sensory representation of what it looks like <ref type="bibr" target="#b10">(Glenberg &amp; Gallese, 2012;</ref><ref type="bibr" target="#b34">Pulvermüller, 2013)</ref>. By contrast, theories suggesting weak embodiment of language are a middle ground between strong embodiment and the traditional view of language as a purely symbolic system that does not involve sensory and motor representations: According to theories suggesting weak embodiment of language, simulations may facilitate language comprehension but are not strictly necessary; that is, mentally picturing the sun may help someone to read sun faster, but they could understand sun, even without any sensory representation of it, by relying on a symbolic system <ref type="bibr" target="#b28">(Meteyard, Cuadrado, Bahrami, &amp; Vigliocco, 2012;</ref><ref type="bibr" target="#b40">Zwaan, 2014)</ref>. As critics of embodied cognition have pointed out, by admitting that sensory simulations may not be necessary for language comprehension, weakly embodied views of language are fundamentally different from strongly embodied views and, in some ways, are similar to traditional, symbolic views of language <ref type="bibr" target="#b2">(Bedny &amp; Caramazza, 2011;</ref><ref type="bibr" target="#b18">Mahon, 2015;</ref><ref type="bibr" target="#b19">Mahon &amp; Caramazza, 2008)</ref>.</p><p>Most support for sensory and motor simulations during language comprehension comes from studies that have taken one of two general approaches: behavioral studies that look at compatibility effects between word meaning and action (or perception; <ref type="bibr" target="#b0">Aravena et al., 2012;</ref><ref type="bibr" target="#b11">Glenberg &amp; Kaschak, 2002;</ref><ref type="bibr" target="#b14">Kaschak et al., 2005;</ref><ref type="bibr" target="#b27">Meteyard, Bahrami, &amp; Vigliocco, 2007;</ref><ref type="bibr" target="#b29">Meteyard, Zokaei, Bahrami, &amp; Vigliocco, 2008;</ref><ref type="bibr" target="#b41">Zwaan, Madden, Yaxley, &amp; Aveyard, 2004;</ref><ref type="bibr" target="#b42">Zwaan &amp; Taylor, 2006)</ref> and neuroimaging studies that compare brain activity during language comprehension with brain activity during action (or perception; <ref type="bibr" target="#b9">Dravida, Saxe, &amp; Bedny, 2013;</ref><ref type="bibr" target="#b13">Hauk, Johnsrude, &amp; Pulvermuller, 2004;</ref><ref type="bibr" target="#b36">Revill, Aslin, Tanenhaus, &amp; Bavelier, 2008)</ref>. A compelling example of a behavioral-compatibility effect was reported by <ref type="bibr">Meteyard and her colleagues (2008)</ref>, who found that upward-downward visual motion affects comprehension speed of words that have a meaning related to upward-downward motion (see also <ref type="bibr" target="#b14">Kaschak et al., 2005;</ref><ref type="bibr" target="#b27">Meteyard et al., 2007)</ref>; that is, participants decided more quickly that fall was a real word (as opposed to a nonword) when they simultaneously saw downward-moving dots. From this, <ref type="bibr" target="#b29">Meteyard et al. (2008)</ref> concluded that understanding words that have a meaning related to upward-downward motion involves, at least in part, the same brain areas as perceiving downward motion. This conclusion is supported by neuroimaging studies that show overlap in the brain areas that are active during both (a) reading of words associated with motion and (b) perception of motion <ref type="bibr" target="#b36">(Revill et al., 2008;</ref><ref type="bibr"></ref> but for the limits of this overlap, see <ref type="bibr" target="#b9">Dravida et al., 2013)</ref>.</p><p>However, behavioral studies have so far not directly tested one of the central predictions of embodied language: that word meaning by itself can trigger, at least in some cases, associated involuntary actions. For example, consider a landmark study by <ref type="bibr" target="#b11">Glenberg and Kaschak (2002)</ref> in which participants judged whether sentences were sensible or not. These sentences conveyed a movement toward or away from the body (e.g., "open the drawer" for movement toward and "close the drawer" for movement away from the body), and participants responded by moving their hands either toward or away from their bodies (e.g., toward themselves for sensible sentences and away from themselves for nonsensible sentences, or the other way around). The crucial finding was that responses were fastest when the direction of the response coincided with the movement direction implied by the sentence; that is, when participants read "open the drawer," they were fastest when they responded with a movement toward the body. This showed that word meaning can modulate actions. However, in this experiment, word meaning did not trigger actions; rather, word meaning sped up (or slowed down) actions that were imposed by the task. To our knowledge, the same is true for all behavioral studies that have investigated the effect of word meaning on action. These studies demonstrate (sometimes very convincingly) that word meaning can modulate actions (e.g., grip force, <ref type="bibr" target="#b0">Aravena et al., 2012)</ref> or speed up manual responses <ref type="bibr" target="#b11">(Glenberg &amp; Kaschak, 2002;</ref><ref type="bibr" target="#b42">Zwaan &amp; Taylor, 2006)</ref>, but not that word meaning can by itself trigger an action.</p><p>In the current study, we aimed to show that word meaning by itself can trigger a pupillary light response, an involuntary movement that has traditionally been believed to be a low-level reflex to light. However, recent studies have shown that the light response, although beyond direct voluntary control, is sensitive to high-level cognition (reviewed in <ref type="bibr" target="#b3">Binda &amp; Murray, 2014;</ref><ref type="bibr" target="#b26">Mathôt &amp; Van der Stigchel, 2015)</ref>. For example, pupils constrict when people covertly attend (without looking at it) to a bright object compared with a dark object <ref type="bibr" target="#b4">(Binda, Pereverzeva, &amp; Murray, 2013;</ref><ref type="bibr" target="#b24">Mathôt, van der Linden, Grainger, &amp; Vitu, 2013;</ref><ref type="bibr" target="#b30">Naber, Alvarez, &amp; Nakayama, 2013)</ref>. Likewise, pupils constrict when people imagine a bright object <ref type="bibr" target="#b16">(Laeng &amp; Sulutvedt, 2014)</ref> or when a bright object reaches awareness in a binocular-rivalry paradigm <ref type="bibr" target="#b31">(Naber, Frassle, &amp; Einhauser, 2011)</ref>. These phenomena are often explained in terms of top-down modulation of visual brain areas <ref type="bibr" target="#b21">(Mathôt, Dalmaijer, Grainger, &amp; Van der Stigchel, 2014;</ref><ref type="bibr" target="#b39">Wang &amp; Munoz, 2016)</ref>; that is, pupils constrict when people covertly attend to a bright object, because attention enhances the representation of the bright object throughout visual cortical and subcortical areas.</p><p>This reasoning can be naturally extended to embodied language: If word comprehension activates brain areas known to be involved in processing of nonlinguistic visual information (i.e., creates sensory representations), then understanding words that convey a sense of brightness or darkness should trigger pupillary responses-just like attending to <ref type="bibr" target="#b24">(Mathôt et al., 2013)</ref> or imagining <ref type="bibr" target="#b16">(Laeng &amp; Sulutvedt, 2014)</ref> bright or dark objects. Phrased differently, if words that convey brightness trigger a pupillary constriction relative to words that convey darkness, this would support the view that word comprehension affects sensory brain areas and can even trigger involuntary (pupillary) responses. To our knowledge, this would also be the first direct demonstration that word comprehension by itself can trigger a response and not merely modulate an action that has been imposed by task instructions.</p><p>To test this hypothesis, we conducted two main experiments in which participants read (visual experiment) or listened to (auditory experiment) words conveying brightness or darkness. We measured pupil size and predicted that pupils would be smaller when participants read or listened to words conveying brightness than when they read or heard words conveying darkness: a pupillary light response triggered by word meaning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stimuli</head><p>For the main experiments, in which we varied the semantic brightness of words (i.e., whether words conveyed brightness or darkness), we manually selected 121 words from Lexique <ref type="bibr" target="#b32">(New, Pallier, Brysbaert, &amp; Ferrand, 2004</ref>), a large database with lexical properties of French words.</p><p>There were four word categories: words conveying brightness (e.g., illuminé or "illuminated"; n = 33), words conveying darkness (e.g., foncé or "dark"; n = 33), neutral words (e.g., renforcer or "to reinforce"; n = 35), and animal names (e.g., lapin or "rabbit"; n = 20). During the visual experiment, words were shown as dark letters (8.5 cd/m 2 ) against a gray background (17.4 cd/m 2 ). For the auditory experiment, words were generated in a synthetic voice by using the Mac OS X "say" command to convert text to speech.</p><p>Because we wanted to compare pupillary responses to words conveying brightness or darkness, these two categories needed to be matched as accurately as possible. We focused on two main properties: lexical frequency, or how often a word occurs in books (words conveying brightness: M = 41 per million, SD = 147; words conveying darkness: M = 39 per million, SD = 119), and, for the visual experiment, visual intensity (words conveying brightness: M = 1.58 × 10 6 arbitrary units, SD = 4.31 × 10 5 ; words conveying darkness: M = 1.56 × 10 6 arbitrary units, SD = 4.26 × 10 5 ). Visual intensity was matched by selecting words that had approximately the same number of letters, then generating images of these words, and finally iteratively resizing these images until the visual intensity (i.e., summed luminance) of the words was almost identical between the two categories.</p><p>In the end, we had a stimulus set in which words conveying brightness or darkness were very closely matched; however, as a result of our stringent criteria, our set contained several variations of the same words, such as briller ("to shine") and brillant ("shining"). But given pupils' sensitivity to slight differences in task difficulty (i.e., lexical frequency) and visual intensity, we felt that matching was more important than having a highly varied stimulus set.</p><p>For the control experiment, in which we varied the valence of words, we selected 60 words that were rated for valence by <ref type="bibr" target="#b5">Bonin et al. (2003)</ref>, complemented with the 20 animal names selected for the main experiments. Positive words (e.g., cadeau or "present"; n = 30) had a valence of at least 3.5 on a scale from 1 (negative) to 5 (positive), and negative words (e.g., cicatrice or "scar"; n = 30) had a valence of 2.5 or less. The positive and negative words were matched on lexical frequency (positive: M = 3.21, SD = 0.76; negative: M = 3.26, SD = 0.53) and visual intensity (positive: M = 1.15 × 10 6 , SD = 3.47 × 10 5 ; negative: M = 1.15 × 10 6 , SD = 3.48 × 10 5 ), and none of the words had any obvious association with brightness or darkness.</p><p>For all experiments, stimuli were manually selected on the basis of strict criteria. Our sample size of around 30 words per condition was therefore a compromise between having well-matched stimuli and having a reasonable number of observations per participant and condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pupillometry experiments</head><p>Thirty naive observers (age range: 18-54 years; 21 women, 9 men) participated in the visual experiment. Thirty other naive observers participated in the auditory experiment (age range: 18-31 years; 19 women, 11 men). Finally, 30 naive observers participated in the control experiment, four of whom had also participated in the auditory experiment (age range: 18-31 years; 19 women, 11 men). We used two to three times as many participants per experiment as in most previous studies on the pupillary light response (e.g., n = 5-15 participants in <ref type="bibr" target="#b4">Binda et al., 2013;</ref><ref type="bibr">Mathôt et al., 2013, but 52</ref> participants in Experiment 5 of <ref type="bibr" target="#b16">Laeng &amp; Sulutvedt, 2014)</ref>, because we expected the effect of embodied language on pupil size to be relatively small. Participants reported normal or corrected vision, provided written informed consent before the experiment, and received €6 for their participation. The experiment was conducted with approval of the Comité d'éthique de l'Université d'Aix-Marseille <ref type="bibr">(Ref. 2014-12-03-09)</ref>.</p><p>Pupil size was recorded monocularly with an EyeLink 1000 (SR Research, Mississauga, ON, Canada), a videobased eye tracker sampling at 1000 Hz. Stimuli were presented on a 21-in. CRT monitor (screen resolution: 1,024 × 768 pixels; refresh rate: 150 Hz; model p227f, ViewSonic, Walnut, CA). Testing took place in a dimly lit room. The experiment was implemented with OpenSesame <ref type="bibr" target="#b23">(Mathôt, Schreij, &amp; Theeuwes, 2012)</ref> using the Expyriment <ref type="bibr" target="#b15">(Krause &amp; Lindemann, 2014)</ref> back end.</p><p>At the beginning of each session, a nine-point eyetracker calibration was performed. Before each trial, a single-point recalibration (drift correction) was performed. Each trial started with a dark central fixation dot on a gray background for 3 s. Next, a word was presented. In the visual experiment and the control experiment, the word was presented in the center of the screen for 3 s or until the participant pressed the space bar; in the auditory experiment, the word was played back through a set of desktop speakers, and the experiment paused for 3 s or until the participants pressed the space bar. The participants' task was to press the space bar whenever they saw or heard an animal name and to withhold response otherwise. Participants saw or heard each word once, with the exception of pénombre in the visual experiment. 1 Word order was fully randomized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Normative ratings</head><p>For all words conveying brightness or darkness, we collected normative ratings from 30 naive observers (age range: 18-29 years; 17 women, 13 men), most of whom had not participated in the pupillometry experiments. Participants received €2 for their participation. Words were presented one at a time and using the same images used for the visual pupillometry experiment, together with a five-point rating scale. On this scale, participants indicated how strongly the word conveyed a sense of brightness (from very bright to very dark) or the word's valence (from very negative to very positive). Brightness and valence were rated in separate blocks, the order of which was counterbalanced across participants. On the basis of valence ratings, we calculated the emotional intensity of the words as the deviation from neutral valence (intensity = |3 -valence|).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Trials in which participants' responses were incorrect (i.e., false alarms and misses) were excluded (visual experiment: 0.36% of trials; auditory experiment: 0.44% of trials; control experiment: 1.12% of trials), as were trials in which the pupil-size recordings contained artifacts (i.e., trials in which pupil size was less than 0.5 times or more than 2.5 times baseline size, because this generally corresponded to unreconstructed blinks or signal loss; visual experiment: 10.1% of trials; auditory experiment: 4.5% of trials; control experiment: 4.2% of trials). The average response time to animal words was 790 ms (SE = 8.6) for the visual experiment, 1067 ms (SE = 12.5) for the auditory experiment, and 790 ms (SE = 10.0) for the control experiment. No participants were excluded from the analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pupil-size results</head><p>The main results (for the visual and auditory experiments) are shown in Figure <ref type="figure" target="#fig_0">1</ref>, in which pupil size is plotted over time from word onset, separately for words conveying brightness, words conveying darkness, and neutral words. (Animal names are not shown, because the pupillary response was distorted by participants' keypress responses.) As predicted, pupils were smaller when participants read or heard words conveying brightness compared with words conveying darkness. This effect was present for both visually presented words (Fig. <ref type="figure" target="#fig_0">1a</ref>) and spoken words (Fig. <ref type="figure" target="#fig_0">1b</ref>). The effect arose gradually and slowly, and it peaked between 1 and 2 s after word onset. For neutral words, which did not convey a specific sense of brightness, pupil size was intermediate.</p><p>In addition to the effect of semantic brightness, in the visual experiment, there was a pronounced pupillary dilation that peaked around 0.6 s after word onset (Fig. <ref type="figure" target="#fig_0">1a</ref>). This is an alerting effect, or orienting response <ref type="bibr" target="#b21">(Mathôt et al., 2014;</ref><ref type="bibr" target="#b38">Wang &amp; Munoz, 2015)</ref>. This early pupillary response was not clearly modulated by the semantic brightness of the words and was followed by the pronounced constriction that always follows visual changes (e.g., <ref type="bibr" target="#b22">Mathôt, Melmi, &amp; Castet, 2015)</ref>. In the auditory experiment, there was no visual stimulation to trigger pupillary constriction, and pupils therefore dilated throughout the trial, with no clear distinction between the early orienting response and later dilation due to task-related effort.</p><p>Pupil size is reported as a proportion of pupil size at word onset and was smoothed with a 51-ms Hanning window. Blinks were reconstructed with cubic-spline interpolation <ref type="bibr" target="#b20">(Mathôt, 2013)</ref>. Only words conveying brightness or darkness were carefully matched (see the Method section), and therefore only these two categories were included in statistical tests. (However, including all words yielded similar results; see the Supplemental Material available online.) For each 10-ms window, we conducted a linear-mixed effects model using the lme4 package (Version 1.1-12; Bates, Maechler, Bolker, &amp; Walker, 2016) for the R software environment (Version 3.3.2; R Development Core Team, 2016). In this model, pupil size was the dependent variable, and semantic brightness (bright or dark) was the fixed effect; we used random by-participant intercepts and slopes. The R formula for our model was as follows-model: pupil_size ~ brightness + (1 + brightness|participant). We commonly use a significance threshold of at least 200 contiguous milliseconds in which p is less than .05 <ref type="bibr" target="#b24">(Mathôt et al., 2013)</ref>. To estimate p values, we interpreted t values as though they were z values (i.e., the computationally fast t-as-z approach), such that a t of 1.96 corresponded to a p of .05. This approach was anticonservative, but only slightly so given our sample size <ref type="bibr">(Luke, 2016)</ref>. With this criterion, the semantic-brightness effect was reliable from 1,310 to 2,410 ms and from 2,440 to 2,760 ms in the visual experiment and from 1,030 to 1,360 ms in the auditory experiment. However, Figure <ref type="figure" target="#fig_0">1</ref> shows significant differences in pupil size between words conveying brightness and words conveying darkness as determined using three alpha thresholds and no minimum number of contiguous samples.</p><p>To test how general the effect was, we also looked at mean pupil size during the 1-to 2-s window for individual participants and words. As shown in Figures <ref type="figure" target="#fig_2">2a</ref> and <ref type="figure" target="#fig_2">2b</ref>, the majority of the participants showed an effect in</p><p>Difference in Proportional Pupil Size (Dark -Bright) Words Conveying Darkness Words Conveying Brightness a b c d .20 -.10 -.05 .00 .05 .10 .15 -.15 -.10 -.05 .00 .05 .10 .15 Auditory Experiment Visual Experiment 1.15 0.85 0.90 0.95 1.00 1.05 1.10 1.00 1.05 1.10 Participants Participants Words Words Proportion of Pupil Size Relative to Size at Word Onset the predicted direction, and this effect was supported by a default Bayesian one-sided, one-sample t test, conducted with JASP (Version 0.7; <ref type="bibr" target="#b17">Love et al., 2015)</ref>. For the visual experiment, the Bayes factor (BF) was 51.3, and for the auditory experiment, the BF was 4.1; the combined BF was 211.1, which represents decisive evidence in support of a positive effect. As shown in Figures <ref type="figure" target="#fig_2">2c</ref> and <ref type="figure" target="#fig_2">2d</ref>, the effect of semantic brightness was small relative to the variability between words; however, there was a clear shift in the distribution of pupil sizes, so that pupil size was slightly larger for words conveying darkness than for words conveying brightness, which was again supported by a default Bayesian one-sided, independent-samples t test. For the visual experiment, the BF was 6.7, and for the auditory experiment, the BF was 3.8; the combined BF was 25.4, which represents strong evidence in support of the hypothesis that pupils are larger in response to words conveying darkness than in response to words conveying brightness. The results were similar when we analyzed the full 3 s of the trials rather than only the 1-to 2-s window (see the Supplemental Material).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The effects of valence and emotional intensity</head><p>To test whether the effect of semantic brightness could be due to differences in valence or emotional intensity, we analyzed the subjective ratings for semantic brightness, valence (positive or negative), and emotional intensity of all words.</p><p>First, participants rated words on a scale from 1 (bright) to 5 (dark). They agreed with our own division of the words into a set of words conveying brightness (rated darkness: M = 0.84, SD = 0.2) and a set of words conveying darkness (rated darkness: M = 3.00, SD = 0.24), t(64) = 36.43, p &lt; .001 (independent-samples t test). Second, we found a strong and reliable correlation between brightness and valence (r = .89, p &lt; .001), such that words conveying brightness were rated as being more positive than words conveying darkness. Valence probably has no effect on pupil size beyond that of emotional intensity; that is, pupils dilate similarly in response to negative and positive stimuli of equal emotional intensity <ref type="bibr" target="#b7">(Collins, Ellsworth, &amp; Helmreich, 1967)</ref>. The correlation between brightness and valence was so strong that we could not control for it statistically. Therefore, we conducted a control experiment in which we looked at the pupillary response to positive and negative words that had no association with brightness. This experiment confirmed that valence has no notable effect on pupil size (see the Supplemental Material): A default Bayesian two-sided one-sample t test conducted on a per-participant basis provided substantial evidence for the null hypothesis (BF = 4.9 in support of no effect); a default Bayesian two-sided independent-samples t test conducted on a per-word basis also provided substantial evidence for null hypothesis (BF = 3.0 in support of no effect). (If valence had been a confound in our main experiments, pupils would have been considerably larger in response to negative words than to positive words.) This control experiment also showed that emotional intensity (i.e., deviation from neutral valence) strongly affected pupil size, such that participants' pupils were largest in response to emotionally intense words (from 810 ms until trial end)-regardless of whether words were intensely positive or intensely negative.</p><p>Third, we found a weak but reliable correlation between brightness and emotional intensity (r = .22, p = .027), such that bright words were rated as being more emotionally intense than dark words; given the results from our control experiment (see also <ref type="bibr" target="#b12">Goldwater, 1972)</ref>, this finding would drive an effect in the opposite direction from the effect that we observed, because emotionally intense stimuli (bright words in our case) trigger a strong pupillary dilation. Given that the correlation between brightness and emotional intensity was only weak, we could take the effect of emotional intensity into account statistically by conducting a control analysis that was identical to the regression analysis described earlier but included emotional intensity as control predictor. Conducted using the same criteria as described earlier, this analysis again revealed in both experiments an effect of brightness that was reliable and in the expected direction. During the visual experiment, the effect was observed between 1,260 and 2,590 ms after word onset; during the auditory experiment, the effect was observed between 830 and 1,460 ms. In the auditory experiment, we also observed an effect between 90 and 330 ms; given that this effect was small and extremely early, it was probably spurious. In summary, it is theoretically and statistically unlikely that the effect of semantic brightness on pupil size was driven by differences in the valence and emotional intensity of our stimuli.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>We have demonstrated that the eyes' pupils are smaller after people read or listen to words conveying brightness (e.g., sun) than when people read or listen to words conveying darkness (e.g., night). This effect arises slowly and gradually and, in our experiments, peaked between 1 and 2 s after word onset.</p><p>Our findings have important implications for theories about how motor and sensory simulations arise during language comprehension. Our starting premise was that there is a cognitive pupillary response to light (i.e., one without direct visual stimulation) that reflects sensory representations that are similar to those that arise during perception <ref type="bibr" target="#b16">(Laeng &amp; Sulutvedt, 2014)</ref> and involve brain areas engaged in processing of nonlinguistic visual information <ref type="bibr" target="#b21">(Mathôt et al., 2014)</ref>. Our findings therefore suggest that word comprehension can induce activity in nonlinguistic visual brain areas, and can even trigger involuntary responses (e.g., a pupillary response) that correspond to the word's meaning. This finding is consistent with results of previous behavioral studies showing that word meaning can modulate actions (e.g., <ref type="bibr" target="#b0">Aravena et al., 2012;</ref><ref type="bibr" target="#b11">Glenberg &amp; Kaschak, 2002)</ref>. However, in previous studies, actions were not triggered by word meaning per se but were imposed by the task and voluntarily performed by the participants (e.g., <ref type="bibr" target="#b0">Aravena et al., 2012;</ref><ref type="bibr" target="#b11">Glenberg &amp; Kaschak, 2002;</ref><ref type="bibr" target="#b42">Zwaan &amp; Taylor, 2006)</ref>. Our findings extend these studies by showing that word meaning alone is sufficient to trigger a response that is not imposed by the task (i.e., the instructions did not mention pupils) and that is largely beyond voluntary control (see also <ref type="bibr" target="#b37">Spivey &amp; Geng, 2001</ref>, who showed that participants had spontaneous eye movements during mental imagery).</p><p>Is pupillary constriction merely a nonfunctional byproduct of reading words conveying brightness, or does it serve some function? If the latter, what might that function be? Given that the semantic pupillary effect occurs late-in the visual experiment, it did not reach its peak until about a second after participants had processed the word's meaning and responded to it-it is unlikely that pupillary responses themselves played a role in word comprehension. Therefore, our results do not reveal whether word representations are strongly embodied (consist, in part, of sensory and motor simulations) or are not (instead are accompanied by sensory and motor simulations; <ref type="bibr" target="#b18">Mahon, 2015)</ref>. However, our results do show that word meaning triggers mental simulations and can even trigger physiological (i.e., pupillary) responseseven when these responses are irrelevant to the task, and even when they are largely beyond voluntary control. This shows a profound interaction between language and the sensory and motor systems.</p><p>One possible function of sensory and motor simulations during language comprehension-one that is not often considered in discussions of embodied languageis preparation for the immediate future. For example, when people hear the name of an object that is in their field of view, they are likely to look at it <ref type="bibr" target="#b8">(Cooper, 1974)</ref>. Therefore, the pupillary constriction that is triggered by reading the word lamp may reflect preparation for looking at a lamp <ref type="bibr" target="#b25">(Mathôt, van der Linden, Grainger, &amp; Vitu, 2015)</ref>. In this view, sensory and motor simulations that arise during word comprehension are not (or not only) part of the comprehension process but reflect preparation for actions and perceptions that are likely to occur in the immediate future. There are many ways, direct and indirect, automatic and voluntary, in which language causes preparation. For example, if someone reads a scary passage from a horror novel about a rabid dog, his or her body might show arousal responses (goose bumps, etc.) that prepare the body for action. If this happens, the link between language and action preparation is automatic, in the sense that goose bumps, like pupillary responses, are involuntary. However, the link is also indirect, because it depends not only on language comprehension but also on fear: People who are afraid of dogs may get goose bumps when they read the novel about the rabid dog, but people who own a big dog may not.</p><p>In contrast, in the case of the semantic pupillary response, the link between language and action is direct, dependent only on language comprehension: Visual brain areas are automatically activated when the brain processes visual words (e.g., <ref type="bibr" target="#b36">Revill et al., 2008)</ref>, and whenever a neural representation of brightness is activated, either through microstimulation of visual brain areas <ref type="bibr" target="#b39">(Wang &amp; Munoz, 2016)</ref> or through cognitive processes such as attention <ref type="bibr" target="#b24">(Mathôt et al., 2013)</ref> and mental imagery <ref type="bibr" target="#b16">(Laeng &amp; Sulutvedt, 2014)</ref>, pupils constrict. Demonstrations of direct, automatic sensory and motor activation during language comprehension (as in the present study) could also be interpreted as reflecting a very direct link between language and action preparation. It is easy to see how such direct links could be beneficial (e.g., by adjusting pupil size ahead of time for optimal perception of an object to be looked at), regardless of whether the stuff of thought is fundamentally embodied or not-which is still an open question.</p><p>Finally, studies on embodied language have not always proven replicable. A study by <ref type="bibr" target="#b33">Papesh (2015)</ref> is particularly relevant: She failed to replicate the findings of <ref type="bibr" target="#b11">Glenberg and Kaschak (2002)</ref>-a key study that we have highlighted here as well. To date, there have been no large-scale replications of important embodied-cognition effects and no systematic meta-analyses to estimate how strongly the field is distorted by selective reporting and publication bias. But studies such as that by Papesh suggest caution-although not, in our view, extreme skepticism. Therefore, in the present study, we have provided a complete description of all data, a conceptual replication (i.e., the auditory experiment), and public access (for the URL, see the Open Practices statement at the end of the article) to all relevant materials to allow for independent, direct replication.</p><p>In summary, we have shown that pupils constrict when people read or listen to words conveying brightness compared with words conveying darkness. This shows that word comprehension alone is sufficient to activate sensory and motor representations and can even trigger involuntary (pupillary) responses.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Proportional change in pupil size as a function of time, separately for words conveying brightness, words conveying darkness, and neutral words. Results are shown for the (a) visual experiment and (b) auditory experiment. The shaded areas represent ±1 SE. Horizontal lines indicate periods during which pupil size differed significantly between trials with words conveying brightness and trials with words conveying darkness, using three different α thresholds. The vertical dotted lines indicate the mean response time to animal words.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Results for individual participants (top row) and individual words (bottom row). Mean proportional pupil-size change in the (a) visual experiment and (b) auditory experiment is presented separately for each participant. The data points are ordered by the magnitude of the difference in change in pupil size, which was calculated as pupil size for words conveying darkness minus pupil size for words conveying brightness. Mean proportion of pupil size relative to size at word onset in the (c) visual experiment and (d) auditory experiment is presented separately for each of the words conveying darkness and words conveying brightness. The data points are ordered by the magnitude of the change in pupil size. Error bars indicate ±1 SE. Pupil size was measured during the 1-to 2-s window after stimulus onset.</figDesc></figure>
		</body>
		<back>

			<div type="funding">
<div><head>Funding</head><p>This research was funded by <rs type="funder">Marie Curie Action 622738 and Nederlandse Organisatie voor Wetenschappelijk Onderzoek VENI</rs> Grant <rs type="grantNumber">451-16-023</rs> (to S. Mathôt) and by <rs type="funder">Marie Curie Action 302807</rs> (to K. Strijkers). The research was also supported by Grants <rs type="grantNumber">16-CONV-0002</rs> (to the <rs type="institution">Institute for Language Communication and the Brain)</rs> and <rs type="grantNumber">11-LABX-0036</rs> (to the <rs type="institution">Brain and Language Research Institute)</rs> from the <rs type="funder">Agence Nationale de la Recherche</rs>.</p></div>
<div><head>Supplemental Material</head><p>Additional supporting information can be found at <ref type="url" target="http://journals.sagepub.com/doi/suppl/10.1177/0956797617702699">http://  journals.sagepub.com/doi/suppl/10.1177/0956797617702699</ref> </p></div>
<div><head>Open Practices</head><p>All data and materials have been made publicly available via Figshare and can be accessed at <ref type="url" target="https://doi.org/10.6084/m9.figshare.4742935.v2">https://doi.org/10.6084/m9  .figshare.4742935.v2</ref>. The complete Open Practices Disclosure for this article can be found at <ref type="url" target="http://journals.sagepub.com/doi/suppl/10.1177/0956797617702699">http://journals.sagepub.com/doi/  suppl/10.1177/0956797617702699</ref>. This article has received badges for Open Data and <rs type="person">Open Materials. More</rs> information about the Open Practices badges can be found at <ref type="url" target="https://www.psychologicalscience.org/publications/badges">https://www.psychological  science.org/publications/badges</ref>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_BJ2UTmq">
					<idno type="grant-number">451-16-023</idno>
				</org>
				<org type="funding" xml:id="_FsXBHvk">
					<idno type="grant-number">16-CONV-0002</idno>
				</org>
				<org type="funding" xml:id="_PWHSjvF">
					<idno type="grant-number">11-LABX-0036</idno>
				</org>
				<org type="funding" xml:id="_x4bWtXT">
					<idno type="grant-number">1177/0956797617702699</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Action Editor</head><p>Matthew A. Goldrick served as action editor for this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions</head><p>All the authors contributed to the design of the experiment. S. Mathôt conducted the analyses and wrote the first draft of the manuscript. All the authors contributed to the revision of the manuscript and approved the final version of the manuscript for submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflicting Interests</head><p>The authors declared that they had no conflicts of interest with respect to their authorship or the publication of this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Note</head><p>1. Because of a bug in the experiment, the word pénombre was shown twice; this is why there were slightly more words conveying darkness than words conveying brightness.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Grip force reveals the context sensitivity of language-induced motor activity during &quot;action words&quot; processing: Evidence from sentential negation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Aravena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Delevoye-Turrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Deprez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cheylus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Paulignan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Frak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nazir</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0050287</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">50287</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">lme4: Linear mixed-effects models using &apos;Eigen&apos; and S4 (Version 1.1-12) [Computer software</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maechler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bolker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<ptr target="http://cran.r-project.org/package=lme4" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Perception, action, and word meanings in the human brain: The case from action verbs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bedny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Caramazza</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1749-6632.2011.06013.x</idno>
	</analytic>
	<monogr>
		<title level="j">Annals of the New York Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">1224</biblScope>
			<biblScope unit="page" from="81" to="95" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Keeping a large-pupilled eye on high-level visual processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Binda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">O</forename><surname>Murray</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2014.11.002</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Attention to bright surfaces enhances the pupillary light reflex</title>
		<author>
			<persName><forename type="first">P</forename><surname>Binda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pereverzeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">O</forename><surname>Murray</surname></persName>
		</author>
		<idno type="DOI">10.1523/jneurosci.3440-12.2013</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2199" to="2204" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Normes de concrétude, de valeur d&apos;imagerie, de fréquence subjective et de valence émotionnelle pour 866 mots [Norms for concreteness, imaging value</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bonin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Méot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Malardier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niedenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Capelle-Toczek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>subjective frequency and emotional valence for 866 words</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">L'année</forename><surname>Psychologique</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="655" to="694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Correlations between pupil size and the semantic differential: An experimental paradigm and pilot study</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Ellsworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Helmreich</surname></persName>
		</author>
		<idno type="DOI">10.3758/bf03327922</idno>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="627" to="628" />
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The control of eye fixation by the meaning of spoken language: A new methodology for the realtime investigation of speech perception, memory, and language processing</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Cooper</surname></persName>
		</author>
		<idno type="DOI">10.1016/0010-0285(74)90005-x</idno>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="84" to="107" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">People can understand descriptions of motion without activating visual motion brain regions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dravida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bedny</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2013.00537</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">537</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Action-based language: A theory of language acquisition, comprehension, and production</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Glenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gallese</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2011.04.010</idno>
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="905" to="922" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Grounding language in action</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Glenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Kaschak</surname></persName>
		</author>
		<idno type="DOI">10.3758/bf03196313</idno>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="558" to="565" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Psychological significance of pupillary movements</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Goldwater</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0032456</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="340" to="355" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Somatotopic representation of action words in human motor and premotor cortex</title>
		<author>
			<persName><forename type="first">O</forename><surname>Hauk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Johnsrude</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pulvermuller</surname></persName>
		</author>
		<idno type="DOI">10.1016/s0896-6273(03)00838-9</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="301" to="307" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Perception of motion affects language processing</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Kaschak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Therriault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Yaxley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aveyard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Zwaan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2004.06.005</idno>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="79" to="B89" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Expyriment: A python library for cognitive and neuroscientific experiments</title>
		<author>
			<persName><forename type="first">F</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lindemann</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-013-0390-6</idno>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="416" to="428" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The eye pupil adjusts to imaginary light</title>
		<author>
			<persName><forename type="first">B</forename><surname>Laeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Sulutvedt</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797613503556</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="188" to="197" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evaluating significance in linear mixedeffects models in R</title>
		<author>
			<persName><forename type="first">J</forename><surname>Love</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Selker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marsman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jamil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dropmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename></persName>
		</author>
		<idno type="DOI">10.3758/s13428-016-0809-y</idno>
		<ptr target="https://jasp-stats.org/Luke" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods. Advance online publication</title>
		<imprint>
			<date type="published" when="2015">2015. 2016</date>
		</imprint>
	</monogr>
	<note>JASP (Version 0.7) [Computer software]</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Z</forename><surname>Mahon</surname></persName>
		</author>
		<idno type="DOI">10.1080/23273798.2014.987791</idno>
		<title level="m">What is embodied about cognition? Language, Cognition and Neuroscience</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="420" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A critical look at the embodied cognition hypothesis and a new proposal for grounding conceptual content</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Z</forename><surname>Mahon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Caramazza</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jphysparis.2008.03.004</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Physiology-Paris</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="59" to="70" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A simple way to reconstruct pupil size during eye blinks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mathôt</surname></persName>
		</author>
		<idno type="DOI">10.6084/m9.figshare.688001</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The pupillary light response reflects exogenous attention and inhibition of return</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mathôt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dalmaijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grainger</surname></persName>
		</author>
		<author>
			<persName><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stigchel</surname></persName>
		</author>
		<idno type="DOI">10.1167/14.14.7</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Intrasaccadic perception triggers pupillary constriction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mathôt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Melmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Castet</surname></persName>
		</author>
		<idno type="DOI">10.7717/peerj.1150</idno>
	</analytic>
	<monogr>
		<title level="j">PeerJ</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">1150</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">OpenSesame: An open-source, graphical experiment builder for the social sciences</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mathôt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schreij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Theeuwes</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-011-0168-7</idno>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="314" to="324" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The pupillary response to light reflects the focus of covert visual attention</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mathôt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Linden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grainger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vitu</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0078168</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">78168</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The pupillary light response reflects eye-movement preparation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mathôt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Linden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grainger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vitu</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0038653</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="28" to="35" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">New light on the mind&apos;s eye: The pupillary light response as active vision</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mathôt</surname></persName>
		</author>
		<author>
			<persName><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stigchel</surname></persName>
		</author>
		<idno type="DOI">10.1177/0963721415593725</idno>
	</analytic>
	<monogr>
		<title level="j">Current Directions in Psychological Science</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="374" to="378" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Motion detection and motion verbs: Language affects low-level visual perception</title>
		<author>
			<persName><forename type="first">L</forename><surname>Meteyard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vigliocco</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9280.2007.02016.x</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1007" to="1013" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Coming of age: A review of embodiment and the neuroscience of semantics</title>
		<author>
			<persName><forename type="first">L</forename><surname>Meteyard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Cuadrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vigliocco</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2010.11.002</idno>
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="788" to="804" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Visual motion interferes with lexical decision on motion words</title>
		<author>
			<persName><forename type="first">L</forename><surname>Meteyard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zokaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vigliocco</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2008.07.016</idno>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="732" to="733" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Tracking the allocation of attention using human pupillary oscillations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Naber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2013.00919</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">919</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Perceptual rivalry: Reflexes reveal the gradual nature of visual awareness</title>
		<author>
			<persName><forename type="first">M</forename><surname>Naber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Frassle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Einhauser</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0020910</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">20910</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Lexique 2: A new French lexical database</title>
		<author>
			<persName><forename type="first">B</forename><surname>New</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pallier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brysbaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ferrand</surname></persName>
		</author>
		<idno type="DOI">10.3758/bf03195598</idno>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="516" to="524" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Just out of reach: On the reliability of the action-sentence compatibility effect</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Papesh</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000125</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page" from="116" to="e141" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">How neurons make meaning: Brain mechanisms for embodied and abstract-symbolic semantics</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pulvermüller</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2013.06.004</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="458" to="470" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing</title>
		<author>
			<orgName type="collaboration">R Development Core Team.</orgName>
		</author>
		<ptr target="https://www.r-project.org/index.html" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Version 3.3.2 Computer software</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Neural correlates of partial lexical activation</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Revill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Aslin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Tanenhaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bavelier</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0807054105</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="13111" to="13115" />
			<date type="published" when="2008">2008</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Oculomotor mechanisms activated by imagery and memory: Eye movements to absent objects</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Spivey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Geng</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2013.06.004</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="235" to="241" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A circuit for pupil orienting responses: Implications for cognitive modulation of pupil size</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Munoz</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.conb.2015.03.018</idno>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Neurobiology</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="134" to="140" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Attentional modulation of pupillary light responses by microstimulation of the superior colliculus</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Munoz</surname></persName>
		</author>
		<idno type="DOI">10.1167/16.12.936</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">936</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Embodiment and language comprehension: Reframing the discussion</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Zwaan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2014.02.008</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="229" to="234" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Moving words: Dynamic representations in language comprehension</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Zwaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Yaxley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Aveyard</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cogsci.2004.03.004</idno>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="611" to="619" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Seeing, acting, understanding: Motor resonance in language comprehension</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Zwaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.135.1.1</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
