<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd" xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Emotional Vocalizations Are Cross-Cultural Regardless of Valence research-article2015</title>
				<funder ref="#_TWUZaGE">
					<orgName type="full">Netherlands Organisation for Scientific Research (NWO)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Disa</forename><forename type="middle">A</forename><surname>Sauter</surname></persName>
							<email>d.a.sauter@uva.nl</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Social Psychology</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Frank</forename><surname>Eisner</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Centre for Cognition</orgName>
								<orgName type="department" key="dep2">Cognition and Behaviour</orgName>
								<orgName type="institution" key="instit1">Donders Institute for Brain</orgName>
								<orgName type="institution" key="instit2">Radboud University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Ekman</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">The Paul Ekman Group</orgName>
								<address>
									<settlement>San Francisco</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sophie</forename><forename type="middle">K</forename><surname>Scott</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Institute of Cognitive Neuroscience</orgName>
								<orgName type="institution">University College London</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Social Psychology</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<addrLine>Weesperplein 4</addrLine>
									<postCode>1018 XA</postCode>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Emotional Vocalizations Are Cross-Cultural Regardless of Valence research-article2015</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">59D01ED8DBDAFFEFD922F413083F82A1</idno>
					<idno type="DOI">10.1177/0956797614560771pss.sagepub.</idno>
					<note type="submission">Received 10/22/14; Accepted 10/31/14</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-05-18T17:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Commentary</head><p>The question of whether emotional expressions have universal meanings has been at the center of heated debates for many decades (e.g., <ref type="bibr" target="#b0">Ekman, 1994;</ref><ref type="bibr" target="#b2">Russell, 1994)</ref>. In a recent contribution, <ref type="bibr" target="#b1">Gendron, Roberson, van der Vyver, and Barrett (2014)</ref> took issue with our study of emotional vocalizations, in which we claimed to show that some nonverbal sounds reliably communicate emotional states across cultures <ref type="bibr" target="#b4">(Sauter, Eisner, Ekman, &amp; Scott, 2010)</ref>. In their Study 2, Gendron et al. replicated part of our study (Himba listeners hearing British vocalizations), but analyzed their data in terms of the valance and arousal of the distractors. They found that recognition was not better than chance for most types of distractors and concluded that emotional vocalizations signal valence, but not specific emotions. We welcome their attempted partial replication of our work. Their article has impelled us to reanalyze our original data in more depth. However, given the results of our reanalysis, together with alternative explanations for the results Gendron et al. obtained, we find that their conclusion does not hold.</p><p>In our study <ref type="bibr" target="#b4">(Sauter, Eisner, Ekman, &amp; Scott, 2010)</ref>, participants listened to a series of brief emotion stories. On each trial, they heard two vocalizations: one target (consistent with the story) and one distractor. Our original results, analyzed by emotion but not distractor type, showed cross-cultural recognition of six emotions: Participants selected target vocalizations more often than would be expected by chance. However, three of the four positive emotions included in our study were not reliably recognized by Himba participants listening to British sounds. A fair test of whether recognition performance exceeds chance levels with different types of distractors should include only those emotion categories that participants can recognize at better-than-chance levels, because we made no claims that the other types of vocalizations communicate specific emotional states across cultures. The fact that <ref type="bibr" target="#b1">Gendron et al. (2014)</ref> included these emotions in their analysis resulted in a considerable reduction in overall accuracy (as shown by the particularly low accuracy they found for positive emotions). Our reanalysis therefore excluded target vocalizations of the culture-specific signals of triumph, pleasure, and relief.</p><p>In our original study, we varied distractors systematically, according to whether their perceived valence was the same as or different from that of the target (valence ratings taken from <ref type="bibr" target="#b3">Sauter, Eisner, Calder, &amp; Scott, 2010)</ref>. For each emotion, every participant performed two trials with distractors having the same valence as the target and two trials with distractors having the valence opposite that of the target. 1 We reanalyzed the data from the 29 Himba participants in our original study who had heard British vocalizations, the part of our study that <ref type="bibr" target="#b1">Gendron et al. (2014)</ref> replicated. Each trial was coded for the relationship of the distractor to the target: same valence or different valence. Because surprise is valence neutral, trials in which surprise was either the target or the distractor were removed.</p><p>Following <ref type="bibr" target="#b1">Gendron et al. (2014)</ref>, we calculated the percentage of correct classifications across emotions for each of these trial types (same or different valence), but only for the basic emotions. One-sample t tests comparing performance with chance (50%) revealed that participants' performance was significantly above chance, both when distractors were of the valence opposite that of the target, t(28) = 7.30, p &lt; .001, Cohen's d = 1.36 (mean difference = 27.22, 95% confidence interval, CI, of the difference = [19.58, 34.86]), and when distractors were of the same valence as the target, t(28) = 4.05, p &lt; .001, Cohen's d = 0.75 (mean difference = 13.45, 95% CI of the difference = [6.64, 20.26]; see Fig. <ref type="figure" target="#fig_0">1</ref>).</p><p>What might underlie the difference in results between our study and the study by <ref type="bibr" target="#b1">Gendron et al. (2014)</ref>? As noted, Gendron et al. included culture-specific signals of positive emotions, and this drove down recognition rates. In addition, overall accuracy levels were considerably lower in their study than in ours (mean overall accuracy across all nine emotions in our study was 64.46%; approximate mean overall accuracy based on Fig. <ref type="figure">4</ref> in <ref type="bibr">Gendron et al. was 51%)</ref>. We repeated our analysis including all eight valenced emotions and found that participants' recognition was again significantly better than chance, both when the distractor and target were of opposite valence, t(28) = 8.30, p &lt; .001, Cohen's d = 1.54 (mean difference = 21.37, 95% CI of the difference = [16.09, 26.64]), and when they had the same valence, t(28) = 2.79, p &lt; .01, Cohen's d = 0.52 (mean difference = 6.71, 95% CI of the difference <ref type="bibr">= [1.79, 11.63]</ref>; see Fig. <ref type="figure" target="#fig_0">1</ref>).</p><p>An apparent difference in procedure could account for the poor recognition rates <ref type="bibr" target="#b1">Gendron et al. (2014)</ref> obtained. In our study, each participant was asked, after each story, how the target person was feeling, in order to ensure that the participant had understood the story correctly. This is because in pilot testing, we found that participants would frequently say that they had understood a story, but were unable to explain it when they were asked to. In our study, therefore, we allowed participants to listen several times to a given recorded story (if needed), until they could explain the intended emotion in their own words, before they proceeded to the experimental trials for that story. The inclusion of a rigorous manipulation check with experimenter verification, rather than reliance on participants' reports, was thus crucial. Gendron et al. did not report having included this check, indicating only that participants who wished to were allowed to hear the scenarios again. This raises the possibility that some participants in their study may not have correctly understood the intended emotional states.</p><p>This may also help to explain the perplexing pattern in the data obtained by <ref type="bibr" target="#b1">Gendron et al. (2014)</ref>: Recognition was better than chance only when the distractor matched the target in arousal and not in valence, and not when the distractor differed from the target in both arousal and valence. The authors acknowledged that this finding was unexpected; it does not fit with their account that vocalizations communicate valence-based information.</p><p>In conclusion, we have presented new analyses that show that nonverbal vocalizations communicate specific emotional states, regardless of the valence of the distractor with which they are presented. Furthermore, we have proposed alternative explanations for the failure of Gendron et al. to find this pattern in their data. We hope that this contribution will serve as a useful addition to the debate on what information can be inferred from emotional expressions cross-culturally.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Himba participants' recognition performance (percentage correct) for basic emotions and all valenced emotions, for trials on which the distractor and target were of the same valence and trials on which the distractor and target were of different valence. Error bars denote ±1 SEM.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors would like to thank <rs type="person">Narda Schenk</rs> for assistance.</p></div>
			</div>
			<div type="funding">
<div><head>Funding</head><p>This work was funded by a <rs type="funder">Netherlands Organisation for Scientific Research (NWO)</rs> <rs type="grantName">Veni grant</rs> (<rs type="grantNumber">275-70-033</rs>) to <rs type="person">D. A. Sauter</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_TWUZaGE">
					<idno type="grant-number">275-70-033</idno>
					<orgName type="grant-name">Veni grant</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions</head><p>D. A. Sauter reanalyzed the data and drafted the manuscript. All authors contributed to the writing of the manuscript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflicting Interests</head><p>The authors declared that they had no conflicts of interest with respect to their authorship or the publication of this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Note</head><p>1. In a small number of cases (&lt; 2%), participants completed three trials with distractors of the same valence as the target for one emotion. Note that, if anything, this should have made the task more difficult.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Strong evidence for universals in facial expressions: A reply to Russell's mistaken critique</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.115</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="268" to="287"/>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cultural relativity in perceiving emotion from vocalizations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gendron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roberson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Van Der Vyver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Barrett</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797613517239</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="911" to="920"/>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Is there universal recognition of emotion from facial expression? A review of the cross-cultural studies</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Russell</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.115.1.102</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="102" to="141"/>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Perceptual cues in non-verbal vocal expressions of emotion</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Sauter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Scott</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470211003721642</idno>
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="2251" to="2272"/>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Crosscultural recognition of basic emotions through nonverbal emotional vocalizations</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Sauter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Scott</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0908239106</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="2408" to="2412"/>
			<date type="published" when="2010">2010</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>