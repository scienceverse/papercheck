<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MudrikDimensions of Perception: 3D Objects Are More Readily Detected</title>
				<funder ref="#_bctZSXZ">
					<orgName type="full">Human Frontier Science Program</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Uri</forename><surname>Korisky</surname></persName>
							<email>urikorisky@tauex.tau.ac.il</email>
							<affiliation key="aff1">
								<orgName type="department">School of Psychological Sciences</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liad</forename><surname>Mudrik</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Psychological Sciences</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Sagol School of Neuroscience</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Psychological Sciences</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MudrikDimensions of Perception: 3D Objects Are More Readily Detected</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D76617B97BC34096504B7B83247B3D03</idno>
					<idno type="DOI">10.1177/09567976211010718</idno>
					<note type="submission">Received 11/10/20; Revision accepted 3/3/21 TC</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-06-03T13:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>consciousness</term>
					<term>real life</term>
					<term>affordances</term>
					<term>continuous flash suppression</term>
					<term>action</term>
					<term>open data</term>
					<term>open materials</term>
					<term>preregistered</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Most of our interactions with our environment involve manipulating real 3D objects. Accordingly, 3D objects seem to enjoy preferential processing compared with 2D images, for example, in capturing attention or being better remembered. But are they also more readily perceived? Thus far, the possibility of preferred detection for real 3D objects could not be empirically tested because suppression from awareness has been applied only to on-screen stimuli. Here, using a variant of continuous flash suppression (CFS) with augmented-reality goggles ("real-life" CFS), we managed to suppress both real 3D objects and their 2D representations. In 20 healthy young adults, real objects broke suppression faster than their photographs. Using 3D printing, we also showed in 50 healthy young adults that this finding held only for meaningful objects, whereas no difference was found for meaningless, novel ones (a similar trend was observed in another experiment with 20 subjects, yet it did not reach significance). This suggests that the effect might be mediated by affordances facilitating detection of 3D objects under interocular suppression.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In our daily lives, we navigate in a world filled with objects, yet not much is known about the mechanisms by which real objects are processed. We do know that these mechanisms differ from ones evoked by 2D representations, both behaviorally <ref type="bibr" target="#b23">(Ozana &amp; Ganel, 2019)</ref> and neurally <ref type="bibr" target="#b21">(Marini et al., 2019)</ref>. Three-dimensional objects are also remembered better <ref type="bibr" target="#b30">(Snow et al., 2014)</ref>, valued more than pictures <ref type="bibr" target="#b6">(Bushong et al., 2010)</ref>, less easily habituated as a category than photographs during infancy <ref type="bibr" target="#b14">(Gerhard et al., 2016)</ref>, and learned earlier <ref type="bibr" target="#b10">(DeLoache et al., 2003)</ref>. Thus, it seems that 3D objects enjoy preferential processing over 2D images; this is strengthened by some cases of visual agnosia, in which recognition of objects from pictures is impaired but no impairment is found for real objects (a "real-object advantage"; <ref type="bibr" target="#b8">Chainay &amp; Humphreys, 2001)</ref>. If so, could it be that our perceptual mechanisms are more tuned to consciously detect real objects, akin to how we prioritize other stimulus types (e.g., upright faces, socially relevant stimuli, danger-associated stimuli; for a review, see <ref type="bibr" target="#b13">Gayet et al., 2014)</ref>? If so, this would shed light both on the underlying mechanisms of object processing and on conscious perception.</p><p>In object processing, a key concept is affordances: motor action plans activated by objects, referring to the possible uses or actions that the observer can perform on them <ref type="bibr" target="#b15">(Gibson, 1979)</ref>. Affordances are held to be automatically evoked by objects, even when either the affordances <ref type="bibr" target="#b37">(Vainio et al., 2011)</ref> or the objects <ref type="bibr" target="#b24">(Roche &amp; Chainay, 2017</ref>; for a review, see <ref type="bibr" target="#b3">Borghi &amp; Riggio, 2015)</ref> are task irrelevant. Similarly, increased activation in areas related to functional object and tool manipulation has also been found for objects for which no action is required (for a meta-analysis, see <ref type="bibr" target="#b17">Ishibashi et al., 2016)</ref>. Such activations were even claimed to occur in response to unconsciously presented tools <ref type="bibr" target="#b12">(Fang &amp; He, 2005;</ref><ref type="bibr" target="#b35">Tettamanti et al., 2017)</ref>, yet other studies challenged these claims <ref type="bibr" target="#b25">(Rothkirch &amp; Hesselmann, 2018)</ref>. Thus, it is currently unknown whether affordances can be activated under interocular suppression <ref type="bibr" target="#b32">(Stein et al., 2011)</ref> or whether they can facilitate detection of the afforded object.</p><p>To date, there is only suggestive evidence in that direction: One study <ref type="bibr" target="#b16">(Gomez et al., 2018)</ref> found enhanced attentional capture by 3D-object flankers compared with photograph flankers (akin to the paradigm of <ref type="bibr" target="#b11">Eriksen &amp; Eriksen, 1974)</ref>. Critically, this effect was not found when the real objects were positioned either out of reach or behind a transparent barrier, a common manipulation for decreasing affordance activation <ref type="bibr" target="#b7">(Caggiano et al., 2009)</ref>. Another study <ref type="bibr" target="#b38">(Weller et al., 2019)</ref> reported shorter suppression times for useful tools compared with useless ones, for which subjects do not have motor knowledge.</p><p>Yet for real 3D objects to be more readily detected or enjoy some preferential perceptual status, they should be distinctively processed as different from 2D images even prior to being detected or reported to be detected. Until now, this possibility could not have been tested because the available methods did not allow researchers to test detection of 3D items, as opposed to their pictorial representations. Testing detection requires some method that would make it harder to detect the 3D items or even suppress them from awareness until they break suppression and are detected. Current suppression methods are all based on screen-presented psychophysical manipulations and are therefore limited to 2D, onscreen stimuli (for a review, see <ref type="bibr" target="#b5">Breitmeyer, 2015)</ref> or, recently, to virtual objects <ref type="bibr" target="#b34">(Suzuki et al., 2019)</ref>.</p><p>Here, we used a novel variant of the continuous flash suppression (CFS) paradigm <ref type="bibr" target="#b36">(Tsuchiya &amp; Koch, 2005)</ref>, termed "real-life" CFS <ref type="bibr" target="#b19">(Korisky et al., 2019)</ref>, to uniquely suppress real 3D objects. In CFS, conscious perception of a target stimulus presented to the nondominant eye is suppressed by a series of masks (consisting of Mondrian patterns) presented to the dominant eye <ref type="bibr" target="#b36">(Tsuchiya &amp; Koch, 2005)</ref> until the target stimulus emerges into awareness (for a recent review and discussion, see <ref type="bibr" target="#b31">Stein, 2019)</ref>. In the "real-life" CFS paradigm, augmentedreality goggles are used to present the series of masks directly to the subjects' dominant eye while their nondominant eye is exposed to the real world in front of them. Any object placed in front of the subject can therefore be suppressed from awareness. We first hypothesized that 3D objects would indeed be more readily detected (i.e., reported to break suppression faster) than their 2D photographs; our second hypothesis was that this effect would be driven by affordances. Notably, reanalyzing data from a study validating the method, we already found initial support for the first hypothesis (see Fig. <ref type="figure" target="#fig_0">S1</ref> in the supplementary online material <ref type="bibr">[SOM]</ref> available on OSF at <ref type="url" target="https://osf.io/9gkv4/">https://osf.io/9gkv4/</ref>; based on data obtained by <ref type="bibr" target="#b19">Korisky et al., 2019)</ref>.</p><p>Here, the question was addressed in a series of three experiments. Experiment 1 presented 3D objects and 2D photographs at three levels of representation (color, black and white, and contours), and subjects were asked to report as soon as they detected a stimulus. Threedimensional objects were indeed detected faster than 2D photographs, irrespective of representation level. We reasoned that this effect could be driven by three possible factors: (a) affordances, in line with the literature presented above; (b) depth, that is, 3D objects could emerge faster because of monocular depth cues or lens accommodation <ref type="bibr" target="#b9">(Ciuffreda, 1998)</ref>; or more trivially, (c) differences in reflectivity between the real 3D objects that sometimes included shiny parts and the matteprinted 2D photographs. These might induce low-level differences, known to affect interocular suppression <ref type="bibr" target="#b36">(Tsuchiya &amp; Koch, 2005)</ref>. To arbitrate between these alternative interpretations of the results, in Experiment 2 (preregistration: <ref type="url" target="https://osf.io/wa8g6/">https://osf.io/wa8g6/</ref>), we manipulated object familiarity as well. To do so, we prepared digital 3D models of the intact objects and of scrambled versions of them. This created novel, unfamiliar objects, for which subjects did not have prior motor knowledge, that shared some of the low-level features of the intact objects. These models were then 3D printed, and detection times for them were compared with detection times for their 2D photographs. A marginally significant trend toward faster detection of intact 3D objects, but not of scrambled ones, was found. Finally, in Experiment 3 (preregistration: <ref type="url" target="https://osf.io/vb95f/">https://osf.io/vb95f/</ref>), in which a bigger</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statement of Relevance</head><p>When it comes to visual awareness, not all stimuli are created equal. Some things are more readily perceived than others, and determining which stimuli are more easily detected and why has been an ongoing experimental challenge. Here, we highlight a new type of stimuli that seem to be perceptually favored: real 3D objects. We found that 3D objects are more readily perceived than 2D images and that this effect holds only for intact, and not scrambled, objects. Why might this be? People are able to functionally interact with 3D objects, whereas they cannot do so with 2D images or even scrambled objects. This suggests that the perceptual priority of 3D objects stems, at least in part, from prior motor knowledge of how one interacts with them. This work not only expands our understanding of the factors affecting detection of stimuli but also suggests that the possibility of functional interaction might play a crucial role in perception.</p><p>sample size was used and the distance between subjects and stimuli was reduced (facilitating affordances processing; <ref type="bibr" target="#b18">Kalénine et al., 2016)</ref>, a clear and strong effect in the same direction was obtained. Overall, our results suggest that real 3D objects are more readily perceived and that this might indeed be driven by the activation of affordances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Because the methodology was shared across the three experiments, we jointly describe it below, highlighting differences between experiments where needed. The complete data, stimuli, and analysis code for all experiments are available at <ref type="url" target="https://osf.io/mygt2/">https://osf.io/mygt2/</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subjects</head><p>Ninety subjects participated in three experiments for payment or course credit: 20 participants in Experiment 1 (14 female; age: M = 24.35 years, SD = 3.88; all right handed; sample size in this more exploratory experiment was chosen on the basis of a common practice for exploratory experiments in our laboratory), 20 participants in Experiment 2 (13 female; age: M = 23.35 years, SD = 1.77; all right handed; sample size was selected on the basis of a power analysis on the effect from Experiment 1; see preregistration at <ref type="url" target="https://osf.io/wa8g6/">https://osf  .io/wa8g6/</ref>), and 50 participants in Experiment 3 (29 female; age: M = 24.76 years, SD = 3.48; 47 right handed; sample size was defined by multiplying the sample size of Experiment 2 by 2.5; see <ref type="bibr" target="#b29">Simonsohn, 2015)</ref>.</p><p>Fourteen additional subjects were excluded for not completing the experiment: one in Experiment 1 (incomplete data due to fatigue), four in Experiment 2 (technical issues; discomfort in wearing the augmented-reality goggles, which prevented them from taking the experiment), and nine in Experiment 3 (discomfort, difficulty in achieving fusion, fatigue, technical issues). Their data were accordingly not collected or not observed in any way. Eleven additional subjects who completed the experiment were excluded from the statistical analyses because evidence suggested that they did not follow instructions: two in Experiment 1, one in Experiment 2 (accuracy lower than 75%), and eight in Experiment 3 (low accuracy, abundance of responses quicker than a 250-ms threshold, reporting seeing stimuli on catch trials when no such stimuli were presented). All the above exclusion criteria were preregistered for Experiments 2 and 3. And, importantly, none of these criteria pertain to assessment of awareness levels or have any bearing on the reported effects and, accordingly, should not evoke regression to the mean that might drive the reported effects <ref type="bibr" target="#b28">(Shanks, 2017)</ref>. All subjects signed a consent form and had normal vision or corrected-to-normal vision using contact lenses. They declared no past neurological, attentional, or mental disorders and no current usage of psychiatric medicines. The experiments were approved by the university's ethics committee.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Apparatus</head><p>The apparatus included a computer-controlled "puppet theater," in which the stimulus object was placed, and a pair of augmented-reality goggles (Epson Moverio BT200) worn by the subject. The graphics shown on the augmented-reality goggles were produced by a computer, using MATLAB (Version 2018b; The MathWorks, Natick, MA) with the Psychophysics Toolbox (Version 3; <ref type="bibr" target="#b4">Brainard, 1997)</ref>. The computer was connected wirelessly to the augmented-reality goggles.</p><p>The puppet theater (Fig. <ref type="figure" target="#fig_0">1a</ref>) was built as a whitepainted wooden wall, 1 m wide and 74.5 cm tall. A window, 20 cm wide and 15 cm tall, was cut in the middle of the wall 26 cm from the bottom of the apparatus. Behind this window was a display box, which acted as a stage. A retractable blind separated this box from the window to allow the stage to be hidden between trials. Three LED strips were used to illuminate the stage (Experiment 1: 2.75 cd/m 2 , Experiments 2 and 3: 10 cd/m 2 ). The strips were covered with three layers of parchment paper to avoid highlights that might differ between the 3D and the 2D conditions. In Experiments 1 and 2, the puppet theater was placed 90 cm from the subject, and in Experiment 3, it was 60 cm away, decreasing the window size to 12 cm × 10 cm. Also, to minimize their ability to rely on irrelevant cues to detect stimulus location, we had subjects in Experiment 3 wear passive noise-cancelling headphones (Sennheiser HD 25). White noise was played between trials to prevent hearing the experimenter placing the target stimulus. In addition, to prevent cross-talk between the eyes, we placed a transparent plexiglass cover on top of the augmented-reality goggles that was opaque only in the field presenting the CFS masks. Thus, no information aside from the CFS stimulation could be perceived by the dominant eye.</p><p>Additionally, in Experiments 2 and 3, an LED was set at each corner of the window of the puppet theater. These LEDs assisted subjects in aligning their gaze with the window despite the dim lighting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stimuli</head><p>On-goggles stimuli. Using the goggles, the subject was presented with a fusion frame (~9.6 × 6.4 degrees of visual angle, depending on individual eye disparity) and a fixation cross. During the trial, the "real-life" CFS method (described in detail by <ref type="bibr" target="#b19">Korisky et al., 2019)</ref>  monocularly, to the dominant eye. The Mondrian masks consisted of colorful circles, randomly placed, ranging between 0.12 and 0.84 degrees of visual angle. The circles were of six different colors, all of 100% value and saturation on the hue, saturation, and value (HSV) scale.</p><p>Real-world stimuli. In Experiment 1, 11 real-life common everyday objects, smaller than 15 cm × 10 cm and easily recognizable, were used (see Fig. <ref type="figure">S4</ref> in the SOM).</p><p>The color-photograph stimuli were created by taking photographs of the objects with a Canon 700D camera from both the left and right sides of the stage of the puppet theater. Photos were taken at the same distance as they were presented in the experiment to match the two perspectives in which they appeared to the subject and to mimic as much as possible the illumination conditions and the shading within the stage that would be observed when the 3D objects were placed. The photographs were then professionally manipulated by a digital print designer and printed on matte paper (Epson enhanced) to avoid highlight reflections. The resulting cutouts closely matched the real objects in appearance (see Fig. <ref type="figure">S4</ref>). The black-and-white stimuli were created by reducing the saturation of the colored photographs to zero. The contour stimuli were created by employing a "find edges" filter on the black-and-white stimuli in Adobe Photoshop.</p><p>In Experiment 2, two sets of stimuli were used (for the creation process, see the SOM): Intact stimuli were 10 full-color real-size 3D-printed replicas of 10 objects out of the 11 used in Experiment 1, all smaller than 10 cm × 10 cm. Scrambled stimuli were 3D-printed versions of these same 10 objects that were digitally deformed in various ways to create meaningless nonobjects (for further details, see the SOM). Notably, the main motivation behind the 3D-printing in Experiments 2 and 3 was to minimize all differences in materials and reflectance between the different items and between each item and its photograph. The 3D printing was accordingly done using a uniform matte polymer, which does not reflect highlights (akin to the matte paper on which the 2D photographs were printed). The same procedure as described above was used to prepare 2D representations of all 3D printed models. In Experiment 3, eight out of the 10 stimuli were used (excluding the Rubik's cube and camera, which were too large to fit in the smaller window).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Experiment 1 consisted of 176 trials split evenly across two blocks. In each block, all 11 objects were shown in all possible experimental conditions in a 4 (representation level: real object, color photograph, blackand-white photograph, contours photograph) × 2 (side of stage: left, right) design. Trial order was pseudorandomly set, with the constraint that no value of one of the variables, or combination thereof, would repeat for more than three consecutive trials.</p><p>Experiment 2 consisted of 160 experimental trials split evenly across two blocks. In each block, five intact objects and five scrambled objects were shown in all possible experimental conditions in a 2 (dimensionality: real 3D object, 2D color photograph) × 2 (side of stage: left, right) design. To prevent subjects from forming associations between the scrambled and intact versions of the items, we ensured that each subject saw each item as either intact or scrambled but never both. Five catch trials, in which no stimulus was introduced, were added to each block. Although adding catch trials is less common in typical on-screen breaking-CFS paradigms, here they were needed to minimize false reports of seeing a stimulus on one side when the subject actually just saw the other, empty side of the stage (because as opposed to on-screen CFS, here we could not simply present the stimuli on a uniform gray background, and sometimes the empty stage itself broke suppression, allowing subjects to infer the location of the suppressed stimulus without seeing it). The maximum duration of catch trials was 19.6 s in Experiment 2 and 40 s in Experiment 3.</p><p>Experiment 3 was similar to Experiment 2, except for the following changes: (a) There were only one or two catch trials in each block, and (b) item assignment as intact or scrambled was counterbalanced between subjects so that each item was seen by approximately the same number of subjects in its intact or scrambled forms.</p><p>At the beginning of each block, a short calibration session was conducted to account for differences in subjects' eye disparity (for details, see <ref type="bibr" target="#b19">Korisky et al., 2019)</ref>. All experiments started with a training block of up to 10 trials, using different stimuli from the ones in the experimental trials.</p><p>Before each trial, the experimenter pulled up a blind, hiding the puppet theater stage, and placed a stimulus either on the left or on the right half of the stage. A fixation frame with a white background was subsequently presented binocularly for 2 s. Then, Mondrian masks were presented to the dominant eye for 1 s while the nondominant eye's fixation frame remained white. Within this second, the blind hiding the stage collapsed, exposing the stage to the subject. Importantly, because of the effective opaqueness of the white background and CFS masks, the subject was not yet exposed to the stimulus. Then, the white background of the fixation frame was linearly transformed to black over 1 s, exposing the nondominant eye to the stage. The Mondrian masks were presented to the dominant eye until subjects responded or for a maximum window of 18.6 s (Experiment 1), 19.6 s (Experiment 2), and 60 s (Experiment 3), including the 1 s of opaqueness ramping down. Subjects were asked to report the location of the stimulus as soon as they detected it by pressing the right or left mouse button. Then, the mask disappeared, allowing the subject to see the stage clearly. The blind was lifted by the experimenter, and a new trial began.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical analysis</head><p>All results were false discovery rate (FDR) corrected <ref type="bibr" target="#b1">(Benjamini &amp; Hochberg, 1995)</ref>, collapsed across experiments, unless otherwise specified. Overall, 16 p values were corrected using FDR. Results in the SOM were FDR corrected separately (87 p values). Because of the nonnormal nature of the detection time distributions in our experiments, randomization procedures and tests were employed (this approach was chosen following consultation that we received after the preregistration of Experiment 2; for a detailed description of the original analyses that we planned and the results obtained under these analyses, see the SOM). Each such procedure or test included 10 4 iterations of resampling or reshuffling of the data, respectively. In cases in which 10 4 iterations did not suffice to produce a p value greater than zero in a test (i.e., no permutations yielded an effect as extreme as in the real data), we reran the permutation test with more iterations (10 5 ) in an attempt to obtain a more accurate p value. If this too yielded a p value of zero, we report it as p &lt; 10 -5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Descriptive statistics: confidence intervals (CIs).</head><p>To obtain CIs, we used a bootstrapping procedure. A resampling of trials was done in each iteration, respecting the division into subjects, items, and conditions (i.e., not shuffling across the borders defined by the values of these variables) and not including side of stage (left, right). The statistics were then calculated on the resulting resampled data. The 2.5 and 97.5 percentiles of the resulting distributions were taken as CIs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1.</head><p>Main effect of representation level. An omnibus nonparametric permutation test was conducted. The statistic calculated on the real and permuted data was the sum of squares of the differences between the average detection time for each representation level and the overall detection time across levels. To obtain the distribution of the null hypothesis, whereby representation level has no impact on detection time, we conducted permutations in two different fashions: The first was per-subject swap, in which all trials belonging to a specific representation level were grouped, and their label was randomly shuffled, respecting the division into subjects and items (e.g., for a specific subject, all black-and-white trials in which a light bulb appeared were labeled as contour trials, and so on). The second was across-subjects swap, which was identical to the first permutation method but applied the changed label for all subjects (e.g., all black-and-white trials in which a light bulb appeared were labeled as contour trials for all subjects, and so on). This shuffling type takes into account variance that is common to subjects and items but does not allow for item-by-item analysis (see the SOM).</p><p>To make sure that the effect did not depend on specific items, we conducted a post hoc item-based analysis under the per-subject-swap approach. For each item, all trials in which other items were presented were excluded from the data, and the same omnibus test was performed. Items were considered extreme if their peritem main effect for representation level was extreme in their distribution and if this extremeness survived a local FDR correction, which included only the p values of the per-item effects of this experiment. These extreme items were then excluded, and the grand omnibus test was performed again to determine whether the effect was still obtained without them (see the SOM). For the FDR correction of the results reported in the SOM, the original, nonlocally FDR-corrected p values of each item's effect were used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Post hoc comparison of paired representation-level categories.</head><p>To test differences between specific representation levels, we excluded all trials of other representation levels. Then, the test statistic was the difference between the mean detection time across stimuli and subjects for the two representation levels, using the same permutation procedure performed in the omnibus test.</p><p>Experiments 2 and 3.</p><p>Interaction between intactness and dimensionality. A directional nonparametric test was used to assess the interaction between intactness and dimensionality. The statistic was calculated by subtracting the mean difference between the two dimensionality levels (3D -2D) for intact items from the same difference for scrambled items, respecting the division between subjects and items. In the permutation procedure, all trials belonging to the same dimensionality level were grouped, and their labels were randomly shuffled (2D, 3D). Additionally, the labels of items as intact or scrambled were shuffled, respecting the division between subjects and the counterbalancing (or lack thereof) between them.</p><p>Simple effect of dimensionality within each intactness level. This analysis was exploratory and was conducted separately for intact and scrambled items. The statistic was the mean difference in detection time between the two dimensionality levels (3D -2D), respecting the division between subjects and items. In the permutation procedure, it was determined with a probability of .50 whether the labeling of all the trials of each item as "3D" or "2D" should be inverted, again respecting the division between subjects and items. Here, too, we tested to see whether the simple effects for dimensionality were driven by any one specific item (see the SOM).</p><p>Main effect of dimensionality. This test was done similarly to the above test for the simple effect, except that it was done across all items, irrespective of their intactness. An additional analysis was done, in which variance common to subjects and items was taken into account (acrosssubjects swap). There, in each iteration, for each item, all trials belonging to a certain dimensionality, across all subjects, were treated as one group. Then, for each item, the labels of the two groups were inverted with a probability of .50.</p><p>Effect sizes. Effect-size measures (Cohen's d, η p 2 ) are reported. Although the significance of the corresponding effects was calculated using nonparametric methods, we report parametric effect-size estimations to facilitate interpretation as well as comparability with other findings in the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Trial exclusion</head><p>Following the preregistered criteria, we removed trials in which subjects' responses were wrong (Experiment 1: 6.85% of total trials, n = 239 across all subjects; Experiment 2: 1.75%, n = 56; Experiment 3: 2.2%, n = 175) or faster than 250 ms (Experiment 1: 0.17%, n = 6; Experiment 2: 1.85%, n = 59; Experiment 3: 1.03%, n = 82). Trials in which the subject did not respond at all (no-response trials) were included in the analysis (Experiment 1: 7.22%, n = 252; Experiment 2: 4.45%, n = 142; Experiment 3: 0.98%, n = 78). No-response trials were taken as evidence that suppression lasted at least as long as the duration of the trial. We conducted additional analyses excluding these trials to make sure they did not solely drive the effect (see the SOM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head><p>Detection times in Experiment 1 were compared among four different levels of representation: real 3D objects, 2D color photographs, 2D black-and-white photographs, and 2D contour-only photographs. A nonparametric permutation analysis revealed that detection time differed between the four levels of representations (Fig. <ref type="figure" target="#fig_1">2</ref>): Real 3D objects were detected fastest-main effect of representation level: p &lt; .0005, η p 2 = .37 (for descriptive and inferential statistics, see Tables <ref type="table" target="#tab_0">1</ref> and <ref type="table" target="#tab_1">2</ref>). Post hoc permutation analyses revealed that this effect stemmed solely from shorter detection times for real objects compared with each and every other representation level (all comparisons were Bonferroni-corrected for six possible comparisons between levels). No other two representation levels differed. These effects remained largely the same when we excluded noresponse trials (see the SOM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>On a descriptive level, the results suggested that the difference between 3D and 2D stimuli might be restricted to intact stimuli (Table <ref type="table" target="#tab_2">3</ref> and Fig. <ref type="figure" target="#fig_3">3a</ref>; see also Fig. <ref type="figure">S4a</ref>), yet this trend was only marginally significant and did not survive FDR correction. Post hoc examination of the interaction did not show a significant simple effect of dimensionality for intact items (Table <ref type="table" target="#tab_2">3</ref>; 3D -2D: ΔM = -0.33 s, SD = 0.73, 95% CI = [-0.74, 0.07], uncorrected p = .11, FDR q = 0.23, Cohen's d = 0.45) or for scrambled items (3D -2D: ΔM = 0.2 s, SD = 0.89, 95% CI = [-0.18, 0.59], uncorrected p = .32, d = 0.23). A main effect of dimensionality was not found (3D -2D: ΔM = -0.07 s, SD = 0.66, 95% CI = [-0.34, 0.22], per-subjectsswap analysis: uncorrected p = .65, across-subjectsswap analysis: uncorrected p = .68, d = 0.1). Excluding no-response trials yielded similar findings (see the SOM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3</head><p>A confirmatory permutation analysis revealed a clear interaction between intactness and dimensionality (Table <ref type="table" target="#tab_2">3</ref> and Fig. <ref type="figure" target="#fig_3">3b</ref>; see also Fig. <ref type="figure">S4b</ref>). Post hoc permutation analyses confirmed that the interaction stemmed from a difference between 3D and 2D stimuli for intact items; detection times for intact 3D items were shorter than for their 2D photographs (3D -2D: ΔM = -0.91 s, SD = 2.15, 95% CI = [-1.42, -0.41], uncorrected p &lt; .005, FDR q &lt; 0.01, d = 0.42). This difference was not found for scrambled stimuli; detection times were similar for scrambled 3D objects and their 2D photographs (3D -2D: ΔM = 0.33 s, SD = 2.4, 95% CI = [-0.18, 0.85], uncorrected p = .275, d = 0.14). No main effect of dimensionality was found (3D -2D: ΔM = -0.29 s, SD = 1.74, 95% CI = [-0.65, 0.06], d = 0.17) in the two confirmatory analyses that were preregistered (permuting familiarity of items per subject, per-subject-swap, uncorrected p = .35, or across all subjects, acrosssubjects-swap, uncorrected p = .89; see the Method section; these two comparisons were Bonferroni corrected confidence intervals obtained by bootstrapping. The shape of each violin plot represents the distribution of its values along the y-axis. Above the plot, histograms depict distributions of pairwise differences between every two levels, obtained by bootstrapping. Red lines represent the actual differences. Asterisks mark distributions that exclude zero, which indicates a significant effect (***p &lt; .0005).  <ref type="bibr">[5.36, 5.86]</ref> Note: CI = confidence interval.</p><p>This was found in both Experiments 1 and 3, alongside an insignificant trend in the same direction in Experiment 2. This confirms our first hypothesis that 3D objects are more readily detected and might be perceptually favored over 2D images. Critically, the advantage of 3D stimuli was not found for scrambled, unfamiliar objects that do not elicit stored motor programs for functional use-in line with our second hypothesis.</p><p>Our results thus suggest that affordances might grant real objects higher perceptual priority <ref type="bibr" target="#b38">(Weller et al., 2019)</ref>. Because 3D objects are held to more strongly activate affordances than 2D objects <ref type="bibr" target="#b21">(Marini et al., 2019)</ref> and because intact objects have more affordances than scrambled ones (specifically, stable affordances; <ref type="bibr" target="#b3">Borghi &amp; Riggio, 2015</ref>; see further discussion below), the finding that intact 3D objects, but not scrambled ones, were detected faster implies that affordances could have indeed mediated this effect. Notably, we went to great in line with the preregistration). Excluding no-response trials yielded similar findings (see the SOM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Here, we showed that intact, familiar 3D objects are detected faster than their 2D pictorial representations.   lengths to ensure that reflectivity, shine, color, shading, or highlights would not provide cues for subjects to differentiate between the conditions; this was done to minimize differences that were not related to affordances (although naturally, there might be additional differences that were still unaccounted for; e.g., features of intact 3D objects could be easier to discern from shadows given prior knowledge about these objects).</p><p>If indeed affordances drove the effects, this would put them together with other high-level, semantic properties that were claimed to influence detection (for a review and criticism, see <ref type="bibr" target="#b13">Gayet et al., 2014)</ref>, alongside low-level, physical ones <ref type="bibr" target="#b20">(Levelt, 1965)</ref>. Arguably, affordances might increase the relevance of the stimuli, making them more readily detected. This supports the claim that interaction with our environment is one of the key organizing principles of our visual system <ref type="bibr" target="#b15">(Gibson, 1979)</ref>. More specifically, the perceptual advantage of real objects seems to be driven by stable affordances rather than by variable affordances. Stable affordances represent prior motor knowledge about possible functional interactions with a specific object <ref type="bibr" target="#b3">(Borghi &amp; Riggio, 2015;</ref><ref type="bibr" target="#b22">Osiurak et al., 2017)</ref> and were accordingly more likely to be activated by intact objects than scrambled ones in our experiments. Variable affordances, conversely, solely rely on the physical properties of the object and on the body schema of the observer <ref type="bibr" target="#b22">(Osiurak et al., 2017)</ref>, irrespective of the function of the objects <ref type="bibr" target="#b3">(Borghi &amp; Riggio, 2015)</ref>. Accordingly, they are evoked by novel, unfamiliar objects <ref type="bibr" target="#b38">(Weller et al., 2019)</ref>, which showed no effect in our experiments. Because stable affordances are inherently confounded by familiarity, which also affects detection under interocular suppression <ref type="bibr" target="#b39">(Yuan et al., 2019)</ref>, one could claim that it was familiarity, rather than affordances, that affected detection times. Yet this is less likely because our critical comparison was between 3D and 2D versions of the very same stimuli (that were accordingly just as familiar). Taken together, our results thus suggest that a general activation of the motor system, which would be evoked by both stable and variable affordances (for a review, see <ref type="bibr" target="#b26">Sakreida et al., 2016)</ref>, is not enough to facilitate detection; rather, stored knowledge about the specific usages of the objects, involving related semantic associations <ref type="bibr" target="#b22">(Osiurak et al., 2017)</ref>, is needed to boost detection. The difference between intact and scrambled objects further mitigates concerns about a possible motor explanation of our results, at least to some extent. It could be claimed that the observed effects stem from general motor effects evoked by affordances in a manner that is not specific to the representation of these objects. Under this account, subjects' responses would be faster for real objects not because they were actually detected faster but, rather, because processing a real object in one side evoked its affordances, and these in turn activated the respective motor area, leading to a faster response for that side <ref type="bibr" target="#b0">(Azaad et al., 2019)</ref>. Although the current design does not allow us to exclude this explanation, the fact that the effect seemed to rely on specific motor knowledge that was related to the identity of the object, rather than on variable affordances that activated the motor system in a more general manner, renders it less plausible.</p><p>Can our results serve as evidence for unconscious processing of affordances without awareness? This is indeed a common interpretation for breaking-CFS studies, according to which a difference in detection times reflects differential unconscious processing <ref type="bibr" target="#b13">(Gayet et al., 2014)</ref>. Thus, one might be tempted to interpret our results as reflecting unconscious processing of affordances. Such an interpretation, supporting claims for the automaticity of affordance processing <ref type="bibr" target="#b2">(Binkofski &amp; Buxbaum, 2013;</ref><ref type="bibr" target="#b3">Borghi &amp; Riggio, 2015)</ref>, would accord with findings of enhanced attentional capture by 3D object flankers compared with photographs flankers <ref type="bibr" target="#b16">(Gomez et al., 2018)</ref>, as well as with the shorter suppression times reported for useful tools compared with useless tools <ref type="bibr" target="#b38">(Weller et al., 2019)</ref>. Although this is admittedly a possible interpretation of the results, the current design does not allow us to make such a claim. Breaking-CFS studies simply do not allow disentangling unconscious processing from postperceptual processing <ref type="bibr" target="#b13">(Gayet et al., 2014;</ref><ref type="bibr" target="#b31">Stein, 2019;</ref><ref type="bibr" target="#b32">Stein et al., 2011)</ref>. A recently published work clearly demonstrated how breaking-CFS measures might be conflated between conscious and unconscious processes, reflecting general differences in detectability rather than unconsciously driven processes <ref type="bibr" target="#b33">(Stein &amp; Peelen, 2021)</ref>. Accordingly, the results of this study cannot be used as the basis for claims of unconscious processing of affordances (nor was the study designed to test such claims). However, they do imply that such unconscious processing is at least possible, calling for future experiments to directly test this option using the "real-life" CFS method <ref type="bibr" target="#b19">(Korisky et al., 2019)</ref>. Such a study could then present real objects as primes while keeping their visibility at zero throughout the experiment and measure their effect on congruent and incongruent subsequent targets. A convincing control condition in such an experiment would be placing a transparent barrier between the subject and the prime, as has been done in other experiments to manipulate affordances <ref type="bibr" target="#b7">(Caggiano et al., 2009;</ref><ref type="bibr" target="#b16">Gomez et al., 2018)</ref>. Our study further opens the gate to two additional research questions. First, what could be the underlying mechanism that drives the effect, given that information is arriving only monocularly during CFS? This could, potentially, rest on monocular depth cues-for example, blur cues <ref type="bibr" target="#b9">(Ciuffreda, 1998)</ref> or eye-movement-induced parallax. Second, to what extent do our results depend on the specific stimulus set we used (i.e., can they be obtained using different and possibly larger stimulus sets)? Going beyond the specific results obtained here and their possible interpretation, this study joins other works in the cognitive sciences in using more ecological, lifelike stimuli and tasks. Such realism has been claimed to evoke more prominent, and sometimes even different, processing than the one evoked by well-controlled representations (Shamay-Tsoory &amp; Mendelsohn, 2019). Thus far, using such stimuli in the study of consciousness was a great challenge given the limitations of current methods. Yet the "real-life" CFS methodology provides a compelling and easy way to do so with practically no adjustment of the properties of the real stimuli used, except for luminosity or contrast.</p><p>In conclusion, we present evidence that real objects enjoy a perceptual advantage over realistic photographs, having facilitated access to awareness. However, this prioritization occurs only when these objects are familiar to the observer. We therefore suggest that it is stored motor representations, or stable affordances, that drive the effect by granting real objects priority in detection, emphasizing the importance of action in perception. The use of "real-life" CFS for suppressing real 3D objects from conscious perception further paves the way for future studies to explore the limits of conscious and unconscious processing of the external world.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transparency</head><p>Action Editor: Krishnankutty Sathian Editor: Patricia J. Bauer</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The setup, paradigm, and types of stimuli used in the experiments. Stimuli were presented to subjects in a "puppet theater" (a; schematic adapted with permission from Korisky et al., 2019). The subject laid his or her head on a chin rest, wearing the augmented-reality goggles, and responded using a mouse. The puppet theater consisted of a display box embedded within a white wall that hid the experimenter. A retractable blind was used to hide the display box between trials. In Experiments 2 and 3, an LED was placed at each corner of the display box to mark the window's position. Across the time course of a trial in Experiments 1, 2, and 3 (b), stimuli were presented to the nondominant eye while Mondrian masks were presented to the dominant eye. The leftmost column shows the state of the puppet theater across a trial, and the rightmost column illustrates subjective perception. Example stimuli used in Experiment 1 (c) are shown from each of the four representation levels. Example stimuli used in Experiments 2 and 3 (d) are shown for levels of intactness (intact vs. scrambled) and dimensionality (2D vs. 3D).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Detection time in Experiment 1. The violin plots show detection time for each representation level. Dots represent single subjects, horizontal lines show group means, and vertical lines depict 95%confidence intervals obtained by bootstrapping. The shape of each violin plot represents the distribution of its values along the y-axis. Above the plot, histograms depict distributions of pairwise differences between every two levels, obtained by bootstrapping. Red lines represent the actual differences. Asterisks mark distributions that exclude zero, which indicates a significant effect (***p &lt; .0005).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc>Note: Each cell shows the mean (given in seconds), standard deviation (in parentheses), and 95% confidence interval (CI; in brackets). Interaction terms between intactness and dimensionality, calculated as ([intact (3D -2D)] -[scrambled (3D -2D)]), were as follows-Experiment 2: ΔM = -0.53 s, SD = 0.96, 95% CI = [-1.1, 0.03], uncorrected p = .063, η p 2 = .25; Experiment 3: ΔM = 1.24 s, SD = 2.95, 95% CI = [-1.96, -0.54], p = .0096, η p 2 = .15.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Reaction time (RT) difference between 3D and 2D representations (2D -3D), separately for intact and scrambled objects in (a) Experiment 2 and (b) Experiment 3. Dots represent single subjects, horizontal lines show group means, and vertical lines depict 95% confidence intervals obtained by bootstrapping. The shape of each violin plot represents the distribution of its values along the y-axis. Asterisks indicate a significant difference from zero (*p &lt; .01) or a significant difference between RT differences (2D -3D) for intact and scrambled objects (**p &lt; .001).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Mean Detection Time (in Seconds) for Each Representation Level in Experiment 1</figDesc><table><row><cell>Representation level</cell><cell>M</cell><cell>SD</cell><cell>95% CI</cell></row><row><cell>Contour</cell><cell>6.69</cell><cell>2.62</cell><cell>[6.41, 6.96]</cell></row><row><cell>Black and white</cell><cell>6.59</cell><cell>2.66</cell><cell>[6.32, 6.87]</cell></row><row><cell>Color</cell><cell>6.78</cell><cell>2.46</cell><cell>[6.51, 7.05]</cell></row><row><cell>Real objects</cell><cell>5.60</cell><cell>2.29</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Detection Time Differences Between Representation Levels in Experiment 1 : Means are given in seconds. Daggers indicate nonsignificant p values and are shown here uncorrected for multiple comparisons (false-discovery rate) for evaluation purposes, though they were used for the overall correction. CI = confidence interval.</figDesc><table><row><cell>Comparison</cell><cell>M</cell><cell>SD</cell><cell>95% CI</cell><cell>p</cell><cell>d</cell></row><row><cell>Contour -black and white</cell><cell>0.09</cell><cell>0.93</cell><cell>[-0.28, 0.49]</cell><cell>.66  †</cell><cell>0.10</cell></row><row><cell>Color -contour</cell><cell>0.09</cell><cell>1.04</cell><cell>[-0.3, 0.47]</cell><cell>.72  †</cell><cell>0.08</cell></row><row><cell>Color -black and white</cell><cell>0.18</cell><cell>0.72</cell><cell>[-0.21, 0.58]</cell><cell>.42  †</cell><cell>0.25</cell></row><row><cell>Contour -real</cell><cell>1.08</cell><cell>1.26</cell><cell>[0.71, 1.45]</cell><cell>&lt; .0005</cell><cell>0.86</cell></row><row><cell>Black and white -real</cell><cell>0.99</cell><cell>1.05</cell><cell>[0.61, 1.36]</cell><cell>&lt; .0005</cell><cell>0.94</cell></row><row><cell>Color -real</cell><cell>1.17</cell><cell>1.15</cell><cell>[0.81, 1.54]</cell><cell>&lt; .0005</cell><cell>1.02</cell></row></table><note><p>Note</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Means for Scrambled and Intact 2D and 3D Stimuli in Experiments 2 and 3</figDesc><table><row><cell></cell><cell cols="2">Intactness</cell><cell></cell></row><row><cell>Experiment and</cell><cell></cell><cell></cell><cell></cell></row><row><cell>dimensionality</cell><cell>Scrambled</cell><cell>Intact</cell><cell>Combined</cell></row><row><cell>Experiment 2</cell><cell></cell><cell></cell><cell></cell></row><row><cell>2D</cell><cell>5.29 (3.08) [5.03, 5.56]</cell><cell>5.45 (2.93) [5.15, 5.76]</cell><cell>5.37 (2.97) [5.17, 5.57]</cell></row><row><cell>3D</cell><cell>5.49 (3.41) [5.21, 5.77]</cell><cell>5.12 (2.77) [4.86, 5.38]</cell><cell>5.31 (3.05) [5.11, 5.50]</cell></row><row><cell>Combined</cell><cell>5.39 (3.22) [5.20, 5.58]</cell><cell>5.28 (2.83) [5.09, 5.48]</cell><cell></cell></row><row><cell>Experiment 3</cell><cell></cell><cell></cell><cell></cell></row><row><cell>2D</cell><cell>7.39 (4.81) [7.04, 7.76]</cell><cell>8.17 (5.15) [7.80, 8.55]</cell><cell>7.78 (4.79) [7.53, 8.04]</cell></row><row><cell>3D</cell><cell>7.72 (4.72) [7.36, 8.10]</cell><cell>7.26 (4.32) [6.93, 7.61]</cell><cell>7.49 (4.37) [7.24, 7.74]</cell></row><row><cell>Combined</cell><cell>7.56 (4.61) [7.30, 7.82]</cell><cell>7.71 (4.63) [7.47, 7.97]</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The research was generously aided by <rs type="institution">Stratasys</rs>, who printed all the 3D models used in the study. We thank <rs type="person">David Steinberg</rs> for providing statistical consultation and <rs type="person">Nitzan Censor</rs>, <rs type="person">Shlomit Yuval-Greenberg</rs>, and <rs type="person">Roy Mukamel</rs> for their feedback on earlier versions of the manuscript. We also thank <rs type="person">Itay Lazarovitch</rs> and <rs type="person">Alexander Kolominsky</rs> for their help in photographing the objects.</p></div>
			</div>
			<div type="funding">
<div><head>Funding</head><p>This work was funded by The <rs type="funder">Human Frontier Science Program</rs> (<rs type="grantNumber">CDA00061-2018</rs>). L. Mudrik is a <rs type="grantName">CIFAR Tanenbaum Fellow in</rs> the <rs type="programName">Brain, Mind, and Consciousness program</rs>.</p></div>
<div><head>Open Practices</head><p>All data, analysis code, stimuli, and supplementary online material have been made publicly available via OSF and can be accessed at <ref type="url" target="https://osf.io/mygt2/">https://osf.io/mygt2/</ref>. The design and analysis plans for Experiments 2 and 3 were preregistered at <ref type="url" target="https://osf.io/wa8g6/">https://osf.io/wa8g6/</ref> and <ref type="url" target="https://osf.io/vb95f/">https://osf.io/vb95f/</ref>, respectively. Some analyses for Experiment 2 differed from the preregistered ones (see Statistical Analyses for details; results of the original analyses are reported in the supplementary online material). This article has received the badges for Open Data, Open Materials, and Preregistration. More information about the Open Practices badges can be found at <ref type="url" target="http://www.psychologicalscience.org/publications/badges">http://www.psychologicalscience.org/publica  tions/badges</ref>.</p><p>TC</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_bctZSXZ">
					<idno type="grant-number">CDA00061-2018</idno>
					<orgName type="grant-name">CIFAR Tanenbaum Fellow in</orgName>
					<orgName type="program" subtype="full">Brain, Mind, and Consciousness program</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions</head><p>Both authors designed the research. U. Korisky conducted the research and analyzed the data. Both authors wrote the manuscript and approved the final version for submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflicting Interests</head><p>The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A meta-analysis of the object-based compatibility effect</title>
		<author>
			<persName><forename type="first">S</forename><surname>Azaad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Laham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shields</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2019.04.028</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2019.04.028" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">190</biblScope>
			<biblScope unit="page" from="105" to="127" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Controlling the false discovery rate: A practical and powerful approach to multiple testing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.2517-6161.1995.tb02031.x</idno>
		<ptr target="https://doi.org/10.1111/j.2517-6161.1995.tb02031.x" />
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society B: Methodological</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="289" to="300" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Two action systems in the human brain</title>
		<author>
			<persName><forename type="first">F</forename><surname>Binkofski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Buxbaum</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bandl.2012.07.007</idno>
		<ptr target="https://doi.org/10.1016/j.bandl.2012.07.007" />
	</analytic>
	<monogr>
		<title level="j">Brain and Language</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page" from="222" to="229" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Stable and variable affordances are both automatic and flexible</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Borghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Riggio</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2015.00351</idno>
		<ptr target="https://doi.org/10.3389/fnhum.2015.00351" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">351</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Psychophysics Toolbox</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Brainard</surname></persName>
		</author>
		<idno type="DOI">10.1163/156856897X00357</idno>
		<ptr target="https://doi.org/10.1163/156856897X00357" />
	</analytic>
	<monogr>
		<title level="j">Spatial Vision</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="433" to="436" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Psychophysical &quot;blinding&quot; methods reveal a functional hierarchy of unconscious visual processing</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Breitmeyer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.concog.2015.01.012</idno>
		<ptr target="https://doi.org/10.1016/j.concog.2015.01.012" />
	</analytic>
	<monogr>
		<title level="j">Consciousness and Cognition</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="234" to="250" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Pavlovian processes in consumer choice: The physical presence of a good increases willingness-to-pay</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bushong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Camerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
		<idno type="DOI">10.1257/aer.100.4.1556</idno>
		<ptr target="https://doi.org/10.1257/aer.100.4.1556" />
	</analytic>
	<monogr>
		<title level="j">American Economic Review</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="1556" to="1571" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mirror neurons differentially encode the peripersonal and extrapersonal space of monkeys</title>
		<author>
			<persName><forename type="first">V</forename><surname>Caggiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fogassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rizzolatti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Thier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casile</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1166818</idno>
		<ptr target="https://doi.org/10.1126/science.1166818" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">324</biblScope>
			<biblScope unit="page" from="403" to="406" />
			<date type="published" when="2009">2009. 5925</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The real-object advantage in agnosia: Evidence for a role of surface and depth information in object recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chainay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Humphreys</surname></persName>
		</author>
		<idno type="DOI">10.1080/02643290042000062</idno>
		<ptr target="https://doi.org/10.1080/02643290042000062" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Neuropsychology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="175" to="191" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Accommodation, the pupil, and presbyopia</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Ciuffreda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Borish&apos;s clinical refraction</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Benjamin</surname></persName>
		</editor>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="77" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The origins of pictorial competence</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Deloache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Pierroutsakos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Uttal</surname></persName>
		</author>
		<idno type="DOI">10.1111/1467-8721.01244</idno>
		<ptr target="https://doi.org/10.1111/1467-8721.01244" />
	</analytic>
	<monogr>
		<title level="j">Current Directions in Psychological Science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="114" to="118" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Effects of noise letters upon the identification of a target letter in a nonsearch task</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Eriksen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Eriksen</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03203267</idno>
		<ptr target="https://doi.org/10.3758/BF03203267" />
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="143" to="149" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cortical responses to invisible objects in the human dorsal and ventral pathways</title>
		<author>
			<persName><forename type="first">F</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn1537</idno>
		<ptr target="https://doi.org/10.1038/nn1537" />
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1380" to="1385" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Breaking continuous flash suppression: Competing for consciousness on the pre-semantic battlefield</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gayet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van Der Stigchel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L E</forename><surname>Paffen</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2014.00460</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2014.00460" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">460</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Distinct visual processing of real objects and pictures of those objects in 7-to 9-month-old infants</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Gerhard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Culham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schwarzer</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2016.00827</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2016.00827" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">827</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">The ecological approach to visual perception</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Gibson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>Houghton, Mifflin</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Grasp able objects grab attention more than images do</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Skiba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Snow</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797617730599</idno>
		<ptr target="https://doi.org/10.1177/0956797617730599" />
	</analytic>
	<monogr>
		<title level="j">Psy chological Science</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="206" to="218" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The neural network for tool-related cognition: An activation likelihood estimation meta-analysis of 70 neuroimaging contrasts</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ishibashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pobric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>&amp; Lambon Ralph</surname></persName>
		</author>
		<idno type="DOI">10.1080/02643294.2016.1188798</idno>
		<ptr target="https://doi.org/10.1080/02643294.2016.1188798" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Neuropsychology</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="241" to="256" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Conflict between object structural and functional affordances in peripersonal space</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kalénine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wamain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Decroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Coello</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2016.06.006</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2016.06.006" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Reallife&quot; continuous flash suppression (CFS)-CFS with realworld objects using augmented reality goggles</title>
		<author>
			<persName><forename type="first">U</forename><surname>Korisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hirschhorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mudrik</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-018-1162-0</idno>
		<ptr target="https://doi.org/10.3758/s13428-018-1162-0" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="2827" to="2839" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">On binocular rivalry</title>
		<author>
			<persName><forename type="first">W</forename><surname>Levelt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965">1965</date>
		</imprint>
		<respStmt>
			<orgName>Institute for Perception RVO-TNO Soesterberg</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Distinct visuo-motor brain dynamics for real-world objects versus planar images</title>
		<author>
			<persName><forename type="first">F</forename><surname>Marini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Breeding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Snow</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2019.02.026</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2019.02.026" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">195</biblScope>
			<biblScope unit="page" from="232" to="242" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">What is an affordance? 40 years later</title>
		<author>
			<persName><forename type="first">F</forename><surname>Osiurak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rossetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Badets</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neubiorev.2017.04.014</idno>
		<ptr target="https://doi.org/10.1016/j.neubiorev.2017.04.014" />
	</analytic>
	<monogr>
		<title level="j">Neuroscience and Biobehavioral Reviews</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="403" to="417" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Weber&apos;s law in 2D and 3D grasping</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ozana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ganel</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00426-017-0913-3</idno>
		<ptr target="https://doi.org/10.1007/s00426-017-0913-3" />
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="977" to="988" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Is there a competition between functional and situational affordances during action initiation with everyday tools</title>
		<author>
			<persName><forename type="first">K</forename><surname>Roche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chainay</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2017.01073</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2017.01073" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">1073</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">No evidence for dorsal-stream-based priming under continuous flash suppression</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rothkirch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hesselmann</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.concog.2018.05.011</idno>
		<ptr target="https://doi.org/10.1016/j.concog.2018.05.011" />
	</analytic>
	<monogr>
		<title level="j">Consciousness and Cognition</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="84" to="94" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Affordance processing in segregated parieto-frontal dorsal stream sub-pathways</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sakreida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Effnert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Menz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jirak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ziemke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Borghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Binkofski</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neubiorev.2016.07.032</idno>
		<ptr target="https://doi.org/10.1016/j.neubiorev.2016.07.032" />
	</analytic>
	<monogr>
		<title level="j">Neuroscience and Biobehavioral Reviews</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="89" to="112" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Real-life neuroscience: An ecological approach to brain and behavior research</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Shamay-Tsoory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mendelsohn</surname></persName>
		</author>
		<idno type="DOI">10.1177/1745691619856350</idno>
		<ptr target="https://doi.org/10.1177/1745691619856350" />
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="841" to="859" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Regressive research: The pitfalls of post hoc data selection in the study of unconscious mental processes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-016-1170-y</idno>
		<ptr target="https://doi.org/10.3758/s13423-016-1170-y" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="752" to="775" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Small telescopes: Detectability and the evaluation of replication results</title>
		<author>
			<persName><forename type="first">U</forename><surname>Simonsohn</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797614567341</idno>
		<ptr target="https://doi.org/10.1177/0956797614567341" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="559" to="569" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Real-world objects are more memorable than photographs of objects</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Skiba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Coleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Berryhill</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2014.00837</idno>
		<ptr target="https://doi.org/10.3389/fnhum.2014.00837" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">837</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The breaking continuous flash suppression paradigm: Review, evaluation, and outlook</title>
		<author>
			<persName><forename type="first">T</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780429469688-1</idno>
		<ptr target="https://doi.org/10.4324/9780429469688-1" />
	</analytic>
	<monogr>
		<title level="m">Transitions between consciousness and unconsciousness</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Hesselmann</surname></persName>
		</editor>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Breaking continuous flash suppression: A new measure of unconscious processing during interocular suppression</title>
		<author>
			<persName><forename type="first">T</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Hebart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sterzer</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2011.00167</idno>
		<ptr target="https://doi.org/10.3389/fnhum.2011.00167" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">167</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Dissociating conscious and unconscious influences on visual detection effects</title>
		<author>
			<persName><forename type="first">T</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Peelen</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-020-01004-5</idno>
		<ptr target="https://doi.org/10.1038/s41562-020-01004-5" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="612" to="624" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Sensorimotor contingency modulates breakthrough of virtual 3D objects during a breaking continuous flash suppression paradigm</title>
		<author>
			<persName><forename type="first">K</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Schwartzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Augusto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Seth</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2019.03.003</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2019.03.003" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="page" from="95" to="107" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Unaware processing of tools in the neural system for object-directed action representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tettamanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Conca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Falini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Perani</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.1061-17.2017</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.1061-17.2017" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">44</biblScope>
			<biblScope unit="page" from="10712" to="10724" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Continuous flash suppression reduces negative afterimages</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tsuchiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn1500</idno>
		<ptr target="https://doi.org/10.1038/nn1500" />
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1096" to="1101" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Motor inhibition associated with the affordance of briefly displayed objects</title>
		<author>
			<persName><forename type="first">L</forename><surname>Vainio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hammarén</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rekolainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riskilä</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470218.2010.538221</idno>
		<ptr target="https://doi.org/10.1080/17470218.2010.538221" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1094" to="1110" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Semantic knowledge enhances conscious awareness of visual objects</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rabovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Rahman</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn_a_01404</idno>
		<ptr target="https://doi.org/10.1162/jocn_a_01404" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1216" to="1226" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">One of us? How facial and symbolic cues to own-versus other-race membership influence access to perceptual awareness</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">V</forename><surname>Bodenhausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2018.12.003</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2018.12.003" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">184</biblScope>
			<biblScope unit="page" from="19" to="27" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
