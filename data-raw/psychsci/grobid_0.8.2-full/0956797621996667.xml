<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Charged With a Crime: The Neuronal Signature of Processing Negatively Evaluated Faces Under Different Attentional Conditions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sebastian</forename><surname>Schindler</surname></persName>
							<email>sebastian.schindler@ukmuenster.de</email>
							<affiliation key="aff1">
								<orgName type="department">Institute of Medical Psychology and Systems Neuroscience</orgName>
								<orgName type="institution">University of Münster</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Otto Creutzfeldt Center for Cognitive and Behavioral Neuroscience</orgName>
								<orgName type="institution">University of Münster</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maximilian</forename><surname>Bruchmann</surname></persName>
							<email>maximilian.bruchmann@uni-muenster.de</email>
							<affiliation key="aff1">
								<orgName type="department">Institute of Medical Psychology and Systems Neuroscience</orgName>
								<orgName type="institution">University of Münster</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Otto Creutzfeldt Center for Cognitive and Behavioral Neuroscience</orgName>
								<orgName type="institution">University of Münster</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Claudia</forename><surname>Krasowski</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Medical Psychology and Systems Neuroscience</orgName>
								<orgName type="institution">University of Münster</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>Moeck</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Medical Psychology and Systems Neuroscience</orgName>
								<orgName type="institution">University of Münster</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Straube</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Medical Psychology and Systems Neuroscience</orgName>
								<orgName type="institution">University of Münster</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Otto Creutzfeldt Center for Cognitive and Behavioral Neuroscience</orgName>
								<orgName type="institution">University of Münster</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Medical Psychology and Systems Neuroscience</orgName>
								<orgName type="department" key="dep2">Institute of Medical Psychology and Systems Neuroscience</orgName>
								<orgName type="institution" key="instit1">University of Münster</orgName>
								<orgName type="institution" key="instit2">University of Münster</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Charged With a Crime: The Neuronal Signature of Processing Negatively Evaluated Faces Under Different Attentional Conditions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C830FD548B81F1616BB52B9CA0DDFA68</idno>
					<idno type="DOI">10.1177/0956797621996667</idno>
					<note type="submission">Received 3/27/20; Revision accepted 1/8/21</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-06-03T13:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>affective person knowledge</term>
					<term>attention task</term>
					<term>attention to emotional information</term>
					<term>feature-based attention</term>
					<term>EEG</term>
					<term>ERP</term>
					<term>open data</term>
					<term>preregistered</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Faces constitute a significant part of human communication because they transfer nonverbal signals to other people and transmit rich information about a person, including unique identity information. A growing body of research shows that contextual effects influence how we interpret faces <ref type="bibr" target="#b38">(Wieser &amp; Brosch, 2012)</ref>, including during instructed threat, in which by merely informing participants that a face will be associated with a shock, persistent threat-related effects are found <ref type="bibr" target="#b3">(Bublatzky et al., 2014)</ref>. These effects modulate specific eventrelated potentials (ERPs; see <ref type="bibr" target="#b30">Schellhaas et al., 2020)</ref>. Such threat signals can likewise be elicited by associating a neutral face with danger because of highly negative biographical knowledge, typically conveyed in various media outlets. Although research has shown that evaluative knowledge modulates ERPs, findings regarding the time course of such effects are conflicting, leading to an ongoing debate on whether early (rather automatic) or late (controlled) stages of processing are 996667P SSXXX10.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>modulated (e.g., see Abdel <ref type="bibr" target="#b0">Rahman, 2011;</ref><ref type="bibr" target="#b1">Baum et al., 2020;</ref><ref type="bibr" target="#b23">McCrackin &amp; Itier, 2018)</ref>.</p><p>Early and late ERP components represent distinct stages of face processing (for a review, see <ref type="bibr" target="#b35">Schweinberger &amp; Neumann, 2016)</ref>. The occipitally scored P1 is known to reflect early stages of stimulus detection and discrimination (e.g., <ref type="bibr" target="#b21">Luck &amp; Hillyard, 1994)</ref>. The following N170 is viewed as a structural encoding component, and larger amplitudes are reported for faces compared with objects at this component <ref type="bibr" target="#b7">(Eimer, 2011)</ref>. The subsequent early posterior negativity (EPN) is observed as a differential negativity when contrasting emotional and neutral expressions and has been related to early attentional selection processes <ref type="bibr" target="#b34">(Schupp et al., 2004)</ref>. The EPN indexes sensitivity to salient emotional information <ref type="bibr" target="#b16">( Junghöfer et al., 2001)</ref> and is modulated by emotional expressions partially independent of attentional resources (e.g., see <ref type="bibr" target="#b9">Frühholz et al., 2011;</ref><ref type="bibr" target="#b12">Hammerschmidt et al., 2018;</ref><ref type="bibr" target="#b15">Itier &amp; Neath-Tavares, 2017;</ref><ref type="bibr" target="#b26">Rellecke et al., 2012;</ref><ref type="bibr" target="#b28">Schacht &amp; Sommer, 2009)</ref>. Finally, the late positive potential (LPP) indicates elaborated stimulus evaluation and controlled attention processes, particularly when the appraisal of affective meaning is involved (e.g., see <ref type="bibr" target="#b11">Hajcak et al., 2009;</ref><ref type="bibr" target="#b33">Schupp et al., 2006)</ref>.</p><p>Evaluative person knowledge has been shown to modulate early and late ERPs. However, experimental tasks and examined ERPs vary considerably, and the resulting findings are conflicting. These experiments included tasks that required responding to an oddball stimulus <ref type="bibr" target="#b40">(Xu et al., 2016)</ref>, discriminating gender <ref type="bibr" target="#b22">(Luo et al., 2016)</ref>, recollecting nationality information <ref type="bibr" target="#b37">(Suess et al., 2014)</ref>, discriminating semantic features (wellknown faces vs. new faces, nationality, and names of the individuals pictured; Abdel Rahman, 2011), or responding to evaluative emotional information <ref type="bibr" target="#b1">(Baum et al., 2020;</ref><ref type="bibr" target="#b17">Kissler &amp; Strehlow, 2017)</ref>. Only one study examined the P1, and it showed no evaluative effects <ref type="bibr" target="#b22">(Luo et al., 2016)</ref>, whereas there are two conflicting findings regarding the N170 <ref type="bibr" target="#b22">(Luo et al., 2016;</ref><ref type="bibr" target="#b40">Xu et al., 2016)</ref>. One study used a passive-viewing task and observed no effects <ref type="bibr" target="#b22">(Luo et al., 2016;</ref><ref type="bibr" target="#b40">Xu et al., 2016)</ref>, whereas the other study required participant to explicitly attend to the gender of faces and found an increased N170 <ref type="bibr" target="#b22">(Luo et al., 2016)</ref>. It remains an open question whether conflicting findings depend on differences in feature-based attention to faces and emotional information of faces. For later components, larger EPN amplitudes were found for faces paired with negative compared with neutral biographical information <ref type="bibr" target="#b0">(Abdel Rahman, 2011;</ref><ref type="bibr" target="#b22">Luo et al., 2016;</ref><ref type="bibr" target="#b37">Suess et al., 2014;</ref><ref type="bibr" target="#b40">Xu et al., 2016)</ref>. However, other studies observed no effect of negative evaluative information at the EPN level <ref type="bibr" target="#b1">(Baum et al., 2020;</ref><ref type="bibr" target="#b17">Kissler &amp; Strehlow, 2017</ref>; for unfamiliar faces, see Abdel <ref type="bibr" target="#b0">Rahman, 2011)</ref>. For the LPP, a majority of the studies show larger amplitudes for faces with negative associations <ref type="bibr" target="#b0">(Abdel Rahman, 2011;</ref><ref type="bibr" target="#b1">Baum et al., 2020;</ref><ref type="bibr" target="#b17">Kissler &amp; Strehlow, 2017;</ref><ref type="bibr" target="#b40">Xu et al., 2016</ref>; but see <ref type="bibr" target="#b22">Luo et al., 2016)</ref>. In summary, studies show that evaluative information modulates ERPs but provide a mixed picture of which information-processing stages are affected. Research on emotional expressions showed that feature-based attention to the emotional information is crucial for late modulations, whereas early components are less vulnerable to a competing task <ref type="bibr" target="#b26">(Rellecke et al., 2012;</ref><ref type="bibr">Schindler, Bruchmann, et al., 2020)</ref>. Whether this holds true for faces associated with evaluative information is unknown.</p><p>Because ERPs index distinct stages of processing and these stages depend on available resources, studies in which task conditions are systematically varied might resolve the inconsistent findings during the processing of faces with acquired emotional meaning. In this preregistered study (<ref type="url" target="https://osf.io/erkdt">https://osf.io/erkdt</ref>), we examined how feature-based attention modulates evaluative person knowledge for early (P1, N170), midlatency (EPN), and late (LPP) ERPs. Participants were required to (a)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statement of Relevance</head><p>Humans are highly sensitive to individual faces that have been associated with negative information. In this research, we asked how our brain differentiates individual human faces on the basis of relevant biographic information, such as that provided by newspaper headlines. We gave adult participants the task of responding to faces, some of which we associated with a brutal crime. While they viewed the faces, we recorded electroencephalograms (EEGs). Very early in the viewing period, we found an attention-independent potentiation of brain responses as participants processed the faces of supposed criminals. When participants' attention was directed to the evaluative background information, subsequent processing of the faces also showed an additional increase in neural activity. These findings suggest a mandatory early prioritization of the processing of negatively evaluated faces, whereas attention to relevant facial features evokes a second stage of potentiated brain responses to faces of individuals charged with a crime. Our findings indicate that negative biographical information that resembles typical newspaper headlines strongly affects the neuronal processing of individual faces. perform a perceptual line-discrimination task, in which faces served as distractor stimuli; (b) discriminate the age of faces, in which attention was directed to the face but not to the evaluative information; or (c) decide about the person's evaluative backstory, thus directing participants' attention to the emotional information. We expected no P1 effects of evaluative emotional information. For the N170 and EPN, on the basis of findings of partially resource-independent increases for emotional information, we expected increased differentiation between negative and neutral faces when attention was directed to the face and even more when attention was directed to the emotional information. Finally, larger LPP amplitudes for negative compared with neutral faces were expected only in the emotion task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Following our preregistered data-sampling plan, we recruited 40 participants. Calculations using G*Power <ref type="bibr">(Version 3.1.7;</ref><ref type="bibr" target="#b8">Faul et al., 2009)</ref> showed that this sample size would yield a power of greater than 90% to detect medium-sized effects of evaluative information and interactions of evaluative information and attention tasks (η p 2 = .06). In total, 41 participants were recruited at the University of Münster, but one participant had to be excluded because of a neurological disorder. The remaining 40 participants (30 women) were 23.50 years old (SD = 3.31) on average, gave written informed consent, and received €10 per hour for participation. All participants had normal or corrected-to-normal vision, were right-handed, and reported no history of neurological or psychiatric disorders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stimuli</head><p>The facial stimuli for the experiment were taken from the FACES database with permission for use in the current experiment <ref type="bibr" target="#b6">(Ebner et al., 2010)</ref>. Specifically, eight identities (four young men, four middle-age men) 1 with neutral expressions were chosen. Half of the faces were associated with highly negative evaluative knowledge and the other half with neutral information (see below). Each half contained two young and two middle-age men. Identities were counterbalanced when they were assigned to the conditions, thus they were equally often associated with negative and neutral information across participants. Moreover, the grouping of identities was balanced across participants; thus, all combinations of identities were equally distributed across experimental conditions. To ensure face validity when coupling the faces with different pieces of narrative information, we displayed only headshots of each face, keeping the facial hair but removing the shirts. The faces were always presented with an overlay of horizontal or vertical thin lines (creating using Presentation software; Version 21.1; Neurobehavioral Systems, 2019). Five horizontal or five vertical lines appeared within the boundaries of each face (horizontal lines: 3.3 degrees of visual angle [DVA]; vertical lines: 4.5 DVA; thickness: 0.03 DVA; centered x = 0, y = 0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Participants first responded to a demographic questionnaire. Then they were seated 60 cm in front of a gammacorrected display (Iiyama G-Master GB2488HSU) running at 60 Hz with a Michelson contrast of .9979 (minimum L = 0.35 cd/m 2 ; maximum L = 327.43 cd/m 2 ). The background was set to medium gray (red, green, blue [RGB] value = 108, 108, 108). Before participants started the first task, we gave them negative and then neutral background information for each of the eight face identities by presenting newspaper headlines and detailed background explanations. Two young and two middle-age men were portrayed as having committed a brutal crime-raping, mutilating, and killing two young women. The other two young and two middleage men were described as firefighter trainees. After each newspaper article, all four individual faces were presented on the screen, and participants were requested to attentively look at all faces and memorize them. This information was presented each time before a task started (see Fig. <ref type="figure" target="#fig_0">1</ref>).</p><p>Participants were instructed to avoid eye movements and blinks during the stimulus presentation and started with the perceptual task, the age task, or the emotion task (see Fig. <ref type="figure" target="#fig_0">1</ref>). Task order and response keys (X and M) were counterbalanced across participants. In each trial, participants had to make a two-alternative forced choice, deciding (a) whether the overlaid line orientation was horizontal or vertical, (b) whether the age of the face was old or young, or (c) whether the associated evaluative emotional information was negative or neutral (i.e., whether the face belonged to the criminal group or the firefighter-training group). Before each task started, the background stories were repeated to ensure that participants would remember the evaluative information. The trial structure and mode of presentation were kept constant across all tasks. Each trial started with the display of a fixation cross for 800 to 1,000 ms, after which a face was presented for 100 ms. This short presentation time of the faces was done to avoid attention shifts to other facial features. The face was followed by another fixation cross presented for 1,500 ms, during which responses were recorded. Each face was repeated 16 times during each task, yielding 64 trials presenting faces associated with neutral information and 64 trials with faces associated with negative information, totaling 384 trials across the three tasks. After testing, participants rated each face on valence, arousal, and perceived threat. Finally, they responded to the Beck Depression Inventory-II and the State-Trait Anxiety Inventory <ref type="bibr" target="#b14">(Hautzinger et al., 2009;</ref><ref type="bibr" target="#b36">Spielberger et al., 1999)</ref> as well as to a short version of the NEO Five-Factor Inventory <ref type="bibr" target="#b19">(Körner et al., 2008)</ref>; these measures were not relevant for the current study but for the analyses of individual differences in effects of evaluative person knowledge in larger samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Electroencephalogram (EEG) recording and preprocessing</head><p>EEG signals were recorded from 64 active electrodes using Biosemi's ActiView software (Version 8.12; <ref type="url" target="https://www.biosemi.com/download.htm">https://www.biosemi.com/download.htm</ref>). Four additional electrodes measured horizontal and vertical eye movements. The recording sampling rate was 512 Hz. Off-line data were re-referenced to the average reference and a low-cutoff filter of 0.01 and a highcutoff filter of 40 Hz were applied. Recorded eye movements were corrected using the automatic eye-artifact correction method implemented in BESA Research (Version 6.0; BESA, 2014). A trigger delay of 15 ms was measured using a photodiode and corrected during the process of extracting epochs from the EEG time window. Filtered data were segmented from 100 ms before stimulus onset to 1,000 ms after stimulus presentation. The 100 ms before stimulus onset was used for baseline correction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data analyses</head><p>Data were analyzed using 2 (emotion: negative, neutral) × 3 (task: perceptual, age, emotion) repeated measures</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EEG Preparation</head><p>Post-Rating Questionnaires and Debriefing</p><p>Rating All Faces After electroencephalogram (EEG) preparation was complete (a), the experiment started with one of the three attention tasks, counterbalanced across participants. Each task required them to perform a binary forced-choice decision, in which they had to discriminate line orientation, age, or emotional information. During each trial (b), the backstory was presented in the form of newspaper articles, after which the faces of all four group members were presented. The story and members of the criminal group were presented first, followed by the story and members of the firefighters. Next, participants were informed about the discriminative feature. During each task, the trial structure was identical. Note that stimulus displays in the illustration are not drawn to scale, and the depicted face identity was not used in the experiment but is shown only for display purposes.</p><p>analyses of variance. For ERP analyses of the P1, N170, and EPN, channel-group laterality (left, right) was included as a factor. Effect sizes were calculated as η p 2 s <ref type="bibr" target="#b5">(Cohen, 1988)</ref>. When Mauchly's test of sphericity indicated a violation of sphericity, degrees of freedom were corrected following the Greenhouse-Geisser method. For secondary analyses, hit rates and reaction times were examined, excluding trials with reaction times of less than 100 ms and greater than 1,500 ms.</p><p>EEG scalp data were statistically analyzed using Electromagnetic Encephalography Software (EMEGS; Version 2.8; <ref type="bibr" target="#b24">Peyk et al., 2011)</ref>. The main effects of emotion, task, and their interaction were examined. Time windows were segmented into intervals from 80 to 100 ms for the P1, 120 to 170 ms for the N170, 250 to 350 ms for the EPN, and 400 to 600 ms for the LPP. We measured the P1, N170, and EPN over two symmetrical occipital clusters (P1 and N170: left P9, P7, PO7; right P10, P8, PO8; EPN: left P9, P7, PO7, O1; right P10, P8, PO8, O2). Additionally, we measured the LPP component over a centroparietal cluster (C1, Cz, C2, CP1, CPz, CP2, P1, Pz, P2). We slightly deviated from our preregistration in time (preregistered N170: 130-170 ms; preregistered EPN: 200-350 ms) and space (preregistered EPN: left P9, P7, PO7; right P10, P8, PO8; preregistered LPP: C1, Cz, C2, CP1, CPz, CP2). This was because of the preregistered approach to validate ERP windows for the P1 and N170 by collapsing ERPs across all conditions <ref type="bibr" target="#b20">(Luck &amp; Gaspelin, 2017)</ref>. For the EPN and LPP, which are typically scored as differences between negative and neutral stimuli, we collapsed waveforms to negative faces and neutral faces across all attention tasks to identify differential effects. Finally, analyses of covariance (ANCOVAs) with reaction time as a covariate were calculated to account for possible influences of reaction time differences on ERP modulations. All data (<ref type="url" target="https://osf.io/rzevn">https://osf.io/rzevn</ref>) and a copy of the preregistration (<ref type="url" target="https://osf.io/erkdt">https://osf.io/erkdt</ref>) and are available on OSF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Manipulation check</head><p>Face ratings. After the experiment, participants rated the valence, arousal, and perceived threat of faces. Rating showed effects of emotional evaluative information for valence, F(1, 39) = 33.92, p &lt; .001, η p 2 = .465 (see Fig. <ref type="figure" target="#fig_1">2</ref>); arousal, F(1, 39) = 15.00, p &lt; .001, η p 2 = .278; and perceived threat, F(1, 39) = 37.73, p &lt; .001, η p 2 = .492. Faces associated with negative evaluative information were rated as more negative (criminal faces: M = 2.88, SD = 0.78; neutral faces: M = 3.99, SD = 0.71), more arousing (criminal faces: M = 3.84, SD = 1.35; neutral faces: M = 2.84, SD = 1.03), and more threatening (criminal faces: M = 4.26, SD = 1.25; neutral faces: M = 2.59, SD = 0.88) than faces paired with neutral information. Finally, participants' ratings of the credibility of the cover story were rather high (Likert-type scale: 1 = not credible, 4 = highly credible; M = 3.1, SD = 0.55).</p><p>Hit rate. With regard to hit rate, there was no main effect of emotion, F(1, 38) = 1.48, p = .231, η p 2 = .037 (see Fig. <ref type="figure" target="#fig_1">2</ref> and Table <ref type="table" target="#tab_0">1</ref>), but a significant effect of task, F(1.45, 55.13) = 27.59, p &lt; .001, η p 2 = .421. The percentage of correct choices was lowest in the emotion task compared with both the age and the perceptual tasks (ps &lt; .001). Further, more hits were made in the perceptual task compared with the age task (p = .003). There was no significant interaction between emotion and task, F(2, 76) = 0.81, p = .449, η p 2 = .021.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reaction time.</head><p>Regarding reaction time, main effects of emotion, F(1, 38) = 18.02, p &lt; .001, η p 2 = .322 (see Fig. <ref type="figure" target="#fig_1">2</ref> and Table <ref type="table" target="#tab_0">1</ref>), and task, F(2, 76) = 127.86, p &lt; .001, η p 2 = .771, were found. These main effects show shorter reaction times for faces associated with negative compared with neutral information and the shortest reaction times during the perceptual task, the age task ranking second and the emotion task eliciting the longest reaction times (all ps &lt; .001). Moreover, there was a significant interaction between emotion and task, F(2, 76) = 16.38, p &lt; .001, η p 2 = .301. When we resolved this interaction, it became evident that there were no differences between negative and neutral faces for the comparison of the perceptual and the age tasks (p = .916). However, larger reaction times were found for the emotion task compared with both the age task (p &lt; .001) and perceptual task (p &lt; .001). In the emotion task, faster responses were found toward faces paired with negative information. For descriptive information, see Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ERP results</head><p>P1. With respect to the P1, there was no main effect of emotion, F(1, 39) = 0.16, p = .693, η p 2 = .004, but a main effect of task, F(2, 78) = 4.82, p = .011, η p 2 = .110. Furthermore, the effect of channel-group laterality did not reach significance, F(1, 39) = 1.85, p = .182, η p 2 = .045. Regarding the main effect of task, smaller P1 amplitudes were found in the emotion task compared with the perceptual task (p = .038) and the age task (p = .002); the latter two did not differ significantly in amplitude from each other (p = .674). There was no interaction between emotion and task, F(2, 78) = 1.18, p = .312, η p 2 = .029, and further interactions did not reach significance either (Fs &lt; 3.79, ps &gt; .059).</p><p>N170. For the N170, there was a large main effect of emotion, F(1, 39) = 16.12, p &lt; .001, η p 2 = .292 (see Fig. <ref type="figure" target="#fig_2">3</ref>), but no main effect of task, F(2, 78) = 0.81, p = .448, η p 2 = .020. Moreover, the main effect of channel-group laterality reached significance, F(1, 39) = 8.50, p = .006, η p 2 = .179. With respect to the main effects, faces paired with negative information elicited larger N170 amplitudes than those coupled with neutral information, and larger N170   amplitudes were recorded over the right compared with the left electrode cluster. There was no significant interaction between emotion and task, F(2, 78) = 0.24, p = .784, η p 2 = .006, nor did any further interactions reach significance (Fs &lt; 0.54, ps &gt; .584).</p><p>EPN. Concerning the EPN, there was no main effect of emotion, F(1, 39) = 2.60, p = .115, η p 2 = .063, but the main effect of task reached significance, F(2, 78) = 8.15, p = .001, η p 2 = .173. Moreover, no effect of channel-group laterality was identified, F(1, 39) &lt; 0.01, p = .948, η p 2 &lt; .001. Smaller EPN amplitudes were recorded in the age task compared with the perceptual task (p = .002) and emotion task (p &lt; .001). The perceptual and emotion tasks did not differ significantly in amplitude (p = .801).</p><p>We observed a significant interaction between emotion and task, F(2, 78) = 3.45, p = .037, η p 2 = .081 (see Fig. <ref type="figure">4</ref>). When we resolved this interaction, results showed no significant differences between the perceptual and age tasks for differences between faces paired with negative compared with neutral information (p = .564). In contrast, larger differentiation was found for the emotion task compared with both the age task (p = .027) and perceptual task (p = .039). Moreover, a significant interaction of task and channel-group laterality was found, F(2, 78) = 6.70, p = .002, η p 2 = .147. Here, analyses showed that the task differences were stronger over the left electrode cluster, F(2, 78) = 10.50, p &lt; .001, η p 2 = .212, than over the right cluster, F(2, 78) = 5.51, p = .006, η p 2 = .124. All further interactions remained insignificant (Fs &lt; 3.29, ps &gt; .077).</p><p>LPP. Regarding the LPP, the main effects of emotion, F(1, 39) = 20.34, p &lt; .001, η p 2 = .343 (see Fig. <ref type="figure">5</ref>), and of task reached significance, F(1.70, 66.28) = 6.52, p = .004, η p 2 = .143. Faces associated with negative information elicited larger positivities than faces paired with neutral information. Furthermore, smaller LPP amplitudes were found for the perceptual task compared with the age task (p = .048) and emotion task (p = .004), the latter two not differing significantly in amplitude (p = .051). Importantly, we observed the predicted interaction between emotion and task, F(2, 78) = 6.29, p = .003, η p 2 = .139 (see Fig. <ref type="figure">5</ref>). When we resolved this interaction, results showed no significant differences for faces paired with negative and neutral information between the perceptual task and the age task (p = .831). In contrast, a larger differentiation was found for the emotion task compared with both the age task (p = .008) and perceptual task (p = .001).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Control analyses: ANCOVAs with reaction time as a covariate</head><p>Because we observed reaction time differences between the tasks as well as interactions of emotion and task, we calculated ANCOVAs with reaction time as a covariate (see Table <ref type="table" target="#tab_1">2</ref>). For the P1, the main effect of task disappeared when the analysis accounted for reaction time differences; however, N170 and LPP main effects of emotion, EPN and LPP main effects of task, and most importantly, EPN and LPP interaction effects of emotion and task remained significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>We tested how feature-based attention to perceptual, face, or emotional information differentially influences evaluative-knowledge effects on early (P1, N170), midlatency (EPN), and late (LPP) ERP components. Faces of supposed criminals were rated more negatively, arousing, and threatening than neutral faces. During all tasks, accuracy was at ceiling, whereas for reaction times, faster responses toward faces of criminals were found only during the evaluative task. Interestingly, we found a task-independent effect of negative evaluative knowledge on the N170 as well as interactions of emotion and task for the EPN and LPP, showing differentiation between faces with negative and neutral associations only when participants attended to the associated emotional information.</p><p>The P1 is hypothesized to be related to early stimulus detection and discrimination (e.g., <ref type="bibr" target="#b21">Luck &amp; Hillyard, 1994)</ref>. We expected no significant effects of evaluative emotional information, in line with the few studies examining P1 effects for different kinds of evaluative or context manipulations (e.g., <ref type="bibr" target="#b22">Luo et al., 2016;</ref><ref type="bibr" target="#b39">Wieser et al., 2014)</ref>. This indicates that the mere evaluative information is not sufficient to increase P1 amplitudes for neutral expressions, in contrast to findings of studies that examined associated monetary gains <ref type="bibr" target="#b13">(Hammerschmidt et al., 2017</ref>; but see <ref type="bibr" target="#b12">Hammerschmidt et al., 2018)</ref>. C1 modulations have been observed even in studies associating monetary information with visual stimuli <ref type="bibr" target="#b27">(Rossi et al., 2017)</ref> and studies in which participants were conditioned to associate faces with an electric shock <ref type="bibr" target="#b25">(Rehbein et al., 2014)</ref>. Finally, we found a smaller P1 during the emotion task, which could indicate differences in tonic vigilance.</p><p>The N170, which follows the P1, is viewed as a structural encoding component related to configural processing, and its amplitude is increased for faces compared with objects <ref type="bibr" target="#b7">(Eimer, 2011)</ref>. Here, we found a task-independent evaluative-information effect with negative biographical information increasing amplitudes for the presented faces. Interestingly, N170 modulations are rarely examined in studies on evaluative person knowledge, but results are conflicting <ref type="bibr" target="#b22">(Luo et al., 2016;</ref><ref type="bibr" target="#b40">Xu et al., 2016)</ref>. A critical factor in our results could be the small number of face identities. Because we used two groups and presented all group members together, it might have been easy to distinguish between subsequently presented</p><p>EPN (250-350 ms) Main Effects of Emotion Perceptual Task Age Task Emotion Task Time (ms) Negative Neutral Negative -Neutral Perceptual Age Task Emotion -10 -5 0 5 Time (m Negative Neutral Neutral e 100 400 200 300 100 400 200 300 300 100 400 200 300 100 400 200 300 -0.5 0.5 -0.5 0.5 -0.5 0.5 100 400 200 300 100 400 200 300 00 100 200 40 300 Negative Neutral 1 0 -1</p><p>Amplitude (µV) Amplitude (µV) Amplitude (µV) LPP (400-600 ms) Main Effects of Evaluative Information Perceptual Task Age Task Emotion Task Time (ms) Negative -Neutral Tim e -Neut N 200 400 600 1 2 3 4 00 60 200 400 600 200 400 600 200 400 600 200 400 600 200 400 600 0.5 -1 1 2 3 4 0.5 -1 1 2 3 4 0.5 00 60 200 4 0 Perceptual Age Task Emotion 0 2 4 6 8 Negative Neutral Amplitude (µV) Amplitude (µV) Amplitude (µV) Negative Neutral µV 1 0 -1 µV 1 0 -1 µV 1 0 -1 -1 Fig. 5. Main effects of evaluative information on the late positive potential (LPP) in each of the three tasks (perceptual, age, and emotion). Scalp topographies depict the differences between event-related potentials (ERPs) in response to faces associated with criminal (negative) and neutral backstories. Black dots indicate positions of electrodes. The top row of ERP waveforms shows the mean time course for highlighted sensors in the negative and neutral conditions. The bottom row of ERP waveforms shows differences between means for the two emotion conditions; error bands show 95% bootstrapped confidence intervals. The gray shaded areas in all waveform graphs highlight the range of the LPP. The bar plot shows average amplitude across selected sensors in each combination of task and emotion condition. Data bars show group means, and error bars depict 95% confidence intervals. Semitransparent dots depict individual data.</p><formula xml:id="formula_0">µV 1 0 -1 µV 1 0 -1 µV -4 -3 -2 -1 1 2 3 4 -4 -3 -2 -1 1 2 3 4 -4 -3 -2 -1 1 2 3 4</formula><p>faces and associate all face identities with their evaluative background. This possibly enabled participants to discriminate configural features between putative criminal and neutral identities. The task-independent N170 modulation indicates that this discriminatory process did not need attention to face or emotional features. Building on this empirical finding, we found that the processing of configural information can be influenced by instructed evaluative knowledge, enabling an early sensory differentiation. Adding to this idea, a recent study has shown increased N170 responses for neutral faces for which participants exhibit more negative stereotypes <ref type="bibr" target="#b10">(Giménez-Fernández et al., 2020)</ref>.</p><p>For the following EPN component, which has been examined more frequently, studies have also provided a mixed picture so far (e.g., <ref type="bibr" target="#b1">Baum et al., 2020;</ref><ref type="bibr" target="#b17">Kissler &amp; Strehlow, 2017;</ref><ref type="bibr" target="#b22">Luo et al., 2016;</ref><ref type="bibr" target="#b37">Suess et al., 2014)</ref>. We expected increasing EPN differences across tasks. However, we observed an effect of negative biographical information only when attention was directed to the biographical background of a given face. Thus, our findings conflict with those of studies showing increased EPN amplitudes for faces associated with negative person knowledge in tasks that do not require attention to the emotional information <ref type="bibr" target="#b37">(Suess et al., 2014;</ref><ref type="bibr" target="#b40">Xu et al., 2016</ref>). An explanation for this finding could be related to the short presentation time of the faces, which was done to avoid attention shifts to other facial features. Further explanations for conflicting EPN findings could be related to the specific learning task used to acquire the evaluative biographical information (see the Supplemental Material at <ref type="url" target="https://osf.io/abx27/">https://osf.io/abx27/</ref>), the limited number of identities, or the specific attention tasks. It might be that in tasks, which require attending to a semantic face feature (e.g., see <ref type="bibr" target="#b37">Suess et al., 2014)</ref>, the associated emotional biographical information is more readily retrieved than in other tasks. We believe that during the EPN stage, attentional selection mechanisms depend on both the emotional saliency of the given stimulus and available processing capacities (see <ref type="bibr" target="#b16">Junghöfer et al., 2001;</ref><ref type="bibr" target="#b32">Schindler, Caldarone, et al., 2020)</ref>. Previous studies using emotional facial expressions (e.g., <ref type="bibr" target="#b26">Rellecke et al., 2012;</ref><ref type="bibr">Schindler, Bruchmann, et al., 2020)</ref> have clearly shown that the EPN can be dissociated from both earlier stages (N170) and later stages (LPP; see below). For example, in a similar paradigm, we showed increasing EPN amplitudes with increasing attention to relevant features of fearful faces, showing also an increased EPN during a genderdiscrimination task <ref type="bibr">(Schindler, Bruchmann, et al., 2020)</ref>. In line with this, other studies showed significant EPN modulations by emotional expressions when participants discriminated face identity <ref type="bibr" target="#b12">(Hammerschmidt et al., 2018)</ref> and even when participants performed perceptual-discrimination tasks <ref type="bibr" target="#b15">(Itier &amp; Neath-Tavares, 2017;</ref><ref type="bibr" target="#b26">Rellecke et al., 2012)</ref>. Thus, even though experimental effects on the EPN and LPP were highly similar in the present study, this does not imply that both components have similar functional roles.</p><p>In contrast to the intermediate stage associated with the EPN, the LPP indicates stimulus evaluation and controlled attention processes (e.g., see <ref type="bibr" target="#b11">Hajcak et al., 2009;</ref><ref type="bibr" target="#b33">Schupp et al., 2006)</ref>, and LPP effects are based on various sources, including evaluative, episodic, personal, and biographical information (see <ref type="bibr" target="#b35">Schweinberger &amp; Neumann, 2016)</ref>. The majority of studies that used evaluative-knowledge designs found late differential effects <ref type="bibr" target="#b0">(Abdel Rahman, 2011;</ref><ref type="bibr" target="#b1">Baum et al., 2020;</ref><ref type="bibr" target="#b17">Kissler &amp; Strehlow, 2017;</ref><ref type="bibr" target="#b18">Klein et al., 2015;</ref><ref type="bibr" target="#b40">Xu et al., 2016)</ref>. Regarding those studies with no significant LPP modulation (e.g., <ref type="bibr" target="#b22">Luo et al., 2016)</ref>, our data suggest that the attended feature matters much for a late differentiation, and elaborate differentiation does not occur inevitably but requires attention to the emotional information. These findings are similar to those of studies that manipulated featurebased attention to threatening emotional expressions <ref type="bibr" target="#b26">(Rellecke et al., 2012;</ref><ref type="bibr">Schindler, Bruchmann, et al., 2020)</ref> and suggest that at these late processing stages, topdown processes interact with the associated emotional significance of a face more generally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Constraints on generality and future directions</head><p>To the best of our knowledge, this is the first EEG study that systematically manipulated attention to evaluative emotional person knowledge. However, the stimulus presentation was very short, which possibly added to the clarity of our findings, and we used specific tasks to manipulate attention to perceptual, face, or emotional features. Future studies are needed, using other tasks to generalize our findings (e.g., attention to gender, face, or nationality information). Secondly, for cover-story purposes, the faces we used were all male, whereas the sample was predominantly women (n = 30 vs. n = 10 men), and effects could be more pronounced for female participants. In this regard, future studies should also resolve how depicted face identity interacts with evaluative information (e.g., age, gender, ethnic background). Third, other operationalizations of emotional face learning should be examined, including instructed threat or classic conditioning (e.g., <ref type="bibr" target="#b3">Bublatzky et al., 2014;</ref><ref type="bibr" target="#b25">Rehbein et al., 2014;</ref><ref type="bibr" target="#b30">Schellhaas et al., 2020)</ref>. Lastly, we focused only on negative evaluative information because it is reported to be highly effective (see <ref type="bibr" target="#b4">Bublatzky et al., 2020;</ref><ref type="bibr" target="#b37">Suess et al., 2014)</ref>. For future studies, it seems promising to include positive evaluative manipulations, for which studies have shown modulations starting with the P1 component (see <ref type="bibr" target="#b13">Hammerschmidt et al., 2017;</ref><ref type="bibr" target="#b29">Schacht &amp; Vrtic ˇka, 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In summary, early (N170) effects of evaluative emotional knowledge are task independent and increased for arguably criminal identities. In contrast, differential EPN and LPP effects depended on attention to the emotional background information. These findings are vitally important for researchers who conduct ERP studies using evaluative information because they reveal a systematic pattern of emotional sensitivity for competing attention tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Schematic overview of (a) the experimental flow and (b) trial presentation in all tasks. After electroencephalogram (EEG) preparation was complete (a), the experiment started with one of the three attention tasks, counterbalanced across participants. Each task required them to perform a binary forced-choice decision, in which they had to discriminate line orientation, age, or emotional information. During each trial (b), the backstory was presented in the form of newspaper articles, after which the faces of all four group members were presented. The story and members of the criminal group were presented first, followed by the story and members of the firefighters. Next, participants were informed about the discriminative feature. During each task, the trial structure was identical. Note that stimulus displays in the illustration are not drawn to scale, and the depicted face identity was not used in the experiment but is shown only for display purposes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Ratings and behavioral results in the three attention tasks. Average ratings of the (a) valence, (b) arousal, and (c) perceived threat of the stimuli are shown for each emotion condition. Average (d) reaction time (RT) and (e) hit rate (proportion of correct responses) for each emotion condition are shown separately for the three different tasks. Data bars show group means, and error bars depict 95% confidence intervals. Semitransparent dots depict individual data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Main effects of emotion on the P1 and N170, respectively, in each of the three tasks (perceptual, age, and emotion). Scalp topographies depict the differences between event-related potentials (ERPs) in response to faces associated with criminal (negative) and neutral backstories. Black dots indicate positions of electrodes. The top row of ERP waveforms shows the mean time course for highlighted sensors in the negative and neutral conditions. The bottom row of ERP waveforms shows differences between means for the two emotion conditions; error bands show 95% bootstrapped confidence intervals. The gray shaded areas in all waveform graphs highlight the range of the P1 and N170, respectively. The bar plots show average amplitude across selected sensors in each combination of task and emotion condition. Data bars show group means, and error bars depict 95% confidence intervals. Semitransparent dots depict individual data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig. 4. Main effects of emotion on the early posterior negativity (EPN) in each of the three tasks (perceptual, age, and emotion). Scalp topographies depict the differences between event-related potentials (ERPs) in response to faces associated with criminal (negative) and neutral backstories. Black dots indicate positions of electrodes. The top row of ERP waveforms shows the mean time course for highlighted sensors in the negative and neutral conditions. The bottom row of ERP waveforms shows differences between means for the two emotion conditions; error bands show 95% bootstrapped confidence intervals. The gray shaded areas in all waveform graphs highlight the range of the EPN. The bar plot shows average amplitude across selected sensors in each combination of task and emotion condition. Data bars show group means, and error bars depict 95% confidence intervals. Semitransparent dots depict individual data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Means for Behavioral Measures Across the Three Attention Tasks</figDesc><table><row><cell></cell><cell cols="2">Perceptual task</cell><cell cols="2">Age task</cell><cell cols="2">Emotion task</cell></row><row><cell>Measure</cell><cell>Criminal faces</cell><cell>Neutral faces</cell><cell>Criminal faces</cell><cell>Neutral faces</cell><cell>Criminal faces</cell><cell>Neutral faces</cell></row><row><cell>Number of hits</cell><cell>61.95</cell><cell>62.18</cell><cell>60.90</cell><cell>59.93</cell><cell>54.93</cell><cell>55.28</cell></row><row><cell></cell><cell>(1.87)</cell><cell>(1.97)</cell><cell>(3.61)</cell><cell>(5.29)</cell><cell>(11.01)</cell><cell>(8.20)</cell></row><row><cell>Reaction time (ms)</cell><cell>581.73</cell><cell>581.67</cell><cell>634.20</cell><cell>631.80</cell><cell>722.00</cell><cell>786.55</cell></row><row><cell></cell><cell>(91.86)</cell><cell>(91.65)</cell><cell>(93.18)</cell><cell>(91.50)</cell><cell>(142.96)</cell><cell>(96.95)</cell></row></table><note><p>Note: Values in parentheses are standard deviations. For four participants, behavioral responses were recoded in at least one condition (emotion task in four participants, age task in one participant) because they reported having confused the response keys. No responses were recorded from one participant in one subcondition of the emotion task, presumably because the participant pressed a wrong key.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Results From Repeated Measures Analyses on the Four Event-Related Potential Components, Both With and Without Reaction Time (RT) as a Covariate</figDesc><table><row><cell></cell><cell></cell><cell cols="2">With RT</cell><cell cols="2">Without RT</cell></row><row><cell>Component and effect</cell><cell>dfs</cell><cell>F</cell><cell>p</cell><cell>F</cell><cell>p</cell></row><row><cell>P1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Emotion</cell><cell>(1, 39)</cell><cell>0.158</cell><cell>.693</cell><cell>0.513</cell><cell>.478</cell></row><row><cell>Task</cell><cell>(2, 78)</cell><cell>4.816</cell><cell>.011</cell><cell>1.050</cell><cell>.337</cell></row><row><cell>Emotion × Task</cell><cell>(2, 78)</cell><cell>1.184</cell><cell>.312</cell><cell>1.878</cell><cell>.160</cell></row><row><cell>N170</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Emotion</cell><cell>(1, 39)</cell><cell>16.120</cell><cell>&lt; .001</cell><cell>15.298</cell><cell>&lt; .001</cell></row><row><cell>Task</cell><cell>(2, 78)</cell><cell>0.810</cell><cell>.448</cell><cell>2.090</cell><cell>.150</cell></row><row><cell>Emotion × Task</cell><cell>(2, 78)</cell><cell>0.244</cell><cell>.784</cell><cell>0.707</cell><cell>.496</cell></row><row><cell>Early posterior negativity</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Emotion</cell><cell>(1, 39)</cell><cell>2.601</cell><cell>.115</cell><cell>3.736</cell><cell>.061</cell></row><row><cell>Task</cell><cell>(2, 78)</cell><cell>8.152</cell><cell>.001</cell><cell>10.114</cell><cell>.001</cell></row><row><cell>Emotion × Task</cell><cell>(2, 78)</cell><cell>3.448</cell><cell>.037</cell><cell>4.455</cell><cell>.015</cell></row><row><cell>Late positive potential</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Emotion</cell><cell>(1, 39)</cell><cell>20.335</cell><cell>&lt; .001</cell><cell>15.846</cell><cell>&lt; .001</cell></row><row><cell>Task</cell><cell>(2, 78)</cell><cell>6.520</cell><cell>&lt; .001</cell><cell>4.050</cell><cell>.029</cell></row><row><cell>Emotion × Task</cell><cell>(2, 78)</cell><cell>6.287</cell><cell>&lt; .001</cell><cell>5.690</cell><cell>.008</cell></row></table><note><p>Note: Significant main and interaction effects are highlighted in boldface. All p values were Greenhouse-Geisser corrected whenever Mauchly's test indicated a violation of the sphericity assumption.</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank <rs type="person">Nele Johanna Bögemann</rs> for her corrections and all participants who contributed to this study.</p></div>
<div><head>Note</head><p>1. For young men, we selected identities 025, 037, 049, 123, and for middle-age men, identities 058, 108, 178, and 179.   </p></div>
			</div>
			<div type="funding">
<div><p>Transparency Action Editor: <rs type="person">Karen Rodrigue</rs> Editor: <rs type="person">Patricia J. Bauer Author</rs> Contributions <rs type="person">S. Schindler</rs> and <rs type="person">M. Bruchmann</rs> contributed equally to this study. All the authors contributed to the study design. <rs type="person">R. Moeck</rs> programmed the experiment. <rs type="person">S. Schindler</rs>, <rs type="person">C. Krasowski</rs>, and <rs type="person">M. Bruchmann</rs> pilot-tested the experiment. <rs type="person">C. Krasowski</rs> tested participants. <rs type="person">S. Schindler</rs> and <rs type="person">M. Bruchmann</rs> analyzed the data. <rs type="person">S. Schindler</rs> and <rs type="person">M. Bruchmann</rs> wrote the manuscript under the supervision of <rs type="person">T. Straube</rs>. All the authors approved the final manuscript for submission.</p></div>
<div><head>Declaration of Conflicting Interests</head><p>The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article.</p></div>
<div><head>Open Practices</head><p>All data have been made publicly available via OSF and can be accessed at <ref type="url" target="https://osf.io/rzevn">https://osf.io/rzevn</ref>. The study was preregistered at <ref type="url" target="https://osf.io/erkdt">https://osf.io/erkdt</ref>. This article has received the badges for Open Data and Preregistration. More information about the Open Practices badges can be found at <ref type="url" target="http://www.psychologicalscience.org/publications/badges">http://www.psychologicalscience.org/publica  tions/badges</ref>.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Facing good and evil: Early brain signatures of affective biographical knowledge in face recognition</title>
		<author>
			<persName><forename type="first">R</forename><surname>Abdel Rahman</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0024717</idno>
		<ptr target="https://doi.org/10.1037/a0024717" />
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1397" to="1405" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Clear judgments based on unclear evidence: Person evaluation is strongly influenced by untrustworthy gossip</title>
		<author>
			<persName><forename type="first">J</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rabovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Abdel Rahman</surname></persName>
		</author>
		<idno type="DOI">10.1037/emo0000545</idno>
		<ptr target="https://doi.org/10.1037/emo0000545" />
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="248" to="260" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><surname>Besa</surname></persName>
		</author>
		<ptr target="https://www.besa.de/products/besa-research/besa-research-overview/" />
		<title level="m">BESA Research (Version 6.0</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>Computer software</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The persistence of socially instructed threat: Two threat-of-shock studies</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bublatzky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B M</forename><surname>Gerdes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Alpers</surname></persName>
		</author>
		<idno type="DOI">10.1111/psyp.12251</idno>
		<ptr target="https://doi.org/10.1111/psyp.12251" />
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1005" to="1014" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Watch out, he&apos;s dangerous! Electrocortical indicators of selective visual attention to allegedly threatening persons</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bublatzky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Guerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Alpers</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2020.07.009</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2020.07.009" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="164" to="178" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Statistical power analysis for the behavioral sciences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Routledge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">FACES-A database of facial expressions in young, middle-aged, and older women and men: Development and validation</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riediger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Lindenberger</surname></persName>
		</author>
		<idno type="DOI">10.3758/BRM.42.1.351</idno>
		<ptr target="https://doi.org/10.3758/BRM.42.1.351" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="351" to="362" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The face-sensitive N170 component of the event-related brain potential</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eimer</surname></persName>
		</author>
		<idno type="DOI">10.1093/oxfordhb/9780199559053.013.0017</idno>
		<ptr target="https://doi.org/10.1093/oxfordhb/9780199559053.013.0017" />
	</analytic>
	<monogr>
		<title level="m">The Oxford handbook of face perception</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Rhodes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Calder</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Johnson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Haxby</surname></persName>
		</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="329" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Statistical power analyses using G*Power 3.1: Tests for correlation and regression analyses</title>
		<author>
			<persName><forename type="first">F</forename><surname>Faul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Erdfelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-G</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1149" to="1160" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Time course of implicit processing and explicit processing of emotional faces and emotional words</title>
		<author>
			<persName><forename type="first">S</forename><surname>Frühholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jellinghaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herrmann</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.biopsycho.2011.03.008</idno>
		<ptr target="https://doi.org/10.1016/j.biopsycho.2011.03.008" />
	</analytic>
	<monogr>
		<title level="j">Biological Psychology</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="265" to="274" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Prejudice drives exogenous attention to outgroups</title>
		<author>
			<persName><forename type="first">T</forename><surname>Giménez-Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Fernández-Folgueiras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fondevila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Méndez-Bértolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Aceves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>García-Rubio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carretié</surname></persName>
		</author>
		<idno type="DOI">10.1093/scan/nsaa087</idno>
		<ptr target="https://doi.org/10.1093/scan/nsaa087" />
	</analytic>
	<monogr>
		<title level="j">Social Cognitive and Affective Neuroscience</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="615" to="624" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Motivated and controlled attention to emotion: Time-course of the late positive potential</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hajcak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Dunning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Foti</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.clinph.2008.11.028</idno>
		<ptr target="https://doi.org/10.1016/j.clinph.2008.11.028" />
	</analytic>
	<monogr>
		<title level="j">Clinical Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="505" to="510" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Implicit reward associations impact face processing: Time-resolved evidence from event-related brain potentials and pupil dilations</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hammerschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kulke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schacht</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2018.06.055</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2018.06.055" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="page" from="557" to="569" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Associated motivational salience impacts early sensory processing of human faces</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hammerschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sennhenn-Reulen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schacht</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2017.04.032</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2017.04.032" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="page" from="466" to="474" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">BDI-II. Beck-Depressions-Inventar</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hautzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kühner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Pearson Assessment</publisher>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>Revision BDI-II. Beck Depression Inventory Version 2</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Effects of task demands on the early neural processing of fearful and happy facial expressions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Itier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Neath-Tavares</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.brainres.2017.03.013</idno>
		<ptr target="https://doi.org/10.1016/j.brainres.2017.03.013" />
	</analytic>
	<monogr>
		<title level="j">Brain Research</title>
		<imprint>
			<biblScope unit="volume">1663</biblScope>
			<biblScope unit="page" from="38" to="50" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fleeting images: A new look at early emotion discrimination</title>
		<author>
			<persName><forename type="first">M</forename><surname>Junghöfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Elbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="175" to="178" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Something always sticks? How emotional language modulates neural processes involved in face encoding and recognition memory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kissler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Strehlow</surname></persName>
		</author>
		<idno type="DOI">10.1515/psicl-2017-0004</idno>
		<ptr target="https://doi.org/10.1515/psicl-2017-0004" />
	</analytic>
	<monogr>
		<title level="j">Poznan Studies in Contemporary Linguistics</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="93" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">This person is saying bad things about you: The influence of physically and socially threatening context information on the processing of inherently neutral faces</title>
		<author>
			<persName><forename type="first">F</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Iffland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wabnitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Neuner</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13415-015-0361-8</idno>
		<ptr target="https://doi.org/10.3758/s13415-015-0361-8" />
	</analytic>
	<monogr>
		<title level="j">Cognitive, Affective, &amp; Behavioral Neuroscience</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="736" to="748" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Persönlichkeitsdiagnostik mit dem NEO-Fünf-Faktoren-Inventar: Die 30-Item-Kurzversion (NEO-FFI-30) [Personality assessment with the NEO-Five-Factor Inventory: The 30-Item-Short-Version (NEO-FFI-30)</title>
		<author>
			<persName><forename type="first">A</forename><surname>Körner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Geyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Drapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schmutzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Albani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brähler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PPmP-Psychotherapie Psychosomatik Medizinische Psychologie</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="238" to="245" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">How to get statistically significant effects in any ERP experiment (and why you shouldn&apos;t)</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Luck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gaspelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="146" to="157" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Electrophysiological correlates of feature analysis during visual search</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Luck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hillyard</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1469-8986.1994.tb02218.x</idno>
		<ptr target="https://doi.org/10.1111/j.1469-8986.1994.tb02218.x" />
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="291" to="308" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Effect of affective personality information on face processing: Evidence from ERPs</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dzhelyova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mo</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2016.00810</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2016.00810" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">810</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Is it about me? Timecourse of self-relevance and valence effects on the perception of neutral faces with direct and averted gaze</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Mccrackin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Itier</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.biopsycho.2018.03.003</idno>
		<ptr target="https://doi.org/10.1016/j.biopsycho.2018.03.003" />
	</analytic>
	<monogr>
		<title level="j">Biological Psychology</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="47" to="64" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">ElectroMagnetoEncephalography software: Overview and integration with other EEG/MEG toolboxes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Peyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>De Cesarei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Junghöfer</surname></persName>
		</author>
		<idno type="DOI">10.1155/2011/861705</idno>
		<ptr target="https://doi.org/10.1155/2011/861705" />
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence and Neuroscience</title>
		<imprint>
			<biblScope unit="page">861705</biblScope>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Rapid plasticity in the prefrontal cortex during affective associative learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Rehbein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Steinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wessing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Pastor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zwitserlood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Keuper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Junghöfer</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0110720</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0110720" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">110720</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Does processing of emotional facial expressions depend on intention? Time-resolved evidence from event-related brain potentials</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rellecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schacht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Psychology</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="32" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Motivational salience modulates early visual cortex responses across task sets</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vanlessen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pourtois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schacht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="968" to="979" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Emotions in word and face processing: Early and late cortical responses</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schacht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain and Cognition</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="538" to="550" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Spatiotemporal pattern of appraising social and emotional relevance: Evidence from event-related brain potentials</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schacht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vrtic ˇka</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13415-018-0629-x</idno>
		<ptr target="https://doi.org/10.3758/s13415-018-0629-x" />
	</analytic>
	<monogr>
		<title level="j">Cognitive, Affective, &amp; Behavioral Neuroscience</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1172" to="1187" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Contextual source information modulates neural face processing in the absence of conscious recognition: A threatof-shock study</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schellhaas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bublatzky</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.nlm.2020.107280</idno>
		<ptr target="https://doi.org/10.1016/j.nlm.2020.107280" />
	</analytic>
	<monogr>
		<title level="j">Neurobiology of Learning and Memory</title>
		<imprint>
			<biblScope unit="volume">174</biblScope>
			<biblScope unit="page">107280</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Attentional conditions differentially affect early, intermediate and late neural responses to fearful and neutral faces</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bruchmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-L</forename><surname>Steinweg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Moeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Straube</surname></persName>
		</author>
		<idno type="DOI">10.1093/scan/nsaa098</idno>
		<ptr target="https://doi.org/10.1093/scan/nsaa098" />
	</analytic>
	<monogr>
		<title level="j">Social Cognitive and Affective Neuroscience</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="765" to="774" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Time-dependent effects of perceptual load on processing fearful and neutral faces</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Caldarone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bruchmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Moeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Straube</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuropsychologia.2020.107529</idno>
		<ptr target="https://doi.org/10.1016/j.neuropsychologia.2020.107529" />
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page">107529</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Emotion and attention: Event-related brain potential studies</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Schupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Flaisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stockburger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Junghöfer</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0079-6123(06)56002-9</idno>
		<ptr target="https://doi.org/10.1016/S0079-6123(06)56002-9" />
	</analytic>
	<monogr>
		<title level="j">Progress in Brain Research</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="page" from="31" to="51" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The selective processing of briefly presented affective pictures: An ERP analysis</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Schupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Junghöfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Weike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">O</forename><surname>Hamm</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1469-8986.2004.00174.x</idno>
		<ptr target="https://doi.org/10.1111/j.1469-8986.2004.00174.x" />
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="441" to="449" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Repetition effects in human ERPs to faces</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Schweinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Neumann</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2015.11.001</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2015.11.001" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="141" to="153" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Suppl. C</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Measuring anxiety and anger with the State-Trait Anxiety Inventory (STAI) and the State-Trait Anger Expression Inventory (STAXI)</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Spielberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Sydeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Owen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Marsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The use of psychological testing for treatment planning and outcomes assessment</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Maruish</surname></persName>
		</editor>
		<imprint>
			<publisher>Erlbaum</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="993" to="1021" />
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Perceiving emotions in neutral faces: Expression processing is biased by affective person knowledge</title>
		<author>
			<persName><forename type="first">F</forename><surname>Suess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rabovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Abdel Rahman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Cognitive and Affective Neuroscience</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="531" to="536" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Faces in context: A review and systematization of contextual influences on affective face processing</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brosch</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2012.00471</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2012.00471" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">471</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Not so harmless anymore: How context impacts the perception and electrocortical processing of neutral faces</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B M</forename><surname>Gerdes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Büngel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mühlberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pauli</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2014.01.022</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2014.01.022" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="74" to="82" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Contextual valence and sociality jointly influence the early and later stages of neutral face processing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2016.01258</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2016.01258" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">1258</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
