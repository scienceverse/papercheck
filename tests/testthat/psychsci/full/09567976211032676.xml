<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Context Impairs Perception of Congruent Objects research-article2022</title>
				<funder>
					<orgName type="full">European Research Council</orgName>
				</funder>
				<funder ref="#_Csuy23T #_XZpPKgu">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_ZwZTmEa">
					<orgName type="full">Vidi</orgName>
				</funder>
				<funder ref="#_Dw9rVCT">
					<orgName type="full">Netherlands Organisation for Scientific Research</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Eelke</forename><surname>Spaak</surname></persName>
							<email>eelke.spaak@donders.ru.nl</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Donders Centre for Cognitive Neuroimaging</orgName>
								<orgName type="department" key="dep2">Donders Institute for Brain</orgName>
								<orgName type="department" key="dep3">Cognition and Behaviour</orgName>
								<orgName type="institution" key="instit1">Radboud University</orgName>
								<orgName type="institution" key="instit2">Radboud University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Donders Centre for Cognitive Neuroimaging</orgName>
								<orgName type="department" key="dep2">Donders Institute for Brain</orgName>
								<orgName type="department" key="dep3">Cognition and Behaviour</orgName>
								<orgName type="institution" key="instit1">Radboud University</orgName>
								<orgName type="institution" key="instit2">Radboud University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Donders Centre for Cognitive Neuroimaging</orgName>
								<orgName type="department" key="dep2">Donders Institute for Brain</orgName>
								<orgName type="department" key="dep3">Cognition and Behaviour</orgName>
								<orgName type="institution" key="instit1">Radboud University</orgName>
								<orgName type="institution" key="instit2">Radboud University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marius</forename><forename type="middle">V</forename><surname>Peelen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Donders Centre for Cognitive Neuroimaging</orgName>
								<orgName type="department" key="dep2">Donders Institute for Brain</orgName>
								<orgName type="department" key="dep3">Cognition and Behaviour</orgName>
								<orgName type="institution" key="instit1">Radboud University</orgName>
								<orgName type="institution" key="instit2">Radboud University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Floris</forename><forename type="middle">P</forename><surname>De Lange</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Donders Centre for Cognitive Neuroimaging</orgName>
								<orgName type="department" key="dep2">Donders Institute for Brain</orgName>
								<orgName type="department" key="dep3">Cognition and Behaviour</orgName>
								<orgName type="institution" key="instit1">Radboud University</orgName>
								<orgName type="institution" key="instit2">Radboud University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Context Impairs Perception of Congruent Objects research-article2022</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">321B269E40E77916A2C770C5DCB8DBDE</idno>
					<idno type="DOI">10.1177/09567976211032676</idno>
					<note type="submission">Received 9/30/20; Revision accepted 6/19/21</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-05-20T20:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>visual perception</term>
					<term>visual attention</term>
					<term>prediction</term>
					<term>perception</term>
					<term>semantic memory</term>
					<term>reaction time</term>
					<term>vision</term>
					<term>visual memory</term>
					<term>open data</term>
					<term>open materials</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Visual scene context is well-known to facilitate the recognition of scene-congruent objects. Interestingly, however, according to predictive-processing accounts of brain function, scene congruency may lead to reduced (rather than enhanced) processing of congruent objects, compared with incongruent ones, because congruent objects elicit reduced prediction-error responses. We tested this counterintuitive hypothesis in two online behavioral experiments with human participants (N = 300). We found clear evidence for impaired perception of congruent objects, both in a change-detection task measuring response times and in a bias-free object-discrimination task measuring accuracy. Congruency costs were related to independent subjective congruency ratings. Finally, we show that the reported effects cannot be explained by low-level stimulus confounds, response biases, or top-down strategy. These results provide convincing evidence for perceptual congruency costs during scene viewing, in line with predictive-processing theory.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Objects are typically encountered in particular contexts; for example, a hair dryer is more commonly encountered in a barbershop than in a grocery store. Semantic associations between real-world scene context and objects within such scenes are well-known to facilitate perception in many circumstances: Objects are located and identified more rapidly and accurately in semantically congruent contexts than in incongruent ones <ref type="bibr" target="#b3">(Bar, 2004;</ref><ref type="bibr" target="#b4">Biederman, 1972;</ref><ref type="bibr" target="#b7">Davenport &amp; Potter, 2004;</ref><ref type="bibr" target="#b20">Kaiser et al., 2019;</ref><ref type="bibr" target="#b30">Oliva &amp; Torralba, 2007)</ref>. These congruency benefits are elegantly explained from the perspective of predictive processing, the idea that the brain is a hypothesis-testing machine <ref type="bibr" target="#b6">(Clark, 2013;</ref><ref type="bibr" target="#b9">de Lange et al., 2018;</ref><ref type="bibr" target="#b14">Friston, 2005;</ref><ref type="bibr" target="#b33">Rao &amp; Ballard, 1999)</ref>: The gist of a (natural) scene induces a prior expectation over particular objects common to such a scene, and stimuli that are likely under that prior are easily integrated with it in order for the brain to arrive at a coherent representation.</p><p>Such an account explains benefits in cases in which the scene-induced expectation is relevant to the task at hand: Observers who are asked to locate a computer mouse in a scene of a desk will naturally look for it next to the keyboard and will thus more quickly find it than if it were presented in a scene of a kitchen countertop. Similarly, in a brief or degraded presentation of such scenes, an oval blob next to a keyboard-shaped blob will more readily be identified as a computer mouse than such a blob in incongruent surroundings. However, according to predictive-processing theories, it is precisely incongruent objects that warrant closest inspection, not congruent ones (specifically, high-precision incongruent objects warrant the closest inspection). The inferred identity of a congruent object is easily integrated with the prior induced by the scene gist, whereas the inferred identity of an incongruent object elicits a larger prediction error. To "resolve" this error (or, equivalently, to leverage the likely high information content afforded by the source of this error signal), observers should associate incongruent objects with more extended processing before integration with the sceneinduced prior is possible. It has been demonstrated that the amount of processing influences the level of subjective awareness <ref type="bibr" target="#b1">(Anzulewicz et al., 2015;</ref><ref type="bibr" target="#b48">Windey et al., 2013)</ref>. Given this assumption and the above reasoning, we hypothesized that in crowded natural scenes with a clear gist-induced prior that is not directly relevant for the current behavioral goals and with multiple objects to be explored ("sampled"), objects in congruent surroundings may be sampled less and therefore perceived less strongly, less saliently, than those in incongruent surroundings.</p><p>Researchers studying change detection have reported such context congruency costs: Observers are slower to detect changes in objects when these objects are embedded within congruent contexts, compared with incongruent ones <ref type="bibr" target="#b17">(Hollingworth &amp; Henderson, 2000;</ref><ref type="bibr" target="#b22">LaPointe et al., 2013;</ref><ref type="bibr" target="#b25">Mack et al., 2017)</ref>. Additionally, it has been reported that, during free viewing, observers tend to fixate earlier on incongruent than on congruent objects <ref type="bibr" target="#b5">(Bonitz &amp; Gordon, 2008;</ref><ref type="bibr" target="#b23">Loftus &amp; Mackworth, 1978;</ref><ref type="bibr" target="#b40">Underwood et al., 2007)</ref>, and other indices of attentional allocation point in the same direction <ref type="bibr" target="#b15">(Gordon, 2004)</ref>.</p><p>However, this reported evidence for congruency costs (or, equivalently, incongruency benefits) is not clear-cut. First, several studies have failed to replicate the earlier fixation latencies for incongruent objects <ref type="bibr" target="#b8">(De Graef et al., 1990;</ref><ref type="bibr" target="#b16">Henderson et al., 1999)</ref>, whereas others have reported the effect only for visually nonsalient objects <ref type="bibr" target="#b39">(Underwood &amp; Foulsham, 2006)</ref>. In general, low-level visual saliency has been described as a potentially confounding factor in the research on attentional attraction by semantic incongruence <ref type="bibr" target="#b39">(Underwood &amp; Foulsham, 2006;</ref><ref type="bibr" target="#b46">Võ &amp; Henderson, 2009)</ref>. A second issue that has received less attention (though see <ref type="bibr" target="#b17">Hollingworth &amp; Henderson, 2000)</ref> but may be equally grave is that congruency costs might reflect a strategic effect: If an incongruent object is present, in many cases it will be task relevant (e.g., the changing object in change detection or something specifically memorable in a memory task), making it beneficial for participants in the experiment to search for incongruent objects in general (leading to an observed congruency cost). Finally, and perhaps most importantly, congruency costs have mainly been demonstrated through latency differences (e.g., change-detection latency) rather than through unbiased measures of perception. Response latency is influenced by multiple factors, including decisional and response biases. Previously reported congruency costs may thus reflect such biases rather than reduced perceptual encoding of congruent objects.</p><p>An intriguing possible implication of the influential idea of neural predictive processing is the existence of congruency costs in purely perceptual (i.e., nonsemantic) tasks, yet this hypothesis has not been tested directly.</p><p>In the present study, we set out to perform this test while taking care of all three concerns voiced above. Importantly, we examined semantic congruency costs in a discrimination task probing object-level (i.e., exemplar) perception free from stimulus, response, semantic, and task-strategic confounds, in addition to a classic changedetection setting. In brief, across these two behavioral experiments, with a total of 300 participants, we found that congruency costs (a) are evident in change detection even with a fully balanced stimulus set, (b) generalize to a more directly perceptual identification task, (c) persist even when attending to incongruent objects is strategically disadvantageous, and (d) are explained by the subjective level of object-scene consistency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stimuli, task, and experimental design</head><p>Experiment 1: change detection. This experiment was a version of the classic change-detection "flicker" task <ref type="bibr" target="#b34">(Rensink et al., 1997)</ref> and is depicted in Figure <ref type="figure" target="#fig_0">1a</ref>. Participants were instructed to detect changes between successive displays of the same scene. Each trial started with an empty screen (500 ms), followed by a fixation button labeled "Go" in the center of the screen that participants</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statement of Relevance</head><p>The theory of the "Bayesian brain," the idea that our brain is a hypothesis-testing machine, has become influential over the past decades. Particularly influential formulations are theories of predictive processing. Such theories may entail that stimuli that are expected, for instance because of the context in which they appear, generate a weaker neural response than unexpected stimuli. Scene context correctly "predicts" congruent scene elements, which should result in lower prediction error. Our study tested this important, counterintuitive, and hitherto not fully tested hypothesis. We found clear evidence in favor of it and demonstrate that these "congruency costs" are indeed evident in perception and not limited to one particular task setting or stimulus set. Because perception in the real world is never of isolated objects but always of entire scenes, these findings are important not just for the Bayesian brain hypothesis but for our understanding of real-world visual perception in general.</p><p>had to click to initiate visual stimulation. Requiring a mouse click in the center of the screen ensured that participants were always fixating the center at stimulus onset. Stimulation consisted of an object-present scene for 250 ms, followed by a 100-ms blank screen and then an objectabsent scene. This sequence was repeated a maximum of 13 times or until participants indicated that they had detected the change by pressing the space bar. After the detection response, a gray rectangle of the same dimensions as the scene stimulus appeared, and participants had to click where they had detected the changed object. This ensured task compliance and prevented blind, rapid pressing of the space bar.</p><p>Stimuli were taken from a recently published, fully balanced stimulus database called SCEGRAM <ref type="bibr" target="#b28">(Öhlschläger &amp; Võ, 2017)</ref>. We used all 62 scenes from the conditions labeled "CON" and "SEM" in the SCEGRAM database (we refer to these conditions here as the "congruent" and "incongruent" conditions, respectively), as well as the corresponding object-absent scenes. This database comprises pairwise balanced stimuli matched in lower level visual features. Each key object occurred in both a congruent context (e.g., a cup in a dishwasher) and an incongruent context (e.g., a cup in a toilet-paper holder) and was matched with another key object similar in shape and orientation that had complementary . This was a typical "flicker" change-detection task, followed by a localization response. Participants clicked the "Go" button to initiate visual stimulation. Stimulation consisted of an object-present scene, followed by a blank screen and then an object-absent scene. This sequence was repeated a maximum of 13 times or until participants indicated that they had detected the change (in this scene, the cup disappeared from the dishwasher). After the detection response, a gray rectangle of the same dimensions as the scene stimulus appeared, and participants had to click where they had detected the changed object. Example stimuli (b) are shown for two scenes, separately for conditions in which the to-be-detected object was congruent and incongruent with the context in which it appeared <ref type="bibr" target="#b28">(Öhlschläger &amp; Võ, 2017)</ref>. congruency mapping (e.g., a toilet-paper roll in either a toilet-paper holder [congruent] or a dishwasher [incongruent]; see Fig. <ref type="figure" target="#fig_0">1b</ref>). Each participant completed 62 trials. Half of these contained congruent scenes, and half contained incongruent scenes. This mapping was counterbalanced across participants. The main dependent variable was change-detection reaction time (RT); localization error was a secondary dependent variable. Localization error was defined in percentage of the target object (e.g., a click located 1 cm away from the center of a 1 cm × 1 cm object would be assigned an error of 100%), and any errors of less than 50% indicated that the observer clicked within the bounds of the target object. Specifically, localization error was defined as follows: For all analyses of RT, we focused only on those change-detection responses for which the subsequent localization error was 100% or less.</p><p>Experiment 2: object identification. For this experiment, instead of having to detect a change, participants were instructed to attentively look at each scene and then make an identification judgment about an object in that scene. Each trial started with a fixation cross (800-1,000 ms, randomly drawn from a uniform distribution) followed by a scene display (2.5 s). After another fixation cross (500 ms), participants were given a two-alternative forced-choice (2AFC) response prompt, which lasted a maximum of 2.5 s or until one of the response keys was pressed (see Fig. <ref type="figure" target="#fig_3">2a</ref>). The 2AFC prompt always consisted of the target item that was present in the scene (again taken from the SCEGRAM stimulus database) as well as a lure item selected through an Internet search. The lure was always from the same category as the target and similar in shape but a clearly different exemplar.</p><p>As in Experiment 1, scenes could occur in a congruent or an incongruent condition. Whether a scene was congruent or incongruent was determined by the nature of the key object in the scene (e.g., the cup or toilet-paper roll in Figs. <ref type="figure" target="#fig_0">1b</ref> and<ref type="figure" target="#fig_3">2</ref>). For Experiment 2, we added a probe (key vs. other) factor, which governed whether, on a given trial, the probe was about this key object or about another object in the same scene. The probed object in probe-other trials was always congruent with the surrounding context (see Fig. <ref type="figure" target="#fig_3">2b</ref>). The rationale for including probe-other trials is twofold. First, this allowed us to control for the strategic concern mentioned in the introduction; that is, if an incongruent object was present, this was no longer necessarily the relevant object <ref type="bibr" target="#b17">(Hollingworth &amp; Henderson, 2000)</ref>. Second, the presence of an irrelevant congruent/incongruent object might draw attention away from the probed target object; this effect should be detectable.</p><p>From the participant's perspective, there was no subjective difference between a congruent/probe-key trial and a congruent/probe-other trial: On both trial types, there were only congruent items present in the scene, and the participant was later probed about one of them. This distinction nevertheless is important because of the design of the stimulus set. Any given congruent/probekey stimulus was matched with an incongruent/probekey stimulus (i.e., the same scene with either a congruent or an incongruent item, where these key items were matched for location, shape, and size). Similarly, any given congruent/probe-other stimulus was matched with an incongruent/probe-other stimulus (i.e., again the same scene with a matched congruent/incongruent item present but where the probe was now about another, nonmanipulated object that was identical across the two levels of congruency). This crossed Probe × Congruency manipulation is very similar to the design used in previous work by <ref type="bibr" target="#b17">Hollingworth and Henderson (2000)</ref>.</p><p>Stimuli were again counterbalanced across participants, each of whom again completed 62 trials. Trials were again 50% congruent and 50% incongruent. Probe × Congruency together formed a 2 × 2 factorial design, but trial counts per cell were deliberately not fully equalized for all participants. Instead, we introduced a between-subjects factor, p(probe key = 1|incongruent = 1), or p(probe key|incongruent) for short, which governed the percentage of incongruent trials that were probe-key trials-that is, given that an incongruent object was present in the scene, p(probe key|incongruent) determined the probability that this object was the taskrelevant one. This factor took on values of 17%, 33%, 50%, 67%, and 83%. For values of the between-subjects factor other than 50% (the fully across-subjects counterbalanced case), a randomly chosen subset (per participant) of incongruent trials was switched from probe-key to probe-other trials or vice versa. This factor allowed us to quantify the degree to which behavioral costs/ benefits were a consequence of task strategy.</p><p>The main dependent variable for this experiment was 2AFC accuracy; RT was of secondary interest. For RT analyses, we focused only on trials with correct responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants, data inclusion, and statistical power</head><p>The experiments were conducted online using the Gorilla platform <ref type="bibr" target="#b0">(Anwyl-Irvine et al., 2020)</ref>, and participants were recruited through the Prolific platform (<ref type="url" target="https://www.prolific.co/">https://www.prolific.co/</ref>). The study was approved by the local ethics committee (Commissie Mensgebonden Onderzoek Arnhem-Nijmegen, Radboud University Medical Center) under the general ethical approval for online studies for the Donders Centre for Cognitive Neuroimaging.</p><p>To increase the signal-to-noise ratio of our data set, we made an a priori decision to remove outliers, which might be especially expected in an online setting. We defined outliers as participants who scored greater than 2.5 standard deviations away from the mean for either dependent variable. Outlier detection was performed on overall scores regardless of condition. For Experiment 1, we recruited 100 participants (49 female, 51 male; age: M = 27.35 years, SD = 5.81), of which three were classified as outliers and removed (see Fig. <ref type="figure" target="#fig_0">S1</ref> in the Supplemental Material available online). The recruitment target was chosen for convenience.</p><p>Effect sizes for similar experiments unfortunately have not been reliably reported in the literature, and where they are reported, they vary widely. Three studies comparing change-detection RTs between congruent and incongruent contexts allowed us to compute effectsize d in two ways. The first is from reported pairedsamples t statistic and sample size ( d t n = / ): d = 1.6 (LaPointe et al., 2013) and d = 0.55 <ref type="bibr" target="#b25">(Mack et al., 2017)</ref>. The second is from reported mean square error and sample size <ref type="bibr" target="#b38">(Thalheimer &amp; Cook, 2002)</ref>: <ref type="bibr" target="#b17">Henderson, 2000)</ref>. However, for reasons noted in the introduction, these effect sizes might be overestimating a potential true effect, and we therefore Participants were shown a natural (indoor) scene and afterward were asked to make a two-alternative forced choice to identify which object had been present in the scene. The two within-subjects manipulations are illustrated in (b). Scenes could be either congruent (left) or incongruent (right), and the probed objects could be either the key object (top) or another object (bottom). Whether a scene was congruent or incongruent was determined by the nature of the key object in the scene (e.g., a toilet-paper roll was congruent with a bathroom scene but incongruent with a kitchen scene).</p><formula xml:id="formula_0">d = 1.1 (Hol- lingworth &amp;</formula><p>cannot assume these to hold for our effect of interest per se. For this reason, we calculated power for an effect that we minimally wanted to be sensitive to. Note that, as mentioned, the sample size for Experiment 1 was chosen for convenience, and we provide the power calculation here only for information. The sample of 97 participants yielded a power of 99.8% for a paired contrast (two tailed) in the case of a medium effect size (d = 0.5) or 49.6% power in the case of a weak effect size (d = 0.2), based on an a priori Type I error rate (α) of .05.</p><p>For Experiment 2, we recruited 200 participants (94 female, 106 male; age: M = 29.85 years, SD = 6.16), resulting in 40 participants for each level of the between-subjects factor. This sample size was chosen to ensure at least 80% power (two tailed) to detect an effect of medium size (d ≥ 0.5) within each level given 34 participants per level, plus margin for potential rejection of unreliable data. Six participants were classified as outliers and removed (see Fig. <ref type="figure">S6</ref> in the Supplemental Material). In addition to the a priori power considerations regarding the paired comparisons, the power to detect the effect of the between-subjects factor is relevant here (which we provide only for information and did not use when determining the sample size). The resulting sample of 194 participants yielded a power of 87.8% (one tailed) to detect a weak correlation (r = .2). None of the participants in Experiment 2 had participated in Experiment 1. All power calculations were performed using G*Power (Version 3.1; <ref type="bibr" target="#b12">Faul et al., 2009)</ref>.</p><p>In addition to detecting outlying participants, we also screened for outlying experimental stimuli (i.e., scenes), again in a condition-agnostic fashion. There were two outlying items in Experiment 1 and zero outlying items in Experiment 2. These items were discarded from further analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data analysis</head><p>All analyses were performed using custom-written scripts in Python (Van Rossum &amp; Drake, 1995) using the NumPy (van der <ref type="bibr" target="#b42">Walt et al., 2011)</ref>, SciPy <ref type="bibr" target="#b45">(Virtanen et al., 2020)</ref>, Pingouin <ref type="bibr" target="#b41">(Vallat, 2018)</ref>, Pandas <ref type="bibr" target="#b26">(McKinney, 2010)</ref>, Matplotlib <ref type="bibr" target="#b18">(Hunter, 2007)</ref>, Seaborn <ref type="bibr" target="#b47">(Waskom et al., 2020)</ref>, PyMC3 <ref type="bibr" target="#b36">(Salvatier et al., 2016)</ref>, ArviZ <ref type="bibr" target="#b21">(Kumar et al., 2019)</ref>, and Bambi <ref type="bibr" target="#b50">(Yarkoni &amp; Westfall, 2016)</ref> libraries. For software package versions, refer to the GitHub link in the Open Practices statement at the end of this article.</p><p>For all pairwise comparisons and correlations, in addition to frequentist statistics such as t values, we report Bayes factors (BFs) quantifying how much more likely the data are under the alternative hypothesis than under the null hypothesis (BF 10 ). BFs were estimated analytically using the following priors for t tests: a Cauchy prior on effect size and a Jeffreys prior on variance, resulting in a Jeffreys-Zellner-Siow ( JZS) BF <ref type="bibr" target="#b19">( Jeffreys, 1998;</ref><ref type="bibr" target="#b35">Rouder et al., 2009;</ref><ref type="bibr" target="#b51">Zellner &amp; Siow, 1980)</ref>. The scale parameter for the Cauchy prior on effect size (r) was set to .33, corresponding to an 80% a priori probability that the observed effect size (d) lies between -1 and +1 (or, equivalently, between 0 and ±1 for a directional test; <ref type="bibr" target="#b37">Schmalz, 2019)</ref>. We chose this on the basis of published effect sizes in similar studies (see above). For the three primary paired contrasts of congruent versus incongruent, we explored the resulting t-based BF 10 values across different plausible levels of Cauchy scale values to verify that our conclusions did not critically depend on the choice for the default. This control analysis is shown in Figure <ref type="figure" target="#fig_3">S12</ref> in the Supplemental Material. BF 10 s for correlations were calculated according to the scheme outlined by <ref type="bibr" target="#b24">Ly et al. (2016)</ref>, with noninformative default priors (i.e., κ = 1) corresponding to a uniform prior distribution over the interval [-1, +1]. Although specifically formulated for Pearson correlations, the same BF 10 calculation was used for Spearman correlations as well, because Spearman correlation is equivalent to Pearson correlation on rank-transformed data <ref type="bibr">(Myers &amp; Well, 2003, p. 508)</ref>.</p><p>In addition to the simple paired comparisons and correlations, we report results from Bayesian hierarchical generalized linear models (also known as mixedeffects or multilevel models) with full random-effects structure. For details on the models and sampling scheme, see Note 1 in the Supplemental Material. Results from these analyses are primarily summarized using 94% highest-density intervals (HDIs).</p><p>Before conducting all statistical analyses (including outlier rejection), we log 10 -transformed bounded variables (RT, localization error) to improve normality and stabilize variance. For all tests with a priori directional hypotheses, we report one-tailed p and BF 10 values; tests without a priori directional hypotheses were conducted using two-tailed values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Congruency costs in change detection with controlled stimuli</head><p>A sample of 100 volunteers participated online in Experiment 1, which was a version of the classic "flicker" change-detection paradigm <ref type="bibr" target="#b34">(Rensink et al., 1997</ref>; see Fig. <ref type="figure" target="#fig_0">1a</ref>) with an added localization response. Importantly, scene changes could occur with either a congruent or an incongruent object, where low-level similarities between conditions were matched as much as possible <ref type="bibr" target="#b28">(Öhlschläger &amp; Võ, 2017</ref>; see Fig. <ref type="figure" target="#fig_0">1b</ref>) and stimuli were counterbalanced across participants.</p><p>Change-detection RTs were well within the maximum of 7.8 s (M = 1,576 ms, SD = 234; see Fig. <ref type="figure" target="#fig_0">S1</ref>), indicating that participants were able to perform the task successfully. This was further corroborated by the localization-error scores, which demonstrate that participants on average were able to locate the item correctly (M = 26.8%, SD = 9.7, where a value &lt; 50% indicates a click inside the key object; see Fig. <ref type="figure" target="#fig_0">S1</ref>). Only 2.10% of total responses had a localization error greater than 100% and were excluded from all RT analyses.</p><p>The key hypothesis that this experiment was designed to test was that change-detection performance suffers when objects are presented in congruent contexts, compared with when objects are presented in incongruent contexts. Specifically, as operationalized here, RTs for congruent trials should be longer than for incongruent trials. This is exactly what we found, t(96) = 4.98, p &lt; .001, d = 0.51, BF 10 = 10,895.21; difference: M = 0.052 log 10 (RT/s), 95% confidence interval (CI) = [0.035, 0.070]; congruent: M = 1.63 s, incongruent: M = 1.51 s, difference = 0.12 s (see Fig. <ref type="figure" target="#fig_0">1c</ref>). Additionally, we found that localization errors were larger on congruent than on incongruent trials, t(96) = 2.44, p = .008, d = 0.25; difference M = 0.020 log 10 , 95% CI = [0.0064, 0.033] (see Fig. <ref type="figure" target="#fig_3">S2</ref> in the Supplemental Material), though the evidence for this effect was only moderate (BF 10 = 5.93).</p><p>Although the stimulus set we used was highly controlled, stimuli were still instances of natural scenes. This improved the ecological validity of the experiment, but it also meant that stimuli were necessarily a sample of all possible scenes that could have been used. This led to variation in the effect across experimental items (see Fig. <ref type="figure" target="#fig_4">S3</ref> in the Supplemental Material). In addition to the null-hypothesis test described above, we therefore conducted a fully Bayesian hierarchical analysis to account for this. In this case, the Bayesian test was analogous to a paired contrast with random intercepts and slopes across both participants and stimulus items. The results of this analysis corroborated the conclusions of the null-hypothesis test: RTs were slower for congruent than for incongruent trials, coefficient posterior M = -0.058 log 10 (RT/s), 94% HDI = [-0.10, -0.010] (see Fig. <ref type="figure" target="#fig_5">S4</ref> in the Supplemental Material). Furthermore, the Bayesian analysis allowed us to generalize our conclusion further: Across both the population from which our participants were drawn and the population from which our stimuli were drawn, we can be 98.71% certain that the RT effect was nonzero. The Bayesian analysis of localization error also yielded a corroboration of the analogous null-hypothesis test, albeit a weaker one (M = -0.021 log 10 , 94% HDI = [-0.046, 0.0061]; see Fig. <ref type="figure" target="#fig_6">S5</ref> in the Supplemental Material), with 92.77% probability that the effect was lower than zero.</p><p>In summary, Experiment 1 provided strong evidence that change detection was impaired when the changing object appeared within a semantically congruent, rather than semantically incongruent, context. We extend the existing literature by showing that this effect persisted even for controlled, matched stimuli.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Congruency costs extend to perceptual identification</head><p>A key motivation for the present research was to investigate whether congruent surroundings have consequences for the perception of the congruent or incongruent key object itself. We therefore conducted a second experiment using the same stimuli as in Experiment 1 but with a different, more directly perceptual task. Two hundred volunteers participated in Experiment 2, in which they had to identify one of two similar objects as having been present in a previously presented scene (see Fig. <ref type="figure" target="#fig_3">2a</ref>). Context was again included as a factor (congruent vs. incongruent), and we additionally included the factor probe (key vs. other), resulting in the addition of trials in which an incongruent object was present but was not the target item (see Fig. <ref type="figure" target="#fig_3">2b</ref>).</p><p>Overall, 2AFC accuracy was clearly above chance level (M = 61.44%, SD = 7.72), and RTs were well within the maximum of 2.5 s (M = 1,226 ms, SD = 216; see Fig. <ref type="figure">S6</ref>), indicating that participants were able to perform the task successfully.</p><p>We found that 2AFC accuracy was significantly lower for congruent trials than for incongruent ones when we focused on the probe-key condition, t(193) = -4.49, p &lt; .001, d = 0.32, BF 10 = 2,733.00; difference: M = -6.18%, 95% CI = [-8.46, -3.90] (see Fig. <ref type="figure" target="#fig_4">3</ref>). There was no difference between congruent and incongruent trials in the probe-other condition, t(193) = -0.23, p = .591, d = 0.02; difference: M = -0.30%, 95% CI = [-2.45, 1.85] (see Fig. <ref type="figure" target="#fig_4">3</ref>), and the data were about 3 times more likely under the null hypothesis of no difference (BF 10 = 0.34). RT data showed a very similar pattern: Responses were slower for congruent than for incongruent trials within the probe-key condition, t(193) = 4.21, p &lt; .001, d = 0.30, BF 10 = 677.40; difference M = 0.053 log 10 (RT/s), 95% CI = [0.032, 0.074]; congruent: M = 1.15 s, incongruent: M = 1.09 s, difference: M = 0.060 s (see Fig. <ref type="figure">S7</ref> in the Supplemental Material), but there was no such difference for the probe-other condition, t(193) = -1.03, p = .152, d = 0.07; difference: M = -0.013 log 10 (RT/s), 95% CI = [-0.035, 0.0080]; congruent: M = 1.21 s, incongruent: M = 1.24 s, difference M = -0.032 s (see Fig. <ref type="figure">S7</ref>), although the evidence for a null effect here was anecdotal at best (BF 10 = 0.54).</p><p>Because Experiment 2 had a 2 × 2 design, it was important to formally test the interaction between the two factors. Additionally, as in Experiment 1, we sought to test the generalization of the observed effects to the population not just of participants but of experimental items as well (for effect spread over items, see Fig. <ref type="figure">S8</ref> in the Supplemental Material). To accomplish these goals, we again conducted a hierarchical Bayesian (logistic) regression analysis of 2AFC accuracy with the key experimental effect captured by the interaction parameter. We found clear evidence for an interaction effect (M = 0.39, 94% HDI = [0.12, 0.65]; see Fig. <ref type="figure">S9</ref> in the Supplemental Material) and a 99.66% probability that the parameter exceeded zero, indicating that participants indeed were more accurate on incongruent trials specifically when probed about the (incongruent) key object and not when probed about another.</p><p>The RT data showed a very similar pattern: Participants were faster on incongruent trials, specifically in the probe-key condition (interaction parameter: M = -0.064 log 10 (RT/s), 94% HDI = [-0.11, -0.014]; see Fig. <ref type="figure" target="#fig_0">S10</ref> in the Supplemental Material), with a probability of 99.24%. RT analysis additionally revealed a main effect of probe, M = -0.060 log 10 (RT/s), 94% HDI = [-0.097, -0.024], indicating that participants were faster to respond on probe-key than on probe-other trials (probability 99.88%). It is possible that the stimuli in the probe-other condition were more difficult than those in the probe-key condition, but given the convincing absence of a main probe effect in 2AFC accuracy (94% HDI = [-0.19, 0.30]), we cannot conclude this with certainty.</p><p>Taken together, we can conclude with considerable confidence that congruency costs are not limited to perceptually indirect measures such as change detection or spatial attention allocation, but they extend to objectexemplar identification and thus have genuine perceptual consequences (for an additional result regarding the possible attentional locus of this effect, see Note 2 in the Supplemental Material).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Congruency costs are not explained by task strategy</head><p>In Experiment 1, as in the majority of previous research on object congruence, if an incongruent item was present in a scene, it was always the task-relevant item. Any congruency costs (or incongruency benefits) might therefore be explained by participants adopting the strategy of always searching for an incongruent object and paying full attention to it. This strategy is effective only on incongruent trials and not on congruent ones, hence potentially causing a general congruency cost. In Experiment 2, we included the probe factor specifically to ensure that incongruent items, when present, were not automatically task relevant (see Fig. <ref type="figure" target="#fig_3">2b</ref>). This factor by itself, in a 2 × 2 balanced design, already ensured that p(probe key = 1|incongruent = 1) was reduced to 50% (from the typical 100%). For the above analysis, p(probe key|incongruent) indeed was 50% on the aggregate, yet we observed that congruency costs persist. Therefore, on the basis of the above, we can already conclude that congruency costs are not exclusively observed in settings in which p(probe key|incongruent) was equal to 100%.</p><p>It is possible that congruency costs, although not abolished, were still attenuated for lower values of p(probe key|incongruent). If this were the case, then the strategic concern described above might still be an issue. For Experiment 2, we manipulated p(probe key|incongruent) across participants to test to what extent the potential confound of task strategy might explain observed congruency costs. We found no effect of p(probe key|incongruent) on task effects in either 2AFC accuracy, Spearman's r(192) = .074, p = .30, 95% CI = [-.067, .21] (see Fig. <ref type="figure" target="#fig_5">4</ref>), or RT, r(192) = -.023, p = .75, 95% CI = [-.16, .12], and the data were about 7 times more likely under the null hypothesis of no correlation for accuracy (BF 10 = 0.15) and about 11 times more likely under the null hypothesis for RT (BF 10 = 0.094).</p><p>Visual inspection of the data (see Fig. <ref type="figure" target="#fig_5">4</ref>) showed that fluctuations in accuracy across p(probe key|incongruent)</p><p>were accompanied by opposite fluctuations in RT, perhaps suggesting variations in speed/accuracy trade-off.</p><p>To account for this, we additionally computed the inverse-efficiency score <ref type="bibr" target="#b43">(Vandierendonck, 2017)</ref>, which also did not show an effect of p(probe key|incongruent), r(192) = .045, p = .53, 95% CI = [-.096, .19], and the data were about 9 times more likely under the null hypothesis (BF 10 = 0.11).</p><p>We finally note that the cell p(probe key|incongruent) = 17% contained relatively few incongruent/probe-key trials per participant; thus, the effect of congruency was estimated less reliably for these participants (e.g., this is evident in the increased error bars in Fig. <ref type="figure" target="#fig_5">4</ref> for this level of the independent variable). For both accuracy and inverse-efficiency score, it may appear as though there was no congruency effect for the 17% cell (or even a negative one), but the data are inconclusive on this point (BF 10 = 0.91 for accuracy; BF 10 = 0.90 for inverse-efficiency score).</p><p>In summary, the persistence of congruency costs on probe-other trials, and in particular the absence of a modulation of congruency costs in response to increasing the task relevance of incongruent objects, is clear evidence that the congruency-cost phenomenon cannot be explained by task-strategic considerations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Change detection and exemplar identification tap into overlapping effects</head><p>A natural question to ask is whether the congruencycost effects identified in both experiments are related. The two experiments were performed using two different samples of participants, yet they employed the same stimulus set. Therefore, to answer this question, we examined this relationship across experimental items. We found that, indeed, the experimental effects were related between the two experiments. For the main dependent variables of change-detection RT (Experiment 1) and 2AFC identification accuracy (Experiment 2), we found clear evidence for a negative correlation across items for congruency difference scores, r(58) = -.35, p = .003, 95% CI = [-.55, -.10], BF 10 = 11.46 (see Fig. <ref type="figure" target="#fig_6">5</ref>). (Note that the negative direction of the effect is explained by positive [or positive changes in] accuracy values indicating better performance, whereas positive [or positive changes in] RT values indicate worse performance.) Correlations between the other dependent variables corroborated this finding: Changedetection-localization performance was highly correlated with identification RT, r(58) = .40, p &lt; .001, 95% CI = [.16, .59], BF 10 = 43.24, whereas the other pairwise correlations were not significant and presented evidence ranging from anecdotal to inconclusive: Experiment 1 RT × Experiment 2 RT: r(58) = .10, p = .21, 95% We can thus conclude that the two perceptual tasks, change detection in Experiment 1 and exemplar identification in Experiment 2, tap into overlapping effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subjective congruency ratings partly explain behavioral performance</head><p>Within the incongruent scenes, there was variation in the extent to which an object might be considered incongruent. This variation was previously established by the authors of the original publication about the stimulus set we used <ref type="bibr" target="#b28">(Öhlschläger &amp; Võ, 2017)</ref>: A separate sample of observers independently rated each of the scene stimuli. In a final, exploratory analysis, we asked whether this variation in incongruency ratings might explain part of the congruency effects we observed. Specifically, we looked at the correlation between subjective inconsistency ratings (where higher means more inconsistent) and behavioral performance across the incongruent scenes. Here, as in the section above, we leveraged variation across experimental items rather than across participants.</p><p>Change-detection RTs in Experiment 1 were not correlated with inconsistency ratings, r(58) = .05, p = .358, 95% CI = [-.21, .30], BF 10 = 0.12 (see Fig. <ref type="figure">6</ref>). However, 2AFC accuracy scores in Experiment 2 were significantly correlated with inconsistency ratings, and higher subjective inconsistency corresponded to better performance, r(60) = .32, p = .005, 95% CI = [.08, .53], BF 10 = 7.67 (see Fig. <ref type="figure">6</ref>). Neither of the secondary dependent variables in the two experiments was significantly correlated with inconsistency ratings (both |r|s &lt; .15, ps &gt; .10, BF 10 s &lt; 0.2; see Fig. <ref type="figure" target="#fig_0">S11</ref> in the Supplemental Material).</p><p>We can conclude that objects within scenes that are rated as subjectively more incongruent by independent observers are easier to identify (Experiment 2), but changes in those objects are not detected faster (Experiment 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In two large-sample behavioral experiments, we tested a counterintuitive consequence of predictive-processing theories of brain function: that scene-induced priors can lead to impaired perception of scene-congruent objects.</p><p>In Experiment 1, we replicated the established congruencycost effect from the change-detection literature while crucially controlling for potential stimulus confounds previously uncontrolled for. More importantly, in Experiment 2, using a task requiring object-exemplar identification, we demonstrated that congruent surroundings impair perception of key objects themselves. By manipulating the percentage of incongruent objects that were relevant, we were able to show that congruency costs are not due to participant strategy but, rather, reflect an automatic perceptual phenomenon.</p><p>Previous studies have reported slower changedetection responses for changes in congruent objects than for changes in incongruent ones <ref type="bibr" target="#b17">(Hollingworth &amp; Henderson, 2000;</ref><ref type="bibr" target="#b22">LaPointe et al., 2013;</ref><ref type="bibr" target="#b25">Mack et al., 2017)</ref>. Eye-tracking studies have additionally reported that scene-incongruent objects are fixated earlier than congruent ones <ref type="bibr" target="#b5">(Bonitz &amp; Gordon, 2008;</ref><ref type="bibr" target="#b23">Loftus &amp; Mackworth, 1978;</ref><ref type="bibr" target="#b40">Underwood et al., 2007)</ref>. It has been debated to what extent these effects are truly due to semantic congruence or might instead be better explained by low-level visual features (e.g., local contrast) differing between conditions <ref type="bibr" target="#b39">(Underwood &amp; Foulsham, 2006;</ref><ref type="bibr" target="#b46">Võ &amp; Henderson, 2009)</ref>. In the present study, we used a stimulus database designed to be highly balanced between the semantically congruent and semantically incongruent conditions <ref type="bibr" target="#b28">(Öhlschläger &amp; Võ, 2017)</ref>. A further advantage of these stimuli is that they were all actual photographs and did not rely on digital image-editing techniques to transplant objects from one context to another. Such digital editing, even when used carefully, might introduce local inconsistencies (e.g., in lighting) that are not exclusively semantic. The results for Experiment 1 demonstrate that congruency costs are evident in change detection even for such controlled stimuli, ruling out worries that this semantic effect might not truly be semantic at all.</p><p>An additional potential concern is that of task strategy. In a typical experimental design with congruent and incongruent trials, if an incongruent object is present in a scene, then it is very likely task relevant (e.g., the locus of change in change detection or specifically memorable in a memory task). Participants might therefore decide to always look for an incongruent object because this will be beneficial in half the trials (and thus in general). This strategy is effective only on incongruent trials, thereby leading to a behavioral benefit in that condition. We quantified this potential strategic effect in Experiment 2 by including trials on which an incongruent object was present but not task relevant. Importantly, we manipulated the percentage of trials on which a presented incongruent object was relevant across participants and found no modulation of congruency costs by this percentage. We can therefore conclude that these congruency costs arise automatically, independent from (deliberate or unconscious) strategic choices. This conclusion is in line with <ref type="bibr" target="#b17">Hollingworth and Henderson's (2000)</ref>  manipulation to our probe (key vs. other) factor. We now crucially extended this work with the manipulation of relevance probability. As described, previous work has identified congruency costs (or, equivalently, incongruency benefits) in perceptually indirect, attentional measures. Perhaps the most important advance made by Experiment 2 over earlier work is that it probed the consequences of scene congruency for object perception itself, through a different task from that previously used, namely, exemplar identification. We used accuracy in a bias-free discrimination task as a dependent variable, thereby enabling us to test whether scene congruency affects perceptual encoding, independently of decisional and response biases. Just as in Experiment 1, we found clear evidence for congruency costs, which were furthermore related to the effect observed during change detection. Congruency costs thus not only reflect nonspecific biases or some peculiarity of change detection but also appear generally during the process of perceiving objects within scenes.</p><p>It is possible that the effects we observed in Experiment 2 were, at least partly, mediated by participants directing their attention (overtly or covertly) to incongruent objects more frequently than to congruent ones. This would be in line with some interpretations of predictive-processing theory, which posit that prediction errors elicited by incongruent objects increase the salience of these objects and thus attract attention <ref type="bibr" target="#b10">(den Ouden et al., 2012;</ref><ref type="bibr" target="#b13">Feldman &amp; Friston, 2010</ref>; see also the next paragraphs). Because we did not measure eye movements, our results do not speak directly for or against this interpretation. The absence of a congruency effect when the key object was irrelevant (probe-other trials; see also Note 2 in the Supplemental Material) provides some circumstantial evidence against spatial attention being the only factor at play here, but further research is needed to determine whether congruency costs, as observed in Experiment 2, are the cause or the consequence of attentional orienting.</p><p>It has been claimed that attentional orienting is best understood as reflecting "active sampling" within the framework of predictive processing <ref type="bibr" target="#b11">(Dey &amp; Gottlieb, 2019;</ref><ref type="bibr" target="#b13">Feldman &amp; Friston, 2010</ref>). An implication of the predictive-processing scheme is that newly incoming data that are unlikely under some prior expectation elicit larger prediction-error responses than stimuli for which prior probability is high. Resolving these errors entails closer inspection (increased attentional sampling) of the corresponding stimuli. An important source of prior information in natural visual perception is the gist of a scene <ref type="bibr" target="#b3">(Bar, 2004;</ref><ref type="bibr" target="#b29">Oliva &amp; Torralba, 2001</ref><ref type="bibr" target="#b18">, 2007)</ref>. Scene gist is typically defined as the holistic semantic information present in a natural image, most commonly operationalized as a category label (in our study, e.g., "kitchen" vs. "bathroom"). Observers can extract scene gist from an image very rapidly before the identification of individual objects, and it is known that scene gist influences the (later or concurrent) processing of objects within a scene <ref type="bibr" target="#b3">(Bar, 2004;</ref><ref type="bibr" target="#b32">Ramkumar et al., 2016)</ref>. The scene gist is naturally interpreted as inducing a prior expectation over objects to be expected within that scene. Congruent objects are easily accommodated by (i.e., a priori likely under) such a prior, whereas incongruent objects should be inspected more closely before a clear perceptual interpretation (i.e., posterior) is arrived at. This difference in amount of processing should have consequences for subjective awareness <ref type="bibr" target="#b1">(Anzulewicz et al., 2015;</ref><ref type="bibr" target="#b48">Windey et al., 2013;</ref><ref type="bibr"></ref> for a schematic outlining the derivation of this hypothesis, see Fig. <ref type="figure" target="#fig_4">S13</ref> in the Supplemental Material). The main motivation for the present study was to test the key hypothesis that gist-induced priors may lead to impaired perception of congruent items. Our results corroborate this hypothesis.</p><p>The Bayesian brain hypothesis is often invoked to explain congruency benefits in perception <ref type="bibr" target="#b9">(de Lange et al., 2018)</ref>, for which ample empirical evidence exists. Nevertheless, we report robust congruency costs. These seemingly contradictory claims are reconciled by noting that congruency benefits in scene perception are typically reported for tasks in which the gist-induced prior is, by itself, already helpful for behavior. After the gist of a scene is recognized as corresponding to a barbershop, observers will more likely identify objects inside that scene as hair dryers, even independently from the associated sensory input. Similarly, observers can use gist-based knowledge to efficiently guide a search for a hair dryer-knowledge that is unavailable when searching for a hammer in the same scene. In contrast to category identification or visual search, change detection is a nonsemantic task, in which scene gist cannot inform the judgment to be made. We deliberately designed Experiment 2 to similarly involve a judgment orthogonal to any scene-induced prior, and as predicted, this revealed congruency costs rather than benefits.</p><p>The apparent paradox between congruency benefits in some settings and congruency costs in others (or, more generally, predictive upweighting vs. cancellation) is an active area of debate and research. A recently proposed "opposing-process" model is designed to resolve this paradox by positing that perception is initially biased toward a priori likely stimuli, whereas later processes shift this balance toward (high-precision) unexpected (and thus informative) inputs <ref type="bibr" target="#b31">(Press et al., 2020)</ref>. Our observations can be neatly accommodated within this framework: High-precision sensory input corresponding to incongruent objects results in informative prediction errors, thus "divert[ing] extra perceptual processing resources to the unexpected" <ref type="bibr">(Press et al., 2020, p. 18)</ref>, leading to the observed impaired perception of congruent objects.</p><p>Finally, we would like to emphasize that in addition to presenting frequentist null-hypothesis tests, we consistently tested our key hypotheses using Bayesian hierarchical models with full random effects. This allowed us to formally generalize our conclusions not just to the population from which our participants were drawn but also to the population from which our stimuli were drawn <ref type="bibr" target="#b2">(Arnqvist, 2020;</ref><ref type="bibr" target="#b49">Yarkoni, 2020)</ref>, lending further support to the generality of our findings.</p><p>In summary, we tested an important and seemingly counterintuitive hypothesis of the influential idea of neural predictive processing: that prior information due to real-world scene gist can lead to reduced processing of objects congruent within such scenes. Across two experiments with distinct experimental tasks, we found clear evidence in favor of this hypothesis, thereby furthering our understanding of how prior knowledge interacts with sensory input to yield real-world percepts and guide behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transparency</head><p>Action Editor: Krishnankutty Sathian Editor: Patricia J. Bauer</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Design and key results for Experiment 1. The structure and timeline of a single experimental trial is shown in (a). This was a typical "flicker" change-detection task, followed by a localization response. Participants clicked the "Go" button to initiate visual stimulation. Stimulation consisted of an object-present scene, followed by a blank screen and then an object-absent scene. This sequence was repeated a maximum of 13 times or until participants indicated that they had detected the change (in this scene, the cup disappeared from the dishwasher). After the detection response, a gray rectangle of the same dimensions as the scene stimulus appeared, and participants had to click where they had detected the changed object. Example stimuli (b) are shown for two scenes, separately for conditions in which the to-be-detected object was congruent and incongruent with the context in which it appeared<ref type="bibr" target="#b28">(Öhlschläger &amp; Võ, 2017)</ref>. Red outlines (not shown to participants) indicate the key object (cup/toilet-paper roll in dishwasher vs. cup/toilet-paper roll in toilet-paper holder). Reaction time (RT) results are shown in (c). The scatterplot shows RT on congruent trials and RT on incongruent trials for all participants. Shaded areas indicate the density of the data (darker = denser). The graph on the right shows the mean difference between RT on congruent and incongruent trials (congruentincongruent); the error bar shows the 95% confidence interval.</figDesc><graphic coords="3,72.55,353.71,88.26,66.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Fig.1. Design and key results for Experiment 1. The structure and timeline of a single experimental trial is shown in (a). This was a typical "flicker" change-detection task, followed by a localization response. Participants clicked the "Go" button to initiate visual stimulation. Stimulation consisted of an object-present scene, followed by a blank screen and then an object-absent scene. This sequence was repeated a maximum of 13 times or until participants indicated that they had detected the change (in this scene, the cup disappeared from the dishwasher). After the detection response, a gray rectangle of the same dimensions as the scene stimulus appeared, and participants had to click where they had detected the changed object. Example stimuli (b) are shown for two scenes, separately for conditions in which the to-be-detected object was congruent and incongruent with the context in which it appeared<ref type="bibr" target="#b28">(Öhlschläger &amp; Võ, 2017)</ref>. Red outlines (not shown to participants) indicate the key object (cup/toilet-paper roll in dishwasher vs. cup/toilet-paper roll in toilet-paper holder). Reaction time (RT) results are shown in (c). The scatterplot shows RT on congruent trials and RT on incongruent trials for all participants. Shaded areas indicate the density of the data (darker = denser). The graph on the right shows the mean difference between RT on congruent and incongruent trials (congruentincongruent); the error bar shows the 95% confidence interval.</figDesc><graphic coords="3,175.30,353.71,88.26,66.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FixationFig. 2 .</head><label>2</label><figDesc>Fig.2. Design for Experiment 2. The structure and timeline of a single experimental trial is shown in (a). Participants were shown a natural (indoor) scene and afterward were asked to make a two-alternative forced choice to identify which object had been present in the scene. The two within-subjects manipulations are illustrated in (b). Scenes could be either congruent (left) or incongruent (right), and the probed objects could be either the key object (top) or another object (bottom). Whether a scene was congruent or incongruent was determined by the nature of the key object in the scene (e.g., a toilet-paper roll was congruent with a bathroom scene but incongruent with a kitchen scene).</figDesc><graphic coords="5,101.27,336.92,105.02,78.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Two-alternative forced-choice accuracy for Experiment 2. The scatterplots show accuracy in congruent trials and incongruent trials, separately for the probe-key and probe-other conditions. Shaded areas indicate the density of the data (darker = denser). The graph on the right shows the mean difference in accuracy between congruent and incongruent trials for each probe condition; error bars show 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Congruency effects in Experiment 2. The mean congruency difference score (congruent -incongruent) is shown for each level of p(probe key|incongruent): the two main dependent variables (twoalternative forced-choice [2AFC] accuracy and reaction time [RT]), as well as a combined metric, inverse-efficiency score (IES). Error bars show 95% confidence intervals, and shading reflects the 95% confidence interval of the effect across the entire sample.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Relation between the congruency effects for exemplar identification (Experiment 2) and change detection (Experiment 1). Two-alternative forced-choice (2AFC) accuracy (top row) and reaction time (bottom row) in Experiment 2 are shown as a function of reaction time (left column) and localization error (right column) in Experiment 1. Lines indicate bestfitting regressions of the 2AFC effect onto the change-detection effect, and the error band around each regression line indicates the 95% confidence interval. Shaded areas around the data points indicate the density of the data (darker = denser).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>work, which included a similar</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Items</cell></row><row><cell>Change Detection</cell><cell cols="2">Reaction Time (log 10 (RT/s))</cell><cell>0 1</cell></row><row><cell>Exemplar Identification</cell><cell>Accuracy (%)</cell><cell cols="2">50 100</cell></row><row><cell></cell><cell></cell><cell></cell><cell>2</cell><cell>4</cell><cell>6</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Inconsistency Rating</cell></row><row><cell cols="4">Fig. 6. Behavioral performance for Experiment 1 (change detec-</cell></row><row><cell cols="4">tion) and Experiment 2 (exemplar identification) as a function of</cell></row><row><cell cols="4">subjective inconsistency rating. Subjective inconsistency ratings for</cell></row><row><cell cols="4">each experimental item were provided by an independent sample of</cell></row><row><cell cols="4">observers and collected by Öhlschläger and Võ (2017). Higher ratings</cell></row><row><cell cols="4">indicate stronger inconsistency (i.e., lower object/scene consistency).</cell></row><row><cell cols="4">Data points are for individual items (incongruent scenes only). Lines</cell></row><row><cell cols="4">indicate best-fitting regressions, and the error band around each</cell></row><row><cell cols="4">regression line indicates the 95% confidence interval. Shaded areas</cell></row><row><cell cols="4">around the data points indicate the density of the data (darker =</cell></row><row><cell cols="4">denser). RT = reaction time.</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><head>Funding</head><p>This work was supported by The <rs type="funder">Netherlands Organisation for Scientific Research</rs> (<rs type="grantName">NWO Veni Grant</rs> <rs type="grantNumber">016.Veni.198.065</rs> awarded to <rs type="person">E. Spaak</rs> and <rs type="funder">Vidi</rs> Grant <rs type="grantNumber">452-13-016</rs> awarded to F. P. de Lange) and by the <rs type="funder">European Research Council</rs> under the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020 program for research and innovation</rs> (Grant No. <rs type="grantNumber">725970</rs> to <rs type="person">M. V. Peelen</rs> and Grant No. <rs type="grantNumber">678286</rs> to F. P. de Lange). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></div>
<div><head>Open Practices</head><p>All data and experimental stimuli for both experiments have been made publicly available via the Donders Repository and can be accessed at <ref type="url" target="https://doi.org/10.34973/x6fy-4q26">https://doi.org/10.34973/x6fy-4q26</ref>. All analysis code is available from GitHub at <ref type="url" target="https://github.com/Spaak/context-congruency">https:// github.com/Spaak/context-congruency</ref>. The design and analysis plans for the experiments were not preregistered. This article has received the badges for Open Data and Open Materials. More information about the Open Practices badges can be found at <ref type="url" target="http://www.psychologicalscience.org/publications/badges">http://www.psychologi calscience.org/publications/badges</ref>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Dw9rVCT">
					<idno type="grant-number">016.Veni.198.065</idno>
					<orgName type="grant-name">NWO Veni Grant</orgName>
				</org>
				<org type="funding" xml:id="_ZwZTmEa">
					<idno type="grant-number">452-13-016</idno>
				</org>
				<org type="funding" xml:id="_Csuy23T">
					<idno type="grant-number">725970</idno>
					<orgName type="program" subtype="full">Horizon 2020 program for research and innovation</orgName>
				</org>
				<org type="funding" xml:id="_XZpPKgu">
					<idno type="grant-number">678286</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Author Contributions M. V. Peelen and F. P. de Lange contributed equally to this study. All the authors contributed to the study design. E. Spaak developed the study concept, implemented the experiments, and collected and analyzed the data. All the authors interpreted the results. E. Spaak wrote the first draft of the manuscript, and all the authors contributed to revisions and approved the final manuscript for submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflicting Interests</head><p>The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplemental Material</head><p>Additional supporting information can be found at <ref type="url" target="http://journals.sagepub.com/doi/suppl/10.1177/09567976211032676">http:// journals.sagepub.com/doi/suppl/10.1177/09567976211032676</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Gorilla in our midst: An online behavioral experiment builder</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Anwyl-Irvine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Massonnié</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Flitton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kirkham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Evershed</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-019-01237-x</idno>
		<ptr target="https://doi.org/10.3758/s13428-019-01237-x" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="388" to="407" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Does level of processing affect the transition from unconscious to conscious perception?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anzulewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Asanowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Windey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Paulewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">´</forename><surname>Wierzchon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cleeremans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.concog.2015.05.004</idno>
		<ptr target="https://doi.org/10.1016/j.concog.2015.05.004" />
	</analytic>
	<monogr>
		<title level="j">Consciousness and Cognition</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mixed models offer no freedom from degrees of freedom</title>
		<author>
			<persName><forename type="first">G</forename><surname>Arnqvist</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tree.2019.12.004</idno>
		<ptr target="https://doi.org/10.1016/j.tree.2019.12.004" />
	</analytic>
	<monogr>
		<title level="j">Trends in Ecology &amp; Evolution</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="329" to="335" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Visual objects in context</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bar</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn1476</idno>
		<ptr target="https://doi.org/10.1038/nrn1476" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="617" to="629" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Perceiving real-world scenes</title>
		<author>
			<persName><forename type="first">I</forename><surname>Biederman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="issue">4043</biblScope>
			<biblScope unit="page" from="77" to="80" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Attention to smokingrelated and incongruous objects during scene viewing</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Bonitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Gordon</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.actpsy.2008.08.006</idno>
		<ptr target="https://doi.org/10.1016/j.actpsy.2008.08.006" />
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="255" to="263" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Whatever next? Predictive brains, situated agents, and the future of cognitive science</title>
		<author>
			<persName><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X12000477</idno>
		<ptr target="https://doi.org/10.1017/S0140525X12000477" />
	</analytic>
	<monogr>
		<title level="j">Behavioral &amp; Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="204" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Scene consistency in object and background perception</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Davenport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Potter</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.0956-7976.2004.00719.x</idno>
		<ptr target="https://doi.org/10.1111/j.0956-7976.2004.00719.x" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="559" to="564" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Perceptual effects of scene context on object identification</title>
		<author>
			<persName><forename type="first">P</forename><surname>De Graef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Christiaens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ydewalle</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF00868064</idno>
		<ptr target="https://doi.org/10.1007/BF00868064" />
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="317" to="329" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">How do expectations shape perception</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Heilbron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kok</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2018.06.002</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2018.06.002" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="764" to="779" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">How prediction errors shape perception, attention, and motivation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E M</forename><surname>Den Ouden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>De Lange</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2012.00548</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2012.00548" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">548</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Attention, information-seeking, and active sampling: Empirical evidence and applications for learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gottlieb</surname></persName>
		</author>
		<idno type="DOI">10.1017/9781316823279.010</idno>
		<ptr target="https://doi.org/10.1017/9781316823279.010" />
	</analytic>
	<monogr>
		<title level="m">The Cambridge handbook of motivation and learning</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Renninger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Hidi</surname></persName>
		</editor>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="183" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Statistical power analyses using G*Power 3.1: Tests for correlation and regression analyses</title>
		<author>
			<persName><forename type="first">F</forename><surname>Faul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Erdfelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-G</forename><surname>Lang</surname></persName>
		</author>
		<idno type="DOI">10.3758/BRM.41.4.1149</idno>
		<ptr target="https://doi.org/10.3758/BRM.41.4.1149" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1149" to="1160" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Attention, uncertainty, and free-energy</title>
		<author>
			<persName><forename type="first">H</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2010.00215</idno>
		<ptr target="https://doi.org/10.3389/fnhum.2010.00215" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">215</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A theory of cortical responses</title>
		<author>
			<persName><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<idno type="DOI">10.1098/rstb.2005.1622</idno>
		<ptr target="https://doi.org/10.1098/rstb.2005.1622" />
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">360</biblScope>
			<biblScope unit="issue">1456</biblScope>
			<biblScope unit="page" from="815" to="836" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Attentional allocation during the perception of scenes</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Gordon</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-1523.30.4.760</idno>
		<ptr target="https://doi.org/10.1037/0096-1523.30.4.760" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="760" to="777" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The effects of semantic consistency on eye movements during complex scene viewing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Weeks</surname></persName>
		</author>
		<author>
			<persName><surname>Jr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hollingworth</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-1523.25.1.210</idno>
		<ptr target="https://doi.org/10.1037/0096-1523.25.1.210" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="210" to="228" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semantic informativeness mediates the detection of changes in natural scenes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hollingworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Henderson</surname></persName>
		</author>
		<idno type="DOI">10.1080/135062800394775</idno>
		<ptr target="https://doi.org/10.1080/135062800394775" />
	</analytic>
	<monogr>
		<title level="j">Visual Cognition</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="213" to="235" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Matplotlib: A 2D graphics environment</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hunter</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCSE.2007.55</idno>
		<ptr target="https://doi.org/10.1109/MCSE.2007" />
	</analytic>
	<monogr>
		<title level="j">Computing in Science Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="90" to="95" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Jeffreys</surname></persName>
		</author>
		<title level="m">The theory of probability</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>3rd ed.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Object vision in a structured world</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Quek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Cichy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Peelen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2019.04.013</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2019.04.013" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="672" to="685" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">ArviZ a unified library for exploratory analysis of Bayesian models in Python</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hartikainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Martin</surname></persName>
		</author>
		<idno type="DOI">10.21105/joss.01143</idno>
		<ptr target="https://doi.org/10.21105/joss.01143" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">33</biblScope>
			<biblScope unit="page">1143</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Context congruency effects in change detection: Opposing effects on detection and identification</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R P</forename><surname>Lapointe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lupianez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Milliken</surname></persName>
		</author>
		<idno type="DOI">10.1080/13506285.2013.787133</idno>
		<ptr target="https://doi.org/10.1080/13506285.2013.787133" />
	</analytic>
	<monogr>
		<title level="j">Visual Cognition</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="99" to="122" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Cognitive determinants of fixation location during picture viewing</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Loftus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Mackworth</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-1523.4.4.565</idno>
		<ptr target="https://doi.org/10.1037/0096-1523.4.4.565" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="565" to="572" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Harold Jeffreys&apos;s default Bayes factor hypothesis tests: Explanation, extension, and application in psychology</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jmp.2015.06.004</idno>
		<ptr target="https://doi.org/10.1016/j.jmp.2015.06.004" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="19" to="32" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Scene incongruity and attention</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Erol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bert</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.concog.2016.10.010</idno>
		<ptr target="https://doi.org/10.1016/j.concog.2016.10.010" />
	</analytic>
	<monogr>
		<title level="j">Consciousness and Cognition</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="87" to="103" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Data structures for statistical computing in Python</title>
		<author>
			<persName><forename type="first">W</forename><surname>Mckinney</surname></persName>
		</author>
		<idno type="DOI">10.25080/Majora-92bf1922-00a</idno>
		<ptr target="https://doi.org/10.25080/Majora-92bf1922-00a" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Python in Science Conference</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Van Der Walt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">J</forename><surname>Millman</surname></persName>
		</editor>
		<meeting>the 9th Python in Science Conference</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="56" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Well</surname></persName>
		</author>
		<ptr target="http://archive.org/details/researchdesignst00jero_935" />
		<title level="m">Research design and statistical analysis</title>
		<imprint>
			<publisher>Erlbaum</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SCEGRAM: An image database for semantic and syntactic inconsistencies in scenes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Öhlschläger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Võ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-H</forename></persName>
		</author>
		<idno type="DOI">10.3758/s13428-016-0820-3</idno>
		<ptr target="https://doi.org/10.3758/s13428-016-0820-3" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1780" to="1791" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Modeling the shape of the scene: A holistic representation of the spatial envelope</title>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1011139631724</idno>
		<ptr target="https://doi.org/10.1023/A:1011139631724" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="145" to="175" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The role of context in object recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2007.09.009</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2007.09.009" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="520" to="527" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The perceptual prediction paradox</title>
		<author>
			<persName><forename type="first">C</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yon</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2019.11.003</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2019.11.003" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="24" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Visual information representation and rapidscene categorization are simultaneous across cortex: An MEG study</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ramkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pannasch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Loschky</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2016.03.027</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2016.03.027" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="295" to="304" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Predictive coding in the visual cortex: A functional interpretation of some extraclassical receptive-field effects</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P N</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
		<idno type="DOI">10.1038/4580</idno>
		<ptr target="https://doi.org/10.1038/4580" />
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="87" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">To see or not to see: The need for attention to perceive changes in scenes</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Rensink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>O'regan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9280.1997.tb00427.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-9280.1997.tb00427.x" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="368" to="373" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Bayesian t tests for accepting and rejecting the null hypothesis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Speckman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Morey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Iverson</surname></persName>
		</author>
		<idno type="DOI">10.3758/PBR.16.2.225</idno>
		<ptr target="https://doi.org/10.3758/PBR.16.2.225" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="225" to="237" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Proba bilistic programming in Python using PyMC3</title>
		<author>
			<persName><forename type="first">J</forename><surname>Salvatier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">V</forename><surname>Wiecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fonnesbeck</surname></persName>
		</author>
		<idno type="DOI">10.7717/peerj-cs.55</idno>
		<ptr target="https://doi.org/10.7717/peerj-cs" />
	</analytic>
	<monogr>
		<title level="j">PeerJ Computer Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Schmalz</surname></persName>
		</author>
		<ptr target="http://xeniaschmalz.blogspot.com/2019/09/justifying-bayesian-prior-parameters-in.html" />
		<title level="m">Bayes factors 101: Justifying prior parameters in JASP. Xenia Schmalz&apos;s Blog</title>
		<imprint>
			<date type="published" when="2019-09-12">2019, September 12</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">How to calculate effect sizes from published research articles: A simplified methodology</title>
		<author>
			<persName><forename type="first">W</forename><surname>Thalheimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Work-Learning Research</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Visual saliency and semantic incongruency influence eye movements when inspecting pictures</title>
		<author>
			<persName><forename type="first">G</forename><surname>Underwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Foulsham</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470210500416342</idno>
		<ptr target="https://doi.org/10.1080/17470210500416342" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1931" to="1949" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Congruency, saliency and gist in the inspection of objects in natural scenes</title>
		<author>
			<persName><forename type="first">G</forename><surname>Underwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Humphreys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cross</surname></persName>
		</author>
		<idno type="DOI">10.1016/B978-008044980-7/50028-8</idno>
		<ptr target="https://doi.org/10.1016/B978-008044980-7/50028-8" />
	</analytic>
	<monogr>
		<title level="m">Eye movements: A window on mind and brain</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">P G</forename><surname>Van Gompel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Fischer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Murray</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Hill</surname></persName>
		</editor>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="563" to="579" />
		</imprint>
	</monogr>
	<note>IV-VII</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Pingouin: Statistics in Python</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vallat</surname></persName>
		</author>
		<idno type="DOI">10.21105/joss.01026</idno>
		<ptr target="https://doi.org/10.21105/joss.01026" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">31</biblScope>
			<biblScope unit="page">1026</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The NumPy array: A structure for efficient numerical computation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Van Der Walt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Colbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCSE.2011.37</idno>
		<ptr target="https://doi.org/10.1109/MCSE.2011" />
	</analytic>
	<monogr>
		<title level="j">Computing in Science Engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="22" to="30" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A comparison of methods to combine speed and accuracy measures of performance: A rejoinder on the binning procedure</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vandierendonck</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-016-0721-5</idno>
		<ptr target="https://doi.org/10.3758/s13428-016-0721-5" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="653" to="673" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Python tutorial</title>
		<author>
			<persName><forename type="first">G</forename><surname>Van Rossum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Drake</surname></persName>
		</author>
		<author>
			<persName><surname>Jr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>Centrum voor Wiskunde en Informatica</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">SciPy 1.0: Fundamental algorithms for scientific computing in Python</title>
		<author>
			<persName><forename type="first">P</forename><surname>Virtanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gommers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Oliphant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haberland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Burovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Weckesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Van Der Walt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jarrod Millman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mayorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R J</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Larson</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41592-019-0686-2</idno>
		<ptr target="https://doi.org/10.1038/s41592-019-0686-2" />
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="261" to="272" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>SciPy 1.0 Contributors</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Does gravity matter? Effects of semantic and syntactic inconsistencies on the allocation of attention during scene perception</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Võ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-H</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename></persName>
		</author>
		<idno type="DOI">10.1167/9.3.24</idno>
		<ptr target="https://doi.org/10.1167/9.3.24" />
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">mwaskom/ seaborn: V0.10.1</title>
		<author>
			<persName><forename type="first">M</forename><surname>Waskom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Botvinnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ostblom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gelbart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lukauskas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Gemperline</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Augspurger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Halchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Warmenhoven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>De Ruiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Villalba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Quintero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">, .</forename><surname>Bachant</surname></persName>
		</author>
		<author>
			<persName><surname>Brian</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3767070</idno>
		<ptr target="https://doi.org/10.5281/zenodo.3767070" />
		<imprint>
			<date type="published" when="2020-04">2020. April 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Subjective visibility depends on level of processing</title>
		<author>
			<persName><forename type="first">B</forename><surname>Windey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cleeremans</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2013.07.012</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2013.07.012" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="404" to="409" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The generalizability crisis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yarkoni</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X20001685</idno>
		<ptr target="https://doi.org/10.1017/S0140525X20001685" />
	</analytic>
	<monogr>
		<title level="j">Behavioral &amp; Brain Sciences</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Advance online</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Bambi: A simple interface for fitting Bayesian mixed effects models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yarkoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Westfall</surname></persName>
		</author>
		<idno type="DOI">10.31219/osf.io/rv7sn</idno>
		<ptr target="https://doi.org/10.31219/osf.io/rv7sn" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Posterior odds ratios for selected regression hypotheses</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zellner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Siow</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02888369</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="j">Trabajos de Estadistica y de Investigacion Operativa</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="585" to="603" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
