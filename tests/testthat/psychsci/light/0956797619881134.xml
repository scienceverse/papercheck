<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reading Increases the Compositionality of Visual Word Representations</title>
				<funder>
					<orgName type="full">Department of Biotechnology-Indian Institute of Science (IISc) Partnership Programme</orgName>
				</funder>
				<funder ref="#_3yTPS4K">
					<orgName type="full">Tata Trusts</orgName>
				</funder>
				<funder>
					<orgName type="full">Carnegie Mellon University-IISc BrainHub</orgName>
				</funder>
				<funder>
					<orgName type="full">Intermediate and Senior Fellowships</orgName>
				</funder>
				<funder ref="#_uE3X7Mr">
					<orgName type="full">Wellcome Trust/DBT India Alliance</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Arun</surname></persName>
							<email>sparun@iisc.ac.in</email>
							<affiliation key="aff3">
								<orgName type="department">Centre for Neuroscience</orgName>
								<orgName type="institution">Indian Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aakash</forename><surname>Agrawal</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Centre for BioSystems Science and Engineering</orgName>
								<orgName type="institution">Indian Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">K</forename><forename type="middle">V S</forename><surname>Hari</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Electrical Communication Engineering</orgName>
								<orgName type="institution">Indian Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Centre for Neuroscience</orgName>
								<orgName type="institution">Indian Institute of Science</orgName>
								<address>
									<postCode>560012</postCode>
									<settlement>Bangalore</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reading Increases the Compositionality of Visual Word Representations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">52DECF75DAEFDD39BFB04630125257BC</idno>
					<idno type="DOI">10.1177/0956797619881134</idno>
					<note type="submission">Received 4/17/19; Revision accepted 8/22/19</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-01-26T20:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>reading</term>
					<term>object recognition</term>
					<term>visual search</term>
					<term>neuroimaging</term>
					<term>open data</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Reading causes widespread changes in the brain, but its effect on visual word representations is unknown. Learning to read may facilitate visual processing by forming specialized detectors for longer strings or by making word responses more predictable from single letters-that is, by increasing compositionality. We provided evidence for the latter hypothesis using experiments that compared nonoverlapping groups of readers of two Indian languages (Telugu and Malayalam). Readers showed increased single-letter discrimination and decreased letter interactions for bigrams during visual search. Importantly, these interactions predicted subjects' overall reading fluency. In a separate brainimaging experiment, we observed increased compositionality in readers, whereby responses to bigrams were more predictable from single letters. This effect was specific to the anterior lateral occipital region, where activations best matched behavior. Thus, learning to read facilitates visual processing by increasing the compositionality of visual word representations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Reading a word involves processing its visual form, associating it with spoken sounds, and processing its overall meaning. Consequently, learning to read alters a variety of brain systems, including the visual, auditory, and language regions <ref type="bibr" target="#b11">(Dehaene, Cohen, Morais, &amp; Kolinsky, 2015)</ref>. In particular, reading has a profound influence on the visual regions. It leads to the formation of the visual word-form area (VWFA) in the left occipitotemporal sulcus; the VWFA is selectively activated by words of familiar scripts and by intact words over scrambled controls, and activation levels in this region predict reading fluency <ref type="bibr" target="#b11">(Dehaene et al., 2015)</ref>. But reading also causes widespread changes throughout the visual cortex, as shown by greater activation for intact words relative to scrambled controls <ref type="bibr">(Dehaene &amp; Cohen, 2011;</ref><ref type="bibr" target="#b13">Dehaene et al., 2010;</ref><ref type="bibr" target="#b22">Lochy et al., 2018;</ref><ref type="bibr" target="#b38">Szwed et al., 2011)</ref> as well as for familiar over unfamiliar scripts <ref type="bibr" target="#b1">(Bai, Shi, Jiang, He, &amp; Weng, 2011;</ref><ref type="bibr" target="#b2">Baker et al., 2007;</ref><ref type="bibr" target="#b21">Krafnick et al., 2016;</ref><ref type="bibr" target="#b39">Szwed, Qiao, Jobert, Dehaene, &amp; Cohen, 2014)</ref>. Despite these insights, several fundamental questions remain regarding how reading affects letter and word representations. Does reading alter single-letter representations? Does it alter word representations beyond the effect on single letters? These questions have been difficult to answer for two reasons. First, letter representations with and without reading expertise are difficult to characterize because many Western languages use the same script, making it difficult to find subjects fluent in distinct scripts without introducing confounding factors such as phonological mapping, writing systems, and literacy <ref type="bibr" target="#b11">(Dehaene et al., 2015)</ref>. Indian languages offer a unique opportunity to investigate these issues because of their diverse alphabetic scripts with shared phonological mapping and writing systems <ref type="bibr" target="#b27">(Nag, 2017)</ref>. This makes it possible for researchers to compare subjects proficient in reading distinct scripts while holding constant other confounding factors.</p><p>Second, to characterize changes in word representations, it is critical to establish a quantitative model to relate word responses to letter responses. According to an influential account, reading facilitates visual processing through the formation of specialized local combination detectors <ref type="bibr" target="#b12">(Dehaene, Cohen, Sigman, &amp; Vinckier, 2005)</ref>. These combination detectors respond to frequently occurring bigrams (e.g., "TH") and longer strings. Evidence in favor of this account comes from the increased activation of the VWFA as letter strings become orthographically similar to real words <ref type="bibr" target="#b6">(Binder, Medler, Westbury, Liebenthal, &amp; Buchanan, 2006;</ref><ref type="bibr" target="#b22">Lochy et al., 2018;</ref><ref type="bibr" target="#b38">Szwed et al., 2011;</ref><ref type="bibr" target="#b42">Vinckier et al., 2007)</ref>. However, these results are based on comparing letter strings equated for mean letter frequency. These matched letter strings may contain letters of disparate frequencies or medium frequencies at different positions, which could elicit different responses simply because of letterfrequency and position effects <ref type="bibr" target="#b33">(Scaltritti, Dufau, &amp; Grainger, 2018)</ref>. Thus, local combination detectors must be invoked only if responses to bigrams cannot be explained using the constituent letters.</p><p>An alternative account is that reading might increase compositionality (i.e., make bigrams and longer strings more predictable from single letters). These two accounts make opposite predictions as to how the response to a bigram relates to the constituent letters: If reading leads to the formation of local combination detectors, the response to a bigram will be less predictable from the individual letters. If reading leads to increased compositionality, the response will be more predictable. We evaluated these predictions using a combination of behavioral and neuroimaging experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>All subjects had normal or corrected-to-normal vision and gave written informed consent to the experimental protocols, which were approved by the Indian Institute of Science Institutional Human Ethics Committee. Subjects had similar educational status: They were all undergraduate or graduate students at the Indian Institute of Science. All subjects were fluent in English and were fluent in reading either Telugu or Malayalam (but not both).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fluency test</head><p>Subjects were asked to perform a brief fluency test along with every experiment. In this test, a passage of text was shown to the subject in his or her known script (Telugu or Malayalam). In both languages, this passage described how the head of an Indian village introduced computers to the village and employed software professionals to train residents. This passage was prepared by translating the same English passage into both languages. Subjects were asked to silently read the passage on a computer screen and press a button after they finished reading it. After this, a dialogue box appeared, and subjects were asked to summarize the passage in English. This summary was reviewed off-line by the first author to confirm that the subjects indeed comprehended the passage. The time taken by subjects for the button press was taken as a measure of reading fluency. All but 2 subjects from Experiment 3 participated in the fluency test. A minority of the subjects (n = 4) declared afterward that they had read the passage multiple times to memorize it, so their data were excluded from subsequent fluency analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1 (single letters)</head><p>A total of 39 subjects (28 males; age: M = 25 years, SD = 4; 19 Telugu, 20 Malayalam) participated in this experiment. Here and in all visual search experiments, we chose this sample size because previous studies from our group have obtained highly consistent data using similar sample sizes <ref type="bibr" target="#b29">(Pramod &amp; Arun, 2016)</ref>. We did not use any stopping criterion. The stimuli consisted of 36 single letters each from the Telugu and Malayalam languages (examples are shown in Fig. <ref type="figure">1</ref>; see Section S1 in the Supplemental Material available online). The font Nirmala UI was used because it has uniform stroke width. Subjects performed a baseline motor-response task and an oddball visual search task.</p><p>In the baseline task, a circle appeared on the left or right of the screen, and subjects had to indicate the side on which the circle appeared by pressing a key ("Z" for left, "M" for right). The average response time (RT) across 20 trials was taken as a measure of baseline motor speed (depicted in Fig. <ref type="figure" target="#fig_0">2b</ref>). In the visual search task, each trial began with a fixation cross for 500 ms, followed by a 4 × 4 search array that contained one oddball target and 15 identical distractors (Fig. <ref type="figure" target="#fig_0">2a</ref>). The exact position of each item was jittered on each trial according to a uniform distribution with a range of ±0.25° in the vertical and horizontal directions. This was done to prevent alignment cues from influencing search. The vertical dimension of all letters subtended 2° of visual angle on the screen, and the longer dimension varied depending on the letter. A vertical red line divided the screen into two halves. All stimuli were presented using custom scripts written in MATLAB (The MathWorks, Natick, MA) running the Psychophysics Toolbox <ref type="bibr" target="#b7">(Brainard, 1997)</ref>.</p><p>Subjects were instructed to locate the target as quickly and as accurately as possible and to respond using a key press ("Z" for left, and "M" for right). The trial timed out after 10 s. All stimuli were presented in white against a black background. In all, subjects completed two search trials corresponding to all 36 C 2 pairs of letters in each language, which amounted to 2,520 correct trials ( 36 C 2 pairs × 2 languages × 2 repetitions). Incorrect or missed trials appeared randomly later in the task. Only correct responses were analyzed. Any response exceeding 5 s was removed from analysis provided such a response occurred in less than 15% of the subjects. This step improved data consistency overall. We obtained qualitatively similar results without this step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2 (bigrams)</head><p>A total of 16 subjects (10 males; age: M = 24 years, SD = 2; 8 Telugu, 8 Malayalam) participated in this experiment. The stimuli consisted of 25 bigrams each from Telugu and Malayalam, created using all possible combinations of five single letters (shown in Section S1). The single letters were chosen such that the full stimulus set contained a few frequent bigrams in each language. In all, subjects performed searches corresponding to all possible pairs of the 25 bigrams, which amounted to 1,200 correct trials ( 25 C 2 searches × 2 languages × 2 repetitions). All other details of the procedure were identical to those in Experiment 1.</p><p>Search RTs were averaged across repetitions and subjects to obtain a composite measure that we then converted to a dissimilarity measure (1/RT), as in our previous studies. This resulted in a total of 300 pairwise dissimilarities ( 25 C 2 = 300) between all possible pairs of bigrams. Using the approach reported in our previous study <ref type="bibr" target="#b29">(Pramod &amp; Arun, 2016)</ref>, we modeled the pairwise dissimilarity between two bigrams, AB and CD, as a linear sum of pairwise dissimilarities between single letters at various locations. Specifically,</p><formula xml:id="formula_0">d c ( , ) , AB CD C C X X W W AC BD AD BC AB CD = + + + + + +</formula><p>where C AC and C BD represent the distances between letters at corresponding locations in the two bigrams, X AD and X BC represent the distances between letters at opposite locations in the two bigrams, W AB and W CD represent distances between letters within each of the two bigrams, and c is a constant term. This part-sum model is extremely general in that it assumes no systematic relation between single-letter distances at corresponding locations in a bigram, across locations in a bigram, or indeed within a given bigram (referred to henceforth as "corresponding, across, and within terms"). It works because a given letter pair occurs repeatedly across bigram pairs (e.g., the pair AC is present at corresponding locations in the bigram pairs AB-CD, AD-CE, and EA-DC). Because there are 5 unique single letters, there are 10 single-letter distances ( 5 C 2 = 10) for each term type (corresponding, across, within), which amounts to a total of 31 parameters (10 of each type × 3 types + 1 constant). Because there are 300 dissimilarity measurements and only 31 parameters, the model parameters can be uniquely estimated from the data. When the above model equation is written down for all 300 pairwise dissimilarities, the set of simultaneous equations can be written as y = Xb, where y is a 300 × 1 vector containing the observed dissimilarities; X is a 300 × 31 matrix with 0, 1, or 2 as entries (depending on the absence, presence, or repetition of a particular letter pair at corresponding locations, across locations, or within the two bigrams of a given pair); and b is a 31 × 1 vector of unknowns. We estimated the </p><formula xml:id="formula_1">అ ఆ బ భ గ ఘ హ ఇ ల మ న ణ ష త థ ట a a</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3 (functional MRI)</head><p>A total of 35 subjects (31 males; age: M = 25 years, SD = 3; 17 Telugu, 18 Malayalam) participated in functional localizer runs (n = 2) and event-related runs (n = 8) that were randomly interleaved. An anatomical scan was also included for each subject at the beginning. We chose this sample size because it was similar to that used in previous studies of reading <ref type="bibr" target="#b2">(Baker et al., 2007)</ref>, and we did not use any stopping criterion.</p><p>In the functional localizer runs, subjects viewed 16-s blocks of scrambled words (in Telugu, Malayalam, and English), objects, and scrambled objects while performing a one-back task throughout. In each block, 14 stimuli were randomly selected from a pool of images. The Telugu pool comprised 8 two-letter and 38 threeletter words, and the Malayalam pool comprised 12 two-letter and 38 three-letter words. The English pool comprised 36 four-letter words and 45 five-letter words. Telugu and Malayalam letters are typically wider than English letters; thus, we used longer English words so that the overall width of the image was roughly equal for all three languages. Each word was divided into grids-8 × 4 for Indian languages and 8 × 3 for Englishand scrambled words were creating by randomly shuffling the grid. The objects pool comprised 80 human-made objects. Scrambled objects were created by scrambling the phase of the Fourier-transformed images and then reconstructing the phase-scrambled image using the inverse Fourier transform.</p><p>All images were presented against a black background. Each block consisted of a total of 16 stimuli presented for 0.8 s with a 0.2-s blank interval, among which two randomly chosen stimuli were repeated. Each block ended with a fixation cross presented for 4 s against a blank screen. Thus, each block lasted 20 s. The size of the object images was about 4.5° along the longer dimension, whereas the vertical size of the word stimuli was 2.5°, as in the event-related runs. There were six repetitions of each block across two runs, and each run lasted for 370 s. Stimuli were presented using custom MATLAB scripts written with the Psychophysics Toolbox.</p><p>In the event-related runs, the stimuli consisted of 10 single letters and 24 bigrams each in Telugu and Malayalam, for a total of 68 stimuli. The height of the stimuli were equated to subtend 2.5° of visual angle, with longer dimensions that were scaled accordingly to preserve the aspect ratio. The bigrams were chosen so that each letter appeared at least four times; both high-and low-frequency bigrams were used, and the mean bigram dissimilarities were similar across the two languages (see Section S1 for all stimuli). On each trial, the stimulus was presented at the center of the screen with a black background for 300 ms, followed by a blank screen with a fixation cross for 3.7 s. In each run, all stimuli were presented once. Subjects were instructed to maintain fixation on the cross and perform a oneback task (i.e., to press a button whenever an image appeared twice in sequence). Each run contained eight trials with only a fixation cross in order to jitter the interstimulus interval, and eight randomly chosen images were repeated in a given run. Each run lasted 368 s, and there were eight runs in all, yielding eight repeats per stimulus.</p><p>Data acquisition. Subjects viewed images projected on a screen through a mirror placed above their eyes. Functional MRI (fMRI) data were acquired using a 32-channel head coil on a 3T Skyra (Siemens, Mumbai, India) at the HealthCare Global Hospital, Bengaluru. Functional scans were performed using a T2*-weighted gradient-echoplanar imaging sequence with the following parameters: repetition time (TR) = 2 s, echo time (TE) = 28 ms, flip angle = 79°, voxel size = 3 × 3 × 3 mm 3 , field of view = 192 × 192 mm 2 , and 33 axial-oblique slices for wholebrain coverage. Anatomical scans were performed using T1-weighted images with the following parameters: TR = 2.30 s, TE = 1.99 ms, flip angle = 9°, voxel size = 1 × 1 × 1 mm 3 , field of view = 256 × 256 × 176 mm 3 .</p><p>Data preprocessing. The raw fMRI data were preprocessed using Statistical Parametric Mapping (SPM) software (Version 12; Welcome Center for Human Neuroimaging; <ref type="url" target="https://www.fil.ion.ucl.ac.uk/spm/software/spm12/">https://www.fil.ion.ucl.ac.uk/spm/software/spm12/</ref>). Raw images were realigned, slice-time corrected, coregistered to the anatomical image, segmented, and normalized to the Montreal Neurological Institute (MNI) 305 anatomical template. Repeating the key analyses with voxel activations estimated from individual subjects yielded qualitatively similar results. Smoothing was performed only on the functional localizer blocks using a Gaussian kernel with a full-width half maximum of 5 mm. Default SPM parameters were used, and voxel size after normalization was kept at 3 × 3 × 3 mm 3 . The data were further processed using GLMdenoise (Version 1.4; <ref type="bibr" target="#b20">Kay, Rokem, Winawer, Dougherty, &amp; Wandell, 2013)</ref>. GLMdenoise improves the signal-to-noise ratio in the data by regressing out the noise estimated from task-unrelated voxels. The denoised time-series data were modeled using generalized linear modeling in SPM after removing low-frequency drift using a high-pass filter with a cutoff of 128 s. In the main experiment, the activity of each voxel was modeled using 83 regressors (68 stimuli + 1 fixation + 6 motion regressors + 8 runs). In the localizer block, each voxel was modeled using 15 regressors (6 stimuli + 1 fixation + 6 motion regressors + 2 runs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regions of interest.</head><p>All regions of interest (ROIs) were defined using the data from functional localizer blocks together with anatomical considerations. Early visual areas (V1-V4) were defined as the regions that responded more to scrambled objects compared with fixation. The regions identified were further parceled into V1 to V3 and V4 using anatomical masks from the SPM Anatomy Toolbox <ref type="bibr" target="#b14">(Eickhoff et al., 2005)</ref>. We grouped V1 to V3 into a single ROI because we observed qualitatively similar differences in activations for known and unknown scripts. Lateral occipital cortex was defined as the voxels that responded to objects more than scrambled objects but were restricted using anatomical masks (inferior temporal gyrus, inferior occipital gyrus, and middle occipital gyrus) created from tissue probability map labels available in SPM12. The VWFA was defined as a contiguous region in the occipitotemporal sulcus that responded more to known words (Telugu or Malayalam) compared with scrambled words. The temporal gyrus was defined as voxels in the temporal gyrus (both superior and medial portions, as well as Wernicke's area) that responded more to known words (Telugu or Malayalam) compared with scrambled words. For each contrast, a voxel-level threshold of p &lt; .001 (uncorrected) or cluster-level threshold of p &lt; .05 (family-wise-error corrected) was used to define contiguous regions. However, for 6 subjects, the VWFA could not be identified, and therefore a lower threshold of p &gt; .05 (uncorrected; the lowest-threshold p value used was .2) was used until we observed a contiguous cluster of at least 40 voxels in left occipitotemporal sulcus. The lateral occipital and VWFA voxels were further restricted to the top 200 and top 20 significant voxels, respectively (according to the t value in the functional contrast). We obtained similar results with other choices of voxel selection. Finally, all results were visualized on the cortical surface using the MATLAB program BSPMVIEW (<ref type="url" target="http://www.bobspunt.com/bspmview/">http://www.bobspunt.com/bspmview/</ref>). A summary of the typical locations and numbers of voxels in each ROI is given in Section S7 in the Supplemental Material.</p><p>Neural similarity in fMRI. For each ROI, the dissimilarity between each pair of stimuli was computed as 1 -r, where r is the Spearman correlation coefficient between the activity patterns evoked across voxels by the two stimuli. The dissimilarities were z scored and then averaged across subjects.</p><p>Voxel population model. For each bigram, we modeled the response of a population of voxels as a linear combination of the response of the voxels to individual letters. For example, if there were 100 voxels in a given ROI, then for each bigram, its response was modeled as y = Xb, where y is 100 × 1 vector of beta (activation) values across voxels for that bigram, X is a 100 × 3 matrix, where the first two columns correspond to the beta values for the corresponding voxels for the two constituent letters of the bigram, and the third column is a vector of 1s corresponding to a constant term, and b is a 3 × 1 vector of unknown weights that corresponds to the summation weights.</p><p>To evaluate model fit, we calculated the correlation between the observed and predicted response for each voxel. This procedure prevents the model fit from being biased by overall activation-level differences between voxels. The correlation coefficients were averaged across all bigrams to obtain an average model correlation for that ROI in a given subject. The model fit was compared between readers and nonreaders using paired-sample t tests across subject-wise model correlations.</p><p>Behavioral dissimilarity for fMRI bigrams. We estimated the behavioral dissimilarities for the bigrams used in this experiment with a reduced part-sum model. Recall that the part-sum model estimates separate letter dissimilarities for corresponding, across, and within terms, but the estimated terms were all correlated with the single-letter dissimilarities. We therefore modified the part-sum model to a highly reduced model in which single-letter dissimilarities from Experiment 1 combined linearly as follows: <ref type="figure"></ref>and<ref type="figure">d</ref> CD are pairwise singleletter dissimilarities observed in Experiment 1 and α, β, and γ are unknown scaling terms for letter relations at corresponding locations, across locations, and within bigrams. Thus, this model had only four free parameters that could be estimated again using linear regression. To predict the behavioral dissimilarities between the bigrams used in the fMRI experiment, we first estimated the parameters of this reduced model from the bigram searches in Experiment 2 and then used these parameters, together with the single-letter dissimilarities from Experiment 1, to generate the predicted dissimilarities for all pairs of bigrams used in Experiment 3. This was then compared with the neural similarity calculated above. We confirmed the validity of this approach by comparing these predicted dissimilarities with search dissimilarities directly estimated in an additional experiment (see Section S7 of the Supplemental Material).</p><formula xml:id="formula_2">d d d d d d d ( , ) , AB CD constant AC BD AD BC AB CD = × + [ ]+ × + [ ]+ × + [ ]+ α β γ where d AC , d BD , d AD , d BC , d AB ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We compared letter and word representations in distinct groups of readers that had similar educational levels and fluency in either of two Indian languages (Telugu and Malayalam). These languages have distinctive scripts with many shared phonemes and highly similar writing systems (Fig. <ref type="figure">1</ref>). We selected visually distinct letters with identical pronunciations from both languages (see Section S1). This design not only eliminates confounding factors due to phonology, writing systems, or literacy but also isolates the effect of reading expertise from intrinsic shape differences across the two scripts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1 (single letters)</head><p>We first investigated whether reading expertise modulates single-letter representations. We recruited 39 readers to perform an oddball visual search task involving Telugu letters and Malayalam letters (see Fig. <ref type="figure">S1</ref> in the Supplemental Material). An example search array using Telugu letters is shown in Figure <ref type="figure" target="#fig_0">2a</ref>. Subjects were equally accurate on searches involving known and unknown scripts (mean accuracy: 99% for known scripts, 98% for unknown scripts). However, they were faster for searches involving letters of known scripts (Fig. <ref type="figure" target="#fig_0">2b</ref>). To compare letter representations, we used the reciprocal of search time as a measure of dissimilarity between letters <ref type="bibr" target="#b0">(Arun, 2012)</ref>. This can be interpreted as the underlying salience signal that accumulates during visual search <ref type="bibr" target="#b37">(Sunder &amp; Arun, 2016)</ref>; it combines linearly across object attributes <ref type="bibr" target="#b28">(Pramod &amp; Arun, 2014</ref><ref type="bibr">, 2016)</ref>, search types <ref type="bibr" target="#b41">(Vighneshvel &amp; Arun, 2013)</ref>, and even top-down influences <ref type="bibr" target="#b37">(Sunder &amp; Arun, 2016)</ref>.</p><p>For each language, we plotted the pairwise dissimilarity for readers against that of nonreaders across all letter pairs. This revealed a strong positive correlation for both Telugu letters (Fig. <ref type="figure" target="#fig_0">2c</ref>) and Malayalam letters (Fig. <ref type="figure" target="#fig_0">2d</ref>). These correlations were close to the consistency of the responses within each group (correlation between dissimilarities in odd-and even-numbered subjects: r = .83, 95% CI = [.8, .85], and r = .87, 95% CI = [.85, .89], for readers and nonreaders of Telugu; r = .83, 95% CI = [.80, .85], and r = .87, 95% CI = [.85, .89], respectively, for readers and nonreaders of Malayalam; all correlations: p &lt; .00005). Reading expertise also resulted in increased dissimilarity for more similar letters, as shown by a negative correlation between baseline letter dissimilarity (as measured in nonreaders) and the increase in dissimilarity for readers over nonreaders (r = -.43, 95% CI = [-.36, -.49] for Telugu; r = -.49, 95% CI = [-.43, -.55] for Malayalam; both correlations: p &lt; .00005). These subtle alterations did not affect the global arrangement of letters in perceptual space (see Section S2 in the Supplemental Material). Letters that co-occurred in a bigram showed greater similarity in readers (see Section S2), and their sounds were perceived as more similar (see Section S3 in the Supplemental Material). In sum, reading subtly altered letter representations through increased discrimination of similar letters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2 (bigrams)</head><p>Next, we set out to characterize how reading expertise affects the representations of longer strings. Subjects performed oddball visual search involving bigrams of either familiar or unfamiliar scripts (Fig. <ref type="figure" target="#fig_1">3a</ref>). Readers were again faster to discriminate bigrams of known scripts over bigrams of unknown scripts (Fig. <ref type="figure" target="#fig_1">3b</ref>). Once again, reading had a subtle effect on bigram representations, as evidenced by a strong correlation between bigram dissimilarities of readers and nonreaders (r = .80, 95% CI = [.76, .84] for Telugu; r = .83, 95% CI = [.79, .86] for Malayalam; p &lt; .00005). These subtle alterations did not result in qualitative changes in the overall perceptual representation (see Section S4 in the Supplemental Material). However, the critical question remained: Are these changes driven solely by the increased discrimination of single letters? Or are there additional emergent properties that make readers better able to distinguish bigrams? Can bigram dissimilarities be predicted from letters?. To address these issues, we drew on our finding that dissimilarities between object parts combine linearly in visual search <ref type="bibr" target="#b29">(Pramod &amp; Arun, 2016)</ref>. Specifically, the net dissimilarity between two bigrams AB and CD is given as a linear sum of part relations at corresponding locations, part relations at opposite locations, and part relations within each bigram (Fig. <ref type="figure" target="#fig_1">3c</ref>; also see the Method section). Given many pairwise dissimilarities between bigrams, this part-sum model attempts to recover the underlying letter-letter relations that accurately predict this data. The model works because a given letter pair, say AC, can be found at corresponding locations across multiple bigram pairs (e.g., AB-CD, AD-CE, BA-DC), allowing us to recover its contribution to the overall dissimilarity whenever A and C are present at matched locations in two bigrams. Likewise, the pair AC is present in many bigram pairs at opposite locations (e.g., AB-DC, AD-EC) and within bigrams (e.g., AC-BD, AC-DE), which allows us to recover its contribution to the net dissimilarity when it occurs at opposite locations in two bigrams or, likewise, within bigrams. This model, based on 1/RT or search dissimilarity, outperformed other models with fewer parameters, as well as models based on reaction time (see Section S4).</p><p>This model yielded excellent predictions of the data. It yielded a significant positive correlation between the observed and predicted bigram dissimilarities for Telugu readers tested on bigrams of their script (Fig. <ref type="figure" target="#fig_1">3d</ref>). Because model coefficients represent dissimilarities between single letters, we first asked whether they were consistent with each other. This was indeed the case: We found a significant correlation between corresponding terms and across terms (r = .81, 95% CI = [.38, .95], p = .004) and a negative correlation between corresponding terms and within terms that approached significance (r = -.62, 95% CI = [-.89, .02], p = .06). The negative sign of within terms represents an effect akin to distractor heterogeneity in visual search <ref type="bibr" target="#b29">(Pramod &amp; Arun, 2016;</ref><ref type="bibr" target="#b41">Vighneshvel &amp; Arun, 2013)</ref>: When the letters in a target bigram are similar to each other, the search for that bigram among distractors is more efficient. All three types of terms contributed to the overall model fit (see Section S4). The corresponding terms were correlated with the single-letter dissimilarities observed in Experiment 1 (r = .83, 95% CI = [.41, .96], p = .003).</p><p>If reading expertise leads to the formation of specialized detectors for letter combinations, the part-sum model should be unable to predict searches involving   <ref type="figure" target="#fig_1">3e</ref>) and Malayalam bigrams (Fig. <ref type="figure" target="#fig_1">3f</ref>). Model coefficients for corresponding and across locations were both positive, which means that dissimilar letters at these locations in the two bigrams led to larger net dissimilarity. For both languages, the within-bigram terms were systematically smaller in magnitude for readers compared with nonreaders (Figs. <ref type="figure" target="#fig_1">3f</ref> and<ref type="figure" target="#fig_1">3g</ref>). We note that the partsum model directly estimated the underlying single-letter dissimilarities, so any simple change in single-letter dissimilarity would have affected all model terms and not specifically the within-bigram interactions. These reduced within-bigram interactions for readers thus represent an effect that was above that expected from increased singleletter dissimilarities. This reduced magnitude for readers resulted in larger dissimilarities and, consequently, easy searches. To confirm that this was indeed the case, we calculated the correlation between the observed difference in RTs between readers and nonreaders and asked whether this could be explained by the difference in the respective part-sum model predictions for each group. This analysis revealed a positive and statistically significant correlation (r = .59, 95% CI = [.51, .66] for Telugu bigrams and r = .55, 95% CI = [.47, .62] for Malayalam bigrams; p &lt; .00005).</p><p>We also confirmed that the first letter in the bigram was more salient than the second, consistent with the first-letter advantage observed in letter-recognition tasks (see Section S4). If reading does indeed reduce letter interactions within a bigram, then it should have no effect on bigrams with identical letters because the within-bigram dissimilarity is zero by definition. Therefore, we predicted that the dissimilarity between repeated-letter bigrams (e.g., AA and BB) should not be different for readers and nonreaders. In contrast, the dissimilarity between the transposed bigrams AB and BA should be strongly influenced by reading expertise because the within-bigram terms are nonzero whereas the across-location terms are zero. Thus, the part-sum model predicts that readers should be faster than nonreaders on transposed letter searches (AB-BA) but not repeated letter searches (AA-BB), even though both types of searches differ in two letters.</p><p>This was indeed the case: Readers were faster than nonreaders on transposed-bigram searches (Fig. <ref type="figure" target="#fig_1">3g</ref>). However, they were equally fast for repeated-letter searches (Fig. <ref type="figure" target="#fig_1">3g</ref>). The lack of effect for repeated-letter searches was not a floor effect, because there were many easier searches for both readers and nonreaders (shortest average search time for readers and nonreaders: 0.90 s and 0.89 s for Telugu letters; 0.79 s and 0.80 s for Malayalam letters). Thus, reading expertise produced increased discrimination of letter transpositions compared with repeated letters, and this effect was due to decreased letter-letter interactions within a bigram. We also tested subjects on visual search for trigrams in a separate experiment. Here, too, the part-sum model yielded excellent fits, with reduced within-trigram letter interactions for readers compared with nonreaders (see Section S5 in the Supplemental Material).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Can bigram interactions predict reading fluency?.</head><p>If within-bigram letter interactions are smaller for readers than for nonreaders, could these interactions predict reading fluency? To investigate this, we estimated model parameters using the pairwise bigram dissimilarity from each subject across experiments and asked if they predicted reading fluency. To be sure that the contribution of each term was independent of the others, we performed a partial-correlation analysis. This revealed a significant partial correlation for within-bigram interactions and the constant term, but not for the others (Fig. <ref type="figure" target="#fig_1">3h</ref>; see also Section S6 in the Supplemental Material). In other words, subjects with weaker within-bigram interactions were faster at reading. Likewise, subjects with faster motor responses (i.e., larger constant term) were also faster at reading. Combining these factors yielded a better model fit than each factor achieved separately, suggesting that they exert distinct influences on reading (Fig. <ref type="figure" target="#fig_1">3h</ref>; see also Section S6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3 (functional MRI)</head><p>Brain imaging of single letters and bigrams. So far, we have shown that reading subtly altered letter representations by making similar letters more discriminable and by reducing interactions between letters within a bigram. However, these results were based on comparing visual search for pairs of bigrams; the suggestion that interactions decreased within a bigram was only an indirect inference. In Experiment 3, we measured brain activations for single letters and bigrams and sought to relate bigram responses to single-letter responses.</p><p>On the basis of the existing literature, we defined a number of ROIs as potential loci for differences in visual processing between readers and nonreaders. We defined early visual areas (V1-V3), mid-level areas (V4), and high-level visual areas (the lateral occipital region). These are regions where previous studies have reported differences for readers and nonreaders <ref type="bibr" target="#b2">(Baker et al., 2007;</ref><ref type="bibr" target="#b39">Szwed et al., 2014)</ref>. We then defined the VWFA, which shows greater activations for words compared with scrambled words and objects <ref type="bibr" target="#b11">(Dehaene et al., 2015)</ref>. Finally, we selected a broad region spanning both the superior and medial temporal gyrus, which also showed greater activations to known compared with unknown scripts, and which is known to be part of the reading network <ref type="bibr" target="#b16">(Friederici &amp; Gierhan, 2013)</ref>. We complemented these ROI-based analyses with whole-brain searchlight analyses to provide an unbiased overview of the observed differences. All ROIs were defined using a combination of anatomical considerations and functional localizers (see the Method section). A representative subject brain with these ROIs is shown in Figure <ref type="figure" target="#fig_2">4a</ref>. We also performed equivalent searchlight analyses to complement all ROI analyses (see Section S7). In the main experiment, subjects viewed single letters and bigrams while performing a one-back task, which we used to obtain single-image activations for further analysis. Do known and unknown scripts elicit differential activations?. We first compared overall activation levels in each ROI between readers and nonreaders. This is an important question because any systematic difference would reveal which brain regions are influenced by reading expertise. For each subject, we calculated the average activation across all voxels and across all stimuli within each script (known and unknown). We compared subject-wise activation levels between known and unknown scripts (Figs. <ref type="figure" target="#fig_2">4b-4f</ref>).</p><p>For early visual areas (V1-V3), we observed opposite effects for known and unknown scripts for Telugu and Malayalam readers, suggesting that Malayalam letters activate early visual areas more than Telugu letters for both readers and nonreaders. Indeed, comparing the activations for the two languages across all subjects, we obtained a statistically significant difference (average activations of V1-V3: 0.61 for Telugu, 0.47 for Malayalam; p &lt; .00005 using a Wilcoxon signed-rank test on subject-wise activations). This difference, however, was highly significant in Malayalam readers (p &lt; .0005) but not in Telugu readers (p = .09).</p><p>The larger activation of early visual cortex for Malayalam might be due to the larger size of Malayalam letters compared with Telugu letters (total letter area, measured using the number of nonzero pixels: 0.08 ± .02 for Telugu and 0.11 ± .02 for Malayalam; p = .0017, rank-sum test across single letters). To investigate whether responses to single letters were driven by lowlevel image properties, we calculated for each subject the correlation between the average activation of each ROI and the ink area across single letters. The average correlation with ink area was significantly different from zero only in V1 to V3 but not in any other ROI (across subjects: mean r = .2, SEM = .04, p &lt; .00001, one-sample t test for V1-V3; mean r = .06, SEM = .04, p = .16 for V4; mean r = -.02, SEM = .06, p = .69 for lateral occipital complex; mean r = .04, SEM = .05, p = .44 for VWFA; and mean r = -.01, SEM = .05, p = .79 for temporal gyrus). We conclude that responses in early visual areas, but not other ROIs, were driven by low-level properties of letter shape. This is consistent with the known properties of early visual cortex.</p><p>We proceeded to compare activations for known and unknown scripts in other visual areas. We observed identical trends in V4, VWFA, and temporal gyrus: Known scripts consistently elicited greater activations in readers of both languages (Figs. <ref type="figure" target="#fig_2">4c-4e</ref>). A searchlight analysis confirmed these trends but additionally revealed that this trend was evident in a nearly continuous swath of cortex along the ventral surface from V4 to the VWFA, as well as in several regions around the temporal gyrus (see Section S7).</p><p>We observed an opposite pattern of activations in the lateral occipital region. Here, known scripts elicited weaker activation compared with unknown scripts for both languages (Fig. <ref type="figure" target="#fig_2">4f</ref>). A searchlight analysis revealed that this was true on the dorsal portion of the occipitotemporal cortex, as well as in parietal regions (see Section S7). Reading expertise thus leads to widespread changes specifically in high-level visual areas but with opposite effects in the lateral occipital region compared with V4 and the VWFA. We performed two additional analyses using overall activation levels. First, there were differences in overall activation with bigram frequency for Telugu but not Malayalam readers, but this effect was abolished on factoring out letter-frequency effects (see Section S7). Second, we observed a positive correlation between mean VWFA activation levels and reading fluency across subjects (see Section S7), consistent with other studies <ref type="bibr" target="#b11">(Dehaene et al., 2015)</ref>.</p><p>Neural correlates of behavior. Because there were systematic effects of reading on bigrams and single letters in visual search (Experiments 1 and 2), we sought to find the underlying neural representations in the brain. We therefore compared pairwise bigram dissimilarities in behavior with corresponding neural dissimilarities in each ROI. Specifically, for each ROI in a given subject, we calculated the neural dissimilarity between pairs of images using the correlation distance between the voxel activations of the two images (1 -r) and averaged this dissimilarity across subjects. In this manner, we calculated average pairwise neural dissimilarities for all pairs of stimuli in each ROI (for the dissimilarity matrices, see Section S7). We estimated the pairwise behavioral dissimilarities for the bigrams used in fMRI. We then asked how well these pairwise dissimilarities matched behavior for known scripts and unknown scripts. The results revealed two interesting patterns. First, neural dissimilarities in a number of areas were significantly correlated with behavior for both known and unknown scripts (Fig. <ref type="figure" target="#fig_2">4g</ref>). However, the best match with behavior for known scripts was in the lateral occipital region, whereas for unknown scripts it was in V1 to V3. A searchlight analysis confirmed these trends (see Section S7): Dissimilarities for known bigrams best matched with neural dissimilarities in occipitotemporal cortex centered around the lateral occipital region, but also with the activation of parietal and motor regions. In contrast, the dissimilarities for unknown bigrams best matched the neural dissimilarities in early visual areas. Thus, perception of known scripts was driven by neural activations in higher visual areas, whereas perception of unknown scripts was driven by neural activations in lower visual areas.</p><p>Does reading alter the compositionality of bigram representations?. We next turned to the critical question of whether reading alters the compositionality of bigram representations. If reading reduces interactions between letters, the responses to bigrams should be more predictable from single letters in readers compared with nonreaders. By contrast, if reading leads to the formation of specialized bigram detectors, the responses to bigrams should be less predictable from single letters in readers. Distinguishing between these possibilities would require a model that predicts bigram responses using singleletter responses.</p><p>We devised a model to predict the response of a population of voxels to a given bigram using a linear sum of the population response to each individual letter in the bigram (Fig. <ref type="figure">5a</ref>). This resulted in a separate population model for each bigram. This approach allowed the model to estimate the average compositionality across a population of correlated voxels and overcome the inherent noise in individual voxels. To evaluate model fits, we compiled model predictions for each voxel across bigrams and compared the predictions with the observed activations. This approach prevents the model fits from being biased by voxels with large activation levels. We obtained similar results on fitting a separate model to each voxel. We compared the average model fit for each subject in a given ROI for known and unknown scripts. We obtained comparable model fits for known and unknown scripts in most ROIs (Fig. <ref type="figure">5b</ref>). The sole exception was the lateral occipital region, where bigrams of known scripts were better predicted by single-letter responses compared with bigrams of unknown scripts (Fig. <ref type="figure">5b</ref>). A searchlight analysis revealed that this effect was localized to the anterior portion of the left lateral occipital region and to the right fusiform gyrus (see Section S7). Since these regions were identified using their higher model fit for known scripts, any direct comparison of model performance would constitute double dipping. To avoid this circularity, we performed a split-half analysis. We identified the anterior portion of the lateral occipital region using odd-numbered subjects and compared the model fits in even-numbered subjects, and vice versa. This revealed significantly larger model fits in the anterior lateral occipital region for known, compared with unknown, scripts for Telugu and Malayalam, separately as well as in both languages combined (Fig. <ref type="figure">5c</ref>). We obtained similar results in the right fusiform gyrus (see Section S7).</p><p>The increased compositionality for bigrams in objectselective cortex could be an incidental artifact of having stronger signal levels overall, which could increase the explainable variance and therefore model performance. However, this is unlikely because known scripts evoke weaker activity in the lateral occipital region, which should have led to weaker, not stronger, model predictions. We conclude that reading increases the compositionality of bigram representations specifically in object-selective cortex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>We investigated the effect of reading expertise on letter representations by comparing Telugu and Malayalam readers using a combination of behavior and brain imaging. In behavior, subjects discriminated letters of their known script better than letters of unknown scripts. This is consistent with the increased discrimination of familiar targets observed for natural objects in visual search <ref type="bibr" target="#b25">(Mruczek &amp; Sheinberg, 2005)</ref>. We found that the net dissimilarity between strings (bigrams and trigrams) can be accurately predicted using pairwise dissimilarities between letters in the two strings. This is consistent with our previous study in which we reported this result for objects <ref type="bibr" target="#b29">(Pramod &amp; Arun, 2016)</ref>.</p><p>This model was able to predict virtually all the explainable variation in the search data for both readers and nonreaders. Importantly, these changes in visual processing directly predicted reading fluency in readers.</p><p>If reading expertise led to the formation of specialized bigram or trigram detectors, our models, based only on single-letter responses, would have shown worse performance for known scripts than for unknown scripts and for frequent than for infrequent bigrams. We found no such effects. Thus, bigram detectors, even if present, did not contribute substantively to the observed effects. Importantly, we were able to precisely quantify the effect of reading on word representations by analyzing how model parameters varied between readers and nonreaders. Our main finding was that reading expertise made single letters more discriminable and reduced interactions between letters in a string. Our model accounted for both letter similarity and letter interactions, thereby providing a framework to compare effects of letter substitution and transposition, both widely used as measures of orthographic processing <ref type="bibr" target="#b11">(Dehaene et al., 2015;</ref><ref type="bibr" target="#b19">Grainger, Dufau, Montant, Ziegler, &amp; Fagot, 2012;</ref><ref type="bibr" target="#b44">Ziegler et al., 2013)</ref>.</p><p>Further, the reduced interactions may work at multiple scales: Conjoined words are easier to parse when they are frequent than when they are infrequent (e.g., "readingdifficulty" is easier to parse than "heliumchromate"). We propose that visual search using letter strings can be a natural and objective way to study how reading alters visual representations.</p><p>Our brain-imaging experiment (Experiment 3) further elucidated the neural basis of word representations. Our main finding is that the anterior ventral portion of the lateral occipital region is a likely locus for the effects observed in behavior. We draw this conclusion because (a) the neural representation of bigrams in the lateral occipital region matched best with behavior for readers, and (b) bigram responses were better predicted from single letters for known scripts specifically in the lateral occipital region but not in other regions. The former finding is interesting because it suggests that reading shifts the neural basis of behavior from lower to higher visual areas. The latter finding is interesting because it indicates that reading makes visual processing more efficient by making words easier to parse into letters. The increased compositionality might result from familiarity with individual letters or with letter combinations. These possibilities will require careful testing. Our findings are congruent with previous reports showing that reading-related plasticity occurs both at the level of single letters <ref type="bibr" target="#b38">(Szwed et al., 2011;</ref><ref type="bibr" target="#b42">Vinckier et al., 2007)</ref> and at the level of words <ref type="bibr" target="#b17">(Glezer, Jiang, &amp; Riesenhuber, 2009;</ref><ref type="bibr" target="#b18">Glezer, Kim, Rule, Jiang, &amp; Riesenhuber, 2015;</ref><ref type="bibr" target="#b30">Riesenhuber &amp; Glezer, 2017)</ref>. Importantly, our findings elucidate the nature of the plasticity that might occur at the word level, suggesting that it reduces interactions between letters, making word responses more compositional.</p><p>That the lateral occipital region could play a role in reading is consistent with evidence that alexia also induces general visual-processing deficits <ref type="bibr" target="#b4">(Behrmann, Nelson, &amp; Sekuler, 1998;</ref><ref type="bibr" target="#b31">Roberts, Lambon Ralph, &amp; Woollams, 2010;</ref><ref type="bibr" target="#b36">Starrfelt, Habekost, &amp; Gerlach, 2010)</ref> and often involves damage to regions posterior to the VWFA <ref type="bibr" target="#b3">(Barton, 2011;</ref><ref type="bibr" target="#b34">Seghier et al., 2012)</ref>. It is also possible that compositionality increases in other areas, such as the VWFA, but the increase is undetectable because these areas have far fewer voxels and therefore weaker statistical power. A conclusive demonstration that the anterior ventral lateral occipital region participates in reading would require perturbing its activity during reading tasks.</p><p>We also found a widespread effect of reading expertise across many high-level visual regions, in keeping with the existing literature <ref type="bibr" target="#b13">(Dehaene et al., 2010;</ref><ref type="bibr" target="#b39">Szwed et al., 2014;</ref><ref type="bibr" target="#b40">Szwed, Ventura, Querido, Cohen, &amp; Dehaene, 2012)</ref>. But unlike in previous studies, we compared readers of closely related Indian languages (i.e., with distinct orthographies and shared phonemes) who had similar educational levels. This enabled us to establish that these effects were truly due to reading expertise and not to letter shapes or other confounding factors. We found opposite trends in different visual areas: In V4 and along the occipitotemporal sulcus up to the VWFA, we found greater activation to known scripts. This is consistent with the effects of learning observed in these regions <ref type="bibr" target="#b9">(Clarke, Pell, Ranganath, &amp; Tyler, 2016;</ref><ref type="bibr" target="#b15">Folstein, Palmeri, Van Gulick, &amp; Gauthier, 2015;</ref><ref type="bibr" target="#b35">Skeide et al., 2017)</ref>. In the occipitotemporal regions in and around the lateral occipital region, we observed greater activation for unknown scripts. This is consistent with the increased response to novel stimuli in the homologous region in the monkey, the inferior temporal cortex <ref type="bibr" target="#b24">(Meyer, Walker, Cho, &amp; Olson, 2014;</ref><ref type="bibr" target="#b26">Mruczek &amp; Sheinberg, 2007)</ref>. Whether these effects are specific to reading scripts or are a more general effect of familiarity in these regions can be resolved by comparing activations for familiar objects and scripts after accounting for differences in visual experience. Likewise, these effects could also arise from different effects of attention on these regions, although such attentional effects have never been proposed or reported. Distinguishing familiarity effects from attentional effects will require careful independent control of task difficulty, attention, and familiarity.</p><p>Our observations both confirm and extend our understanding of the VWFA in several ways. First, we consistently localized the VWFA for both Indian languages and observed no difference in its anatomical location across language (see Section S7). This is consistent with other studies in which the VWFA was observed at similar locations for multiple languages <ref type="bibr" target="#b1">(Bai et al., 2011;</ref><ref type="bibr" target="#b21">Krafnick et al., 2016;</ref><ref type="bibr" target="#b39">Szwed et al., 2014)</ref>. Second, we found a positive correlation between VWFA activation levels and fluency <ref type="bibr" target="#b11">(Dehaene et al., 2015)</ref>. Third, neural dissimilarity in the VWFA was significantly correlated with behavioral dissimilarity in readers but not in nonreaders (Fig. <ref type="figure" target="#fig_2">4g</ref>). There have been surprisingly few studies on this point: Only one study has shown VWFA representations to be correlated with subjective visual dissimilarity <ref type="bibr" target="#b32">(Rothlein &amp; Rapp, 2014)</ref>, but this could be due to explicit letter reading by subjects. Our measure of behavioral dissimilarity (visual search) did not require explicit reading and was similar for readers and nonreaders. Thus, this finding suggests that the VWFA receives letter-shape information for only known scripts. Finally, we observed concordant effects in the VWFA with both the lateral occipital and temporal gyrus regions, consistent with its status as an intermediate region between the visual and auditory processing of language <ref type="bibr" target="#b11">(Dehaene et al., 2015;</ref><ref type="bibr" target="#b16">Friederici &amp; Gierhan, 2013)</ref>.</p><p>Our central finding that reading makes word responses more compositional raises the intriguing question of how compositionality could benefit reading. Here, we drew on previous work on the motor system suggesting that viewing multiple movement targets enables parallel planning <ref type="bibr" target="#b5">(Bhutani, Sengupta, Basu, Prabhu, &amp; Murthy, 2017;</ref><ref type="bibr" target="#b8">Cisek &amp; Kalaska, 2010;</ref><ref type="bibr" target="#b23">McSorley, Gilchrist, &amp; McCloy, 2019;</ref><ref type="bibr" target="#b43">Wu et al., 2013)</ref>. Similarly, simultaneous viewing of a string of letters in a word might enable the parallel programming of the associated sounds, thereby enabling efficient reading.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Example search array and results from Experiment 1. An example single-letter search array using Telugu letters is shown in (a). Average search time (b) is shown for readers and nonreaders of Telugu and Malayalam letters. The baseline response time is also shown for each group of subjects. Error bars depict standard errors of the mean across subjects, and asterisks indicate statistically significant differences between groups (p &lt; .00005, sign-rank test across pairs). Pairwise search dissimilarity is shown separately for 630 pairs of (c) Telugu letters and (d) Malayalam letters, plotted for readers and nonreaders. Each point represents one search pair; an example easy and hard search pair are shown. The dotted line is the y = x line, and the solid line is the best-fitting line to the data. Asterisks indicate that the correlations were significant (p &lt; .00005).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Example search array and results from Experiment 2. An example search array using Telugu bigrams is shown in (a). The Telugu and Malayalam letters used to create all 25 possible bigrams are shown below the search array. Average search time (b) is shown for readers and nonreaders of Telugu bigrams and Malayalam bigrams. The baseline response time (RT) is also shown for each group of subjects. Error bars depict standard errors of the mean across subjects, and asterisks indicate significant differences between groups (p &lt; .00005). A schematic of the part-sum model is shown in (c). According to this model, the net dissimilarity (1/RT) between bigrams AB and CD can be explained using single-letter dissimilarities between letters at corresponding locations, at opposite locations in the two bigrams, and within each of the bigrams (see the text for further details). Observed bigram dissimilarity (d) is plotted against predicted bigram dissimilarity from the part-sum model for Telugu readers on Telugu bigrams. Searches with low-frequency bigrams (n = 91) and high-frequency bigrams (n = 55) are plotted separately from all other search pairs (n = 154; gray circles). Each point represents one</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Neural correlates of reading expertise and results from Experiment 3. Regions of interest (ROIs) are shown in (a) for an example subject, showing V1 to V3, V4, lateral occipital (LO) region, visual word-form area (VWFA), and temporal gyrus (TG). Average activation levels in Telugu readers, Malayalam readers, and the combination of both are shown for known and unknown scripts, separately for (b) V1 to V3, (c) V4, (d) VWFA, (e) TG, and (f) LO. Error bars indicate ±1 SEM across subjects. Asterisks indicate</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>AA vs. BB) for readers and nonreaders, averaged across Telugu and Malayalam readers. Error bars depict standard errors of the mean across subjects, and asterisks indicate significant differences between groups (p &lt; .00005 on a rank-sum test across search times for 20 AB-BA pairs across the two languages, or across AA-BB pairs). The model equations below the graph show how smaller within-bigram terms lead to increased dissimilarity for transposed letters but not repeated letters.For transposed-letter searches, letters are identical at opposite locations, so the opposite-location terms are multiplied by zero, but the smaller within-bigram terms for readers lead to larger dissimilarities (and therefore faster searches). For repeated-letter searches, the within-bigram terms are multiplied by zero by definition, and therefore there is no benefit for readers. Partial correlation (h) is illustrated between reading fluency and each part-sum model term (after factoring out all other terms) across subjects. We used subjects' data across multiple experiments to perform this analysis. See Section S6 in the Supplemental Material for details. The combined model is based on predicting reading fluency as a linear combination of all model terms. Error bars represent ±1 SD, and asterisks indicate significant partial correlations (*p &lt; .05, **p &lt; .005, ***p &lt; .0005).</figDesc><table><row><cell>high-frequency bigrams because it encodes single-letter dissimilarities but not bigram frequency. Note that the model can account for letter-frequency effects because it estimates the underlying single-letter dissimilarity, which in turn could depend on letter frequency. We</cell><cell>.0005, **p &lt;</cell></row><row><cell>observed no qualitative difference between model fits</cell><cell></cell></row><row><cell>for high-frequency bigram pairs compared with low-</cell><cell></cell></row><row><cell>frequency bigram pairs (Fig. 3d). A statistical compari-</cell><cell></cell></row><row><cell>son of the residual error between low-and high-frequency</cell><cell></cell></row><row><cell>pairs revealed no significant difference (average model</cell><cell></cell></row><row><cell>residual error: 0.07 for 91 low-frequency pairs, 0.08 for</cell><cell></cell></row><row><cell>55 high-frequency pairs; p = .96, rank-sum test). We</cell><cell></cell></row><row><cell>observed similar patterns for readers of Malayalam let-</cell><cell></cell></row><row><cell>ters (model correlation = .91, p &lt; .0005; average residual</cell><cell></cell></row><row><cell>error: 0.08 for 45 low-frequency pairs, 0.07 for 105</cell><cell></cell></row><row><cell>high-frequency pairs; p = .06).</cell><cell></cell></row></table><note><p>****p &lt; .00005 on a signed-rank test across 10 part relations between readers and nonreaders). Average search time (g) is shown for transposed-letter searches (e.g., AB among BA) and repeated-letter searches (e.g., Differences between readers and nonreaders. The part-sum model yielded excellent fits to the observed bigram dissimilarities for both readers and nonreaders (model correlations for readers and nonreaders: r = .89, 95% CI = [.87, .91], and r = .90, 95% CI = [.87, .92], for Telugu; r = .91, 95% CI = [.89, .93], and r = .92, 95% CI = [.91, .94], for Malayalam; p &lt; .00005). If model predictions are equally good for readers and nonreaders, then what makes readers faster than nonreaders? We compared the strength of corresponding, across, and within model coefficients for readers and nonreaders for Telugu bigrams (Fig.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Compositionality of neural bigram representations in Experiment 3. A schematic of the voxel-population model is shown in (a). The response of each bigram across voxels was modeled as a linear combination of the constituent letter responses. To evaluate the model fit, we calculated the correlation between observed and predicted activations for each voxel. Average model correlation across voxels (b) is presented for each of five regions of interest, separately for known and unknown scripts. The regions are V1 to V3, V4, lateral occipital (LO) region, visual word-form area (VWFA), and temporal gyrus (TG). Error bars indicate standard errors of the model correlation across subjects. The asterisk indicates a significant difference between script types (p &lt; .05, using a signed-rank test on subject-wise model correlations between the two groups). Average model correlation in the anterior lateral occipital region (c) is shown for Telugu readers, Malayalam readers, and both groups combined, separately for known and unknown scripts. Error bars represent standard errors of the mean across subjects. Asterisks represent statistical significance, as obtained using a signed-rank test comparing average model correlations across subjects (*p &lt; .05, **p &lt; .005, ****p &lt; .00005).</figDesc><table><row><cell>a</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>b</cell><cell></cell><cell></cell></row><row><cell>Step 1:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">B</cell><cell>0.4</cell><cell></cell></row><row><cell>Estimate Population Model for Each Bigram Step 2: Evaluate Bigram Activations for Each Voxel</cell><cell>Bigram Activation Observed</cell><cell>= W1</cell><cell cols="3">Single-Letter Activations + W2 Bigram 1 Bigram 2 Bigram n</cell><cell>Average Model Correlation</cell><cell>0</cell><cell>Known Script</cell><cell>Unknown Script</cell><cell>*</cell></row><row><cell></cell><cell></cell><cell cols="3">Predicted</cell><cell></cell><cell></cell><cell></cell><cell cols="2">V1-V3</cell><cell>V4</cell><cell>LO</cell><cell>VWFA</cell><cell>TG</cell></row><row><cell></cell><cell></cell><cell>c</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Anterior LO</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.5</cell><cell>**</cell><cell>*</cell><cell></cell><cell>****</cell></row><row><cell></cell><cell></cell><cell cols="2">Average Model Correlation</cell><cell>0</cell><cell>Known Script Telugu Unknown Script</cell><cell>Malayalam</cell><cell cols="3">Combined</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Readers</cell><cell>Readers</cell><cell></cell><cell></cell></row><row><cell>Fig. 5.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We are grateful to <rs type="person">Mike Tarr</rs>, <rs type="person">John Pyles</rs>, and <rs type="person">Elissa Aminoff</rs> for organizing an excellent functional MRI workshop at the <rs type="institution">Indian Institute of Science (IISc)</rs> and for help with standardizing scan and task parameters, which laid the groundwork for this study.</p></div>
			</div>
			<div type="funding">
<div><head>Funding</head><p>This study was funded by the <rs type="funder">Department of Biotechnology-Indian Institute of Science (IISc) Partnership Programme</rs> and by <rs type="funder">Intermediate and Senior Fellowships</rs> from the <rs type="funder">Wellcome Trust/DBT India Alliance</rs> (all to <rs type="person">S. P. Arun</rs>; Grant Nos. <rs type="grantNumber">500027/Z/09/Z</rs> and <rs type="grantNumber">IA/S/17/1/503081</rs>). The functional MRI workshop was funded by a <rs type="funder">Tata Trusts</rs> grant, and MRI scan time required to standardize task and scanning parameters was funded by a <rs type="funder">Carnegie Mellon University-IISc BrainHub</rs> grant (both with <rs type="person">S. P. Arun</rs> as co-principal investigator).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_uE3X7Mr">
					<idno type="grant-number">500027/Z/09/Z</idno>
				</org>
				<org type="funding" xml:id="_3yTPS4K">
					<idno type="grant-number">IA/S/17/1/503081</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Action Editor</head><p>John Jonides served as action editor for this article.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions</head><p>A. Agrawal and S. P. Arun designed the experiments. A. Agrawal collected the data, A. Agrawal and S. P. Arun analyzed the data, and all the authors interpreted the results. A. Agrawal and S. P. Arun wrote the manuscript with input from K. V. S. Hari. All the authors approved the final manuscript for submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflicting Interests</head><p>The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplemental Material</head><p>Additional supporting information can be found at <ref type="url" target="http://journals.sagepub.com/doi/suppl/10.1177/0956797619881134">http:// journals.sagepub.com/doi/suppl/10.1177/0956797619881134</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open Practices</head><p>All data have been made publicly available via the Open Science Framework and can be accessed at <ref type="url" target="https://osf.io/wytek/">https://osf.io/wytek/</ref>. The design and analysis plans for the experiments were not preregistered. The complete Open Practices Disclosure for this article can be found at <ref type="url" target="http://journals.sagepub.com/doi/suppl/10.1177/0956797619881134">http://journals.sagepub.com/doi/ suppl/10.1177/0956797619881134</ref>. This article has received the badge for Open Data. More information about the Open Practices badges can be found at <ref type="url" target="http://www.psychologicalscience.org/publications/badges">http://www.psychological science.org/publications/badges</ref>.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Turning visual search time on its head</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Arun</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2012.04.005</idno>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="86" to="92" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Chinese and Korean characters engage the same visual word form area in proficient early Chinese-Korean bilinguals</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Weng</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0022765</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Article e22765</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visual word processing and experiential origins of functional selectivity in human extrastriate cortex</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Kwong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Benner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kanwisher</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0703300104</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="9087" to="9092" />
			<date type="published" when="2007">2007</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Disorder of higher visual function</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J S</forename><surname>Barton</surname></persName>
		</author>
		<idno type="DOI">10.1097/WCO.0b013e328341a5c2</idno>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Neurology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Visual complexity in letter-by-letter reading: &quot;Pure&quot; alexia is not pure</title>
		<author>
			<persName><forename type="first">M</forename><surname>Behrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Sekuler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1115" to="1132" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Parallel activation of prospective motor plans during visually-guided sequential saccades</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bhutani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Murthy</surname></persName>
		</author>
		<idno type="DOI">10.1111/ejn.13496</idno>
	</analytic>
	<monogr>
		<title level="j">The European Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="631" to="642" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tuning of the human left fusiform gyrus to sublexical orthographic structure</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Medler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Westbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Liebenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Buchanan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2006.06.053</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="739" to="748" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The psychophysics toolbox</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Brainard</surname></persName>
		</author>
		<idno type="DOI">10.1163/156856897X00357</idno>
	</analytic>
	<monogr>
		<title level="j">Spatial Vision</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="433" to="436" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural mechanisms for interacting with a world full of action choices</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cisek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Kalaska</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.neuro.051508.135409</idno>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="269" to="298" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning warps object representations in the ventral temporal cortex</title>
		<author>
			<persName><forename type="first">A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Pell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Tyler</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn_a_00951</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1010" to="1023" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The unique role of the visual word form area in reading</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2011.04.003</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="254" to="262" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Illiterate to literate: Behavioural and cerebral changes induced by reading acquisition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kolinsky</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn3924</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="234" to="244" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The neural code for written words: A proposal</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sigman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vinckier</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2005.05.004</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="335" to="341" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">How learning to read changes the cortical networks for vision and language</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pegado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Braga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ventura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nunes Filho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
		<idno type="DOI">10.1126/science.1194140</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">330</biblScope>
			<biblScope unit="page" from="1359" to="1364" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A new SPM toolbox for combining probabilistic cytoarchitectonic maps and functional imaging data</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Stephan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mohlberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Grefkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Amunts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zilles</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2004.12.034</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1325" to="1335" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Category learning stretches neural representations in visual cortex</title>
		<author>
			<persName><forename type="first">J</forename><surname>Folstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Palmeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Van Gulick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gauthier</surname></persName>
		</author>
		<idno type="DOI">10.1177/0963721414550707</idno>
	</analytic>
	<monogr>
		<title level="j">Current Directions in Psychological Science</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="17" to="23" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The language network</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Friederici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M E</forename><surname>Gierhan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.conb.2012.10.002</idno>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Neurobiology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="250" to="254" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evidence for highly selective neuronal tuning to whole words in the &quot;visual word form area</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Glezer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riesenhuber</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2009.03.017</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="199" to="204" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adding words to the brain&apos;s visual dictionary: Novel word learning selectively sharpens orthographic representations in the VWFA</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Glezer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rule</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riesenhuber</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.4031-14.2015</idno>
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="4965" to="4972" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Orthographic processing in baboons (Papio papio)</title>
		<author>
			<persName><forename type="first">J</forename><surname>Grainger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dufau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Montant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fagot</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1218152</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">336</biblScope>
			<biblScope unit="page" from="245" to="248" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">GLMdenoise: A fast, automated technique for denoising task-based fMRI data</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rokem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Winawer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Dougherty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Wandell</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2013.00247</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Chinese character and English word processing in children&apos;s ventral occipitotemporal cortex: fMRI evidence for script invariance</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Krafnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Flowers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Luetje</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Napoliello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Siok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Eden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2016.03.021</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="302" to="312" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Selective visual representation of letters and words in the left ventral occipito-temporal cortex with intracerebral recordings</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lochy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jacques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Maillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Colnat-Coulbois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rossion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jonas</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1718987115</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="7595" to="E7604" />
			<date type="published" when="2018">2018</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The programming of sequences of saccades</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mcsorley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Gilchrist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mccloy</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00221-019-05481-7</idno>
	</analytic>
	<monogr>
		<title level="j">Experimental Brain Research</title>
		<imprint>
			<biblScope unit="volume">237</biblScope>
			<biblScope unit="page" from="1009" to="1018" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Image familiarization sharpens response dynamics of neurons in inferotemporal cortex</title>
		<author>
			<persName><forename type="first">T</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Olson</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.3794</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1388" to="1394" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Distractor familiarity leads to more efficient visual search for complex stimuli</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E B</forename><surname>Mruczek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Sheinberg</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03193628</idno>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="1016" to="1031" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Context familiarity enhances target processing by inferior temporal cortex neurons</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E B</forename><surname>Mruczek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Sheinberg</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.2106-07.2007</idno>
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="8533" to="8545" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to read alphasyllabaries</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nag</surname></persName>
		</author>
		<idno type="DOI">10.1075/swll</idno>
	</analytic>
	<monogr>
		<title level="m">Theories of reading development</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Cain</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Compton</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Parrila</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>John Benjamins</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="75" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Features in visual search combine linearly</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Pramod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Arun</surname></persName>
		</author>
		<idno type="DOI">10.1167/14.4</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Object attributes combine additively in visual search</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Pramod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Arun</surname></persName>
		</author>
		<idno type="DOI">10.1167/16.5.8</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Evidence for rapid localist plasticity in the ventral visual stream: The example of words</title>
		<author>
			<persName><forename type="first">M</forename><surname>Riesenhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Glezer</surname></persName>
		</author>
		<idno type="DOI">10.1080/23273798.2016.1210178</idno>
	</analytic>
	<monogr>
		<title level="j">Language, Cognition and Neuroscience</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="286" to="294" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">When does less yield more? The impact of severity upon implicit recognition in pure alexia</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Lambon Ralph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Woollams</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuropsychologia.2010.04.002</idno>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="2437" to="2446" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The similarity structure of distributed neural responses reveals the multiple representations of letters</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rothlein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rapp</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2013.11.054</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="331" to="344" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Stimulus orientation and the first-letter advantage</title>
		<author>
			<persName><forename type="first">M</forename><surname>Scaltritti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dufau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grainger</surname></persName>
		</author>
		<idno type="DOI">10.1016/J.ACTPSY.2017.12.009</idno>
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="page" from="37" to="42" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Reading without the left ventral occipito-temporal cortex</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Seghier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Neufeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zeidman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Leff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mechelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nagendran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.neuropsychologia.2012.09.030</idno>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="3621" to="3635" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning to read alters cortico-subcortical cross-talk in the visual system of illiterates</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Skeide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guleria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Huettig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename></persName>
		</author>
		<idno type="DOI">10.1126/sciadv.1602612</idno>
	</analytic>
	<monogr>
		<title level="j">Science Advances</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">1602612</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Visual processing in pure alexia: A case study</title>
		<author>
			<persName><forename type="first">R</forename><surname>Starrfelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Habekost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gerlach</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2009.03.013</idno>
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="242" to="255" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Look before you seek: Preview adds a fixed benefit to all searches</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sunder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Arun</surname></persName>
		</author>
		<idno type="DOI">10.1167/16.15</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">15</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Specialization for written words over objects in the visual cortex</title>
		<author>
			<persName><forename type="first">M</forename><surname>Szwed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Eger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Valabrègue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Amadon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2011.01.073</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="330" to="344" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Effects of literacy in early visual and occipitotemporal areas of Chinese and French readers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Szwed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn_a_00499</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="459" to="475" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Reading acquisition enhances an early visual process of contour integration</title>
		<author>
			<persName><forename type="first">M</forename><surname>Szwed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ventura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Querido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-7687.2011.01102.x</idno>
	</analytic>
	<monogr>
		<title level="j">Developmental Science</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="139" to="149" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Does linear separability really matter? Complex visual search is explained by simple search</title>
		<author>
			<persName><forename type="first">T</forename><surname>Vighneshvel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Arun</surname></persName>
		</author>
		<idno type="DOI">10.1167/13.11.10</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Hierarchical coding of letter strings in the ventral stream: Dissecting the inner organization of the visual word-form system</title>
		<author>
			<persName><forename type="first">F</forename><surname>Vinckier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Dubus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sigman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2007.05.031</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="143" to="156" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Parallel programming of saccades during natural scene viewing: Evidence from eye movement positions</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">X W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">O</forename><surname>Gilani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J A</forename><surname>Van Boxtel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Amihai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Yen</surname></persName>
		</author>
		<idno type="DOI">10.1167/13.12.17</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">17</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Transposed-letter effects reveal orthographic processing in baboons</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hannagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dufau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Montant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fagot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grainger</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797612474322</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1609" to="1611" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
