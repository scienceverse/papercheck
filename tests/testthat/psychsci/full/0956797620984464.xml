<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">984464P SSXXX10.1177/0956797620984464Fernandes, CastelhanoInitial Scene Representations Across Depth</title>
				<funder>
					<orgName type="full">Ontario Ministry of Research and Innovation Early Researcher Award</orgName>
				</funder>
				<funder>
					<orgName type="full">Natural Sciences and Engineering Research Council of Canada</orgName>
				</funder>
				<funder ref="#_EXahJnF">
					<orgName type="full">Canadian Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Monica</forename><forename type="middle">S</forename><surname>Castelhano</surname></persName>
							<email>monica.castelhano@queensu.ca</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">Department of Psychology</orgName>
								<orgName type="institution" key="instit1">University</orgName>
								<orgName type="institution" key="instit2">Queen&apos;s University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">Department of Psychology</orgName>
								<orgName type="institution" key="instit1">University</orgName>
								<orgName type="institution" key="instit2">Queen&apos;s University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">Department of Psychology</orgName>
								<orgName type="institution" key="instit1">University</orgName>
								<orgName type="institution" key="instit2">Queen&apos;s University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Suzette</forename><surname>Fernandes</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">Department of Psychology</orgName>
								<orgName type="institution" key="instit1">University</orgName>
								<orgName type="institution" key="instit2">Queen&apos;s University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">984464P SSXXX10.1177/0956797620984464Fernandes, CastelhanoInitial Scene Representations Across Depth</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6F2AC7CAB488B727B8CB0C773B30A7F3</idno>
					<idno type="DOI">10.1177/0956797620984464</idno>
					<note type="submission">Received 11/21/18; Revision accepted 10/20/20</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-06-03T13:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>rapid scene-gist perception</term>
					<term>scene categorization</term>
					<term>depth</term>
					<term>contextual bias</term>
					<term>open data</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>When you walk into a large room, you perceive visual information that is both close to you in depth and farther in the background. Here, we investigated how initial scene representations are affected by information across depth. We examined the role of background and foreground information on scene gist by using chimera scenes (images with a foreground and background from different scene categories). Across three experiments, we found a foreground bias: Information in the foreground initially had a strong influence on the interpretation of the scene. This bias persisted when the initial fixation position was on the scene background and when the task was changed to emphasize scene information. We concluded that the foreground bias arises from initial processing of scenes for understanding and suggests that scene information closer to the observer is initially prioritized. We discuss the implications for theories of scene and depth perception.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Imagine walking into a room for the first time. Rapidly, you understand the size and shape of the space, different objects, and other visual features. Researchers have known for decades that the overall meaning of a scene is quickly extracted <ref type="bibr" target="#b9">(Castelhano &amp; Henderson, 2008;</ref><ref type="bibr" target="#b33">Potter, 1975;</ref><ref type="bibr" target="#b40">Williams &amp; Castelhano, 2019)</ref>. In a seminal study, <ref type="bibr" target="#b33">Potter (1975)</ref> first demonstrated that humans were able to ascertain a scene's general meaning (scene gist) with as little as 113 ms of exposure. Since then, other researchers have shown that people understand scenes after even briefer presentations (e.g., 20-40 ms; <ref type="bibr" target="#b38">Thorpe et al., 1996)</ref>. Subsequent studies on scene gist have explored how different sources of information contribute to rapid scene understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scene-Gist Processing</head><p>In studies examining rapid scene understanding, researchers have parsed visual information in various ways. For instance, <ref type="bibr" target="#b36">Schyns and Oliva (1994)</ref> posited that visual information is extracted from a coarse-to-fine gradient. They presented participants with hybrid images composed of low-pass and high-pass information from separate images. When briefly presented, scenes were categorized according to low-frequency information, but when presented for additional time, they were categorized according to high-frequency information.</p><p>Researchers have also contrasted global scene structure with local visual details. Global information is defined as the overall shape of the scene background <ref type="bibr" target="#b20">(Greene &amp; Oliva, 2009;</ref><ref type="bibr" target="#b28">Munneke et al., 2013)</ref>, whereas local visual details are often defined as the movable objects <ref type="bibr" target="#b21">(Henderson &amp; Hollingworth, 1999;</ref><ref type="bibr" target="#b32">Pereira &amp; Castelhano, 2014;</ref><ref type="bibr" target="#b39">Williams, 2010)</ref>. Although both influences affect scene interpretation, the consensus is that scene gist is largely derived from the global structure. However, despite years of research on how scenes are processed, it is not yet clear how information across depth is initially perceived.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Information Across Depth</head><p>Studies of depth perception have traditionally examined how information across distance is processed: from peripersonal to vista space <ref type="bibr" target="#b15">(Costantini et al., 2011;</ref><ref type="bibr" target="#b16">Cutting &amp; Vishton, 1995;</ref><ref type="bibr" target="#b30">Nagata, 1991)</ref>. However, recent studies have shown that observers process space closer to them in a qualitatively different manner than space farther from them <ref type="bibr" target="#b2">(Bonner &amp; Epstein, 2017</ref><ref type="bibr">, 2018;</ref><ref type="bibr" target="#b24">Josephs &amp; Konkle, 2019)</ref>. For example, <ref type="bibr" target="#b24">Josephs and Konkle (2019)</ref> found that scene representations of reachable spaces are qualitatively different from representations of close-up objects or larger scene spaces. Given qualitative differences in processing across depth, it stands to reason that information closer in depth may have different utility and, thus, influence initial scene processing. Notably, this contrasts with studies suggesting a primary role of global scene structure in scene-gist understanding. The present study examined whether information presented at different depths (foreground and background) affected initial interpretation of scenes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Foreground and Background</head><p>In the current study, scene information across depth was manipulated so that information in the foreground and background contained content from different scene categories (i.e., chimera scenes; see Fig. <ref type="figure" target="#fig_0">1</ref>; <ref type="bibr" target="#b6">Castelhano et al., 2019)</ref>. We defined the background as the large boundary defining elements such as walls, floors, and ceilings and the foreground as the content objects closer to the observer. We operationalized the distinction by manipulating the information within scene categories (e.g., kitchen, office) at roughly 50% of the overall room depth (foreground in front half and background in back half; see the Method section). With this distinction, we examined how scene-gist perception is influenced by the background and foreground when each have different interpretations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Present Study</head><p>Across three experiments, scene images had foregrounds and backgrounds that were semantically either matched (normal scenes) or mismatched (chimera scenes). To examine the interpretation of these scenes, we used the contextual-bias paradigm <ref type="bibr" target="#b9">(Castelhano &amp; Henderson, 2008)</ref>, which allowed us to measure scene understanding without relying on judgments of scenecategory names. The contextual-bias paradigm reflects scene-gist understanding using the participant's bias to confirm consistent target objects and to disconfirm inconsistent targets.</p><p>In each experiment, we examined shorter (50 ms or 100 ms) and longer (250 ms or 330 ms) exposure durations in two subexperiments. Experiment 1 examined performance when scenes were viewed from the image center. Experiment 2 investigated whether initial perception was influenced by fixation position. For each image, participants fixated on scenes' foreground or background. Experiment 3 examined the effect of task and had participants respond to scene-category names. Across all experiments, we found that, initially, participants were strongly influenced by the scene foreground.</p><p>Experiment 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants. Two groups of 36 participants took part in Experiments 1a and 1b. They were compensated with either course credit or an honorarium at the rate of $10 per hour. All participants had normal or corrected-tonormal vision. This study was approved by Queen's University's General Research Ethics Board. Sample size was determined on the basis of the effect size for the contrast between the consistent and inconsistent target responses for 50-ms presentations <ref type="bibr" target="#b9">(Castelhano &amp; Henderson, 2008)</ref>, which showed a medium to large effect size (d = 0.6-2.7) depending on condition. Because we were interested in determining how manipulated scenes would affect interpretation, we used a conservative effect size (d) of 0.5, an alpha of .05, and power of .8 for our sample-size computation (G*Power Version 3.1.9.2; <ref type="bibr" target="#b19">Faul et al., 2007)</ref>. The estimated sample size was 34 participants, but we used 36 to fit the counterbalancing (six conditions), which yielded a power estimate of .83.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and apparatus. Using Complete Home</head><p>Designer <ref type="bibr">(Version 5.0;</ref><ref type="bibr">Data Becker, 2003)</ref>, we created computer-generated colored images consisting of both indoor and outdoor scene categories (for example scenes, see Fig. <ref type="figure" target="#fig_0">1</ref>). All scenes were created using the same template; they were built into the corner with two adjoining walls providing the main definition of the space and depth of the scene. Thus, indoor and outdoor scenes had a similar shape and depth. Each image's background and foreground areas were then identified and partitioned. 1  The depth of the foreground information (from the camera position to the back wall) occupied, on average, 52% (SD = 13%) of the distance. When images were rendered as 2D, the pixel content for the foreground versus background was roughly equated (51% foreground, 49% background).</p><p>To create the chimera scenes, we matched two images from separate scene categories and then paired the foreground of one image with the semantically different background of the other image. The experimental stimuli consisted of 48 scenes, each with a normal and chimera version, for a total of 96 images. The study was run using MATLAB R2014a ( Version 8.3; The Math-Works, Natick, MA) and the Psychophysics Toolbox (Version 3; Brainard, 1997) on a 21-in. CRT monitor with a refresh rate of 100 Hz, a resolution of 800 × 600 pixels. Stimuli subtended 38.1° × 26.6°. Head position was restricted with a chin rest located approximately 60 cm from the monitor.</p><p>Design. For each experiment, a 2 (presentation duration) × 2 (scene type: normal, chimera) × 3 (target condition: foreground, background, inconsistent control) within-subjects design was used. The presentation duration was 50 ms and 100 ms for Experiment 1a and 250 ms and 330 ms for Experiment 1b. Participants saw a total of 48 images divided into an equal number of different scene types (24 normal scenes and 24 chimera scenes). The target word belonged to one of three conditions: (a) consistent with the background scene category (background condition), (b) consistent with the foreground scene category (foreground condition), or (c) inconsistent with both the background and the foreground scene category (inconsistent control condition). Target objects were never present in the image.</p><p>Procedure. The procedure followed the contextual-bias paradigm <ref type="bibr" target="#b9">(Castelhano &amp; Henderson, 2008)</ref>. Prior to beginning the experiment, participants provided written informed consent. Across conditions, participants were each tested individually. Participants were instructed to view briefly presented images and, on the following query screen, make a response regarding whether the named target object seemed appropriate in the context of the scene. There were no practice trials. Participants' heads were not restrained, but they sat approximately 60 cm from the monitor. On each trial, participants were presented with a black fixation dot centered on a gray screen. An image then appeared on the screen for the duration corresponding with the duration condition. This was followed by a mask image for 50 ms. The mask image was made of individual sections of different scene images to provide a wide range of visual features. The targetobject word then appeared, and participants indicated via a response box whether that target object was likely to be found in the image (yes/no). The target names were manipulated such that the object was consistent with either the foreground or the background exclusively or was inconsistent with both scene contexts. Each target-object type was presented with equal frequency across trials. Importantly, as noted above, the queried target objects were never present in the scenes. Thus, the response did not reflect detection of the object but, rather, the response bias of how likely the object was to appear in the scene. The logic was that if the foreground (or background) was perceived, then responding "yes" was more likely when the object was consistent with the scene and more unlikely when the target was inconsistent with the scene. Thus, responses were driven by the interpretation of the scene gist, so gist perception was measured indirectly by examining the difference between the consistent and inconsistent responses.</p><p>All images and conditions were counterbalanced across participants and were randomly intermixed throughout the experiment. Importantly, participants saw each scene only once. For the scene images and the different target names, see the Supplemental Material available online. The experimental session lasted approximately 15 to 20 min.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>To determine how participants attended to the foreground and the background of a scene, we calculated the mean proportion of times the participants responded "yes" to the target object. This was used as the dependent variable for all reported analyses. Because data from each group of participants were collected at different times, the analyses for Experiments 1a and 1b were conducted separately; however, exploratory analysis across both experiments can be found in the Supplemental Material.</p><p>The main a priori analyses focused on how interpretation of the chimera scenes changed over time. To this end, we conducted planned comparisons contrasting the responses in the foreground and background conditions with responses in the control condition (inconsistent target) at each exposure duration. We also planned contrasts between the responses for the foreground and background scenes to examine whether they differed at each duration. This is interesting because in reality, both of these interpretations of the scene are legitimate. However, responses that favor one over another would allow us to examine whether one source of information was privileged over the other. Thus, for each duration condition, we conducted three a priori comparisons: foreground versus inconsistent control, background versus inconsistent control, and foreground versus background. For all planned comparisons, alpha was adjusted such that the familywise error did not exceed .05. The specific alpha used is reported below prior to the report of the tests. 2  We performed the analyses on the normal-scene condition (α = .004) as a manipulation check. As might be expected, we found that responses in both the foreground and background conditions were significantly different from responses in the inconsistent condition for both the 50-ms duration-foreground: t(35) = 7.66, p &lt; .001, d = 1.81; background: t(35) = 7.76, p &lt; .001, d = 1.72-and the 100-ms duration-foreground: t(35) = 20.92, p &lt; .001, d = 3.76; background: t(35) = 13.44, p &lt; .001, d = 3.31. This pattern, which showed that participants were engaged and able to complete the task, replicated previous results <ref type="bibr" target="#b9">(Castelhano &amp; Henderson, 2008)</ref>.</p><p>Accordingly, we found no difference in responses between the foreground and background targets for either the 50-ms duration, t(35) = 0.40, p = .692, d = 0.07, or the 100-ms duration, t(35) = 1.21, p = .233, d = 0.25. This was expected because regardless of whether the foreground or background was initially used for the interpretation, the response would be the same. Thus, because the normal condition was not of theoretical interest, it will not be discussed or reported further; however, means are included in all graphs for completeness.</p><p>The mean proportion of "yes" responses across the scene-type and target conditions in Experiment 1a are shown in the top row of Figure <ref type="figure" target="#fig_2">2</ref>. As mentioned above, planned comparisons were done on the chimera scenes because these images contained the theoretically interesting contrast between scene categories within a single image (six comparisons, α = .00833). When we compared the foreground and background conditions with the inconsistent control condition, we found that at 50 ms, participants responded "yes" in the foreground condition more than in the control condition, t(35) = 4.40, p &lt; .001, d = 1.10, but interestingly, we did not see a significant difference in responses between the background and control conditions, t(35) = -1.28, p = .21, d = -0.23. The pattern persisted in the 100-ms duration condition; participants responded "yes" significantly more often in the foreground condition than in the control condition, t(35) = 15.26, p &lt; .001, d = 3.06, but not in the background condition, t(35) = 0.71, p = .48, d = 0.15. To assess the bias directly, we compared the foreground and background conditions directly and found a significantly greater proportion of "yes" responses for the foreground than the background for both the 50-ms duration, t( <ref type="formula">35</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>When we examined the position of the fixation cross (prior to the presentation of the image), we found that this central position often overlapped with the foreground scene region (78%). Thus, information at fixation could explain the results of Experiment 1. In Experiment 2, we manipulated where the participants were looking when the scene was presented by changing the position of the initial fixation prior to image presentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants. Two groups of 48 participants each took part in Experiments 2a and 2b for course credit or were paid $10 per hour. All participants had normal or corrected-to-normal vision, and none had participated in the previous experiment. Sample size was determined using the effect size for the contrast between the foreground and background conditions from Experiment 1, which was large (d = 0.87-3.30) across duration conditions. Because we were interested in determining the effects of fixation position on interpretation, we used a medium effect size (d) of 0.6, an alpha of .004 ( Bonferroni corrected for the current study), and power of .8 for our sample-size computation (G*Power Version 3.1.9.2; <ref type="bibr" target="#b19">Faul et al., 2007)</ref>. The estimated sample size was 33 participants, but to fit the counterbalancing, we recruited 48, which yielded a power estimate of .86.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design.</head><p>A two-level factor manipulating fixation placement was added to create a 2 (initial fixation position: background, foreground) × 2 (presentation duration) × 2 (scene type: normal, chimera) × 3 (target condition: foreground, background, inconsistent control) withinsubjects design. 3 The presentation duration was 50 ms and 100 ms for Experiment 2a and 250 ms and 330 ms for Experiment 2b.</p><p>Procedure. The procedure was identical to that in Experiment 1, with the exception of the placement of the fixation cue. The fixation cue was placed in either the foreground or the general background region of the scene. The location was predetermined for each scene individually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Again, the mean proportion of times that participants indicated "yes" to the match between the target word and the scene was calculated and used as the dependent variable in all analyses. For all planned comparisons, alpha was adjusted such that the familywise error did not exceed .05. The specific alpha used is reported below prior to the report of the tests. Because data from each group of participants were collected at different times, analyses for Experiments 2a and 2b were conducted separately; however, an exploratory analysis across both experiments can be found in the Supplemental Material.</p><p>The mean proportion of "yes" responses across the scene-type, target, and fixation conditions in Experiment 2a are shown in the top row of Figure <ref type="figure" target="#fig_3">3</ref>. To examine effects on response bias, we conducted planned comparisons of the foreground and background conditions with the inconsistent control condition for each duration condition at each fixation position (12 comparisons, α = .004167). As might be expected, when the fixation dot was positioned on the foreground, the pattern of responses did not change from the first experiment. For both the 50-ms and 100-ms duration conditions, participants responded "yes" to the foreground condition, t(47) = 4.69, p &lt; .001, d = 0.91, more than the control condition, t(47) = 5.51, p &lt; .001, d = 1.05. Interestingly, they did not show a significant difference in responses between the background and control conditions for 50-ms durations, t(47) = 1.46, p = .15, d = 0.27, but did show a significant difference (yielding a medium-size effect) in the 100-ms condition, t(47) = 3.10, p = .003, d = 0.57. When we compared the responses from the foreground and background conditions directly, we found that participants had a significant bias toward the foreground targets for the 50-ms duration, t(47) = 3.00, p = .004, d = 0.60, but there was no significant difference for the 100-ms duration, t(47) = 1.91, p = .063, d = 0.36. Thus, compared with the effect in the previous experiment, the effect here persisted but was diminished.</p><p>Surprisingly, when the fixation dot was in the background, we found that participants continued to show the foreground bias. Participants responded "yes" in the foreground condition more than the inconsistent control condition-50 ms: t(47) = 6.93, p &lt; .001, d = 1.32; 100 ms: t(47) = 4.85, p &lt; .001, d = 1.09-but their responses in the background and inconsistent control conditions were not significantly different for 50-ms durations, t(47) = 1.95, p = .057, d = 0.42. However, there was a significant difference in the 100-ms condition, t(47) = 5.38, p &lt; .001, d = 1.09.</p><p>When we compared the responses from the foreground and background conditions directly, we found that participants showed a significant bias for the foreground targets at the 50-ms duration, t(47) = 4.64, p &lt; .001, d = 0.90, but not at the 100-ms duration, in which the means were almost identical, t(47) &lt; 1. Therefore, these results showed that a strong bias toward the foreground remained early on, even when the fixation position varied. Although it was not surprising that there was a foreground bias when the fixation location was in the foreground, the bias never reversed to the background of a scene when the background was fixated directly. Instead, the foreground bias was present with</p><p>0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Foreground Background Inconsistent Control Foreground Background Inconsistent Control Foreground Fixation Background Fixation Proportion of "Yes" Responses 50 ms Normal Chimera 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Foreground Background Inconsistent Control Foreground Background Inconsistent Control Foreground Background Inconsistent Control Foreground Background Inconsistent Control Foreground Background Inconsistent Control Foreground Background Inconsistent Control Foreground Fixation Background Fixation Proportion of "Yes" Responses 100 ms 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Foreground Fixation Background Fixation Proportion of "Yes" Responses 250 ms 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Foreground Fixation Background Fixation Proportion of "Yes" Responses 330 ms short exposures (50 ms), and then, with increased exposure, responses were equally likely between the foreground and background conditions. To further assess the effects of fixation location and to see whether the effect would eventually reverse, we conducted another experiment with longer exposure durations: 250 ms and 330 ms.</p><p>The mean proportion of "yes" responses across the scene-type, target, and fixation conditions in Experiment 2b are shown in the bottom row of Figure <ref type="figure" target="#fig_3">3</ref>. To assess whether the bias toward the foreground of scenes continued with longer presentation times, we conducted the three planned comparisons contrasting the foreground and background conditions as before for each duration condition at each fixation location (12 comparisons, α = .004167). When the fixation dot was positioned on the foreground, participants responded "yes" in the foreground condition more than the control condition-250 ms: t(47) = 7.51, p &lt; .001, d = 1.63; 330 ms: t(47) = 10.01, p &lt; .001, d = 2.06-and to the background condition more than the control condition-250 ms: t(47) = 3.00, p = .004, d = 0.65; 330 ms: t(47) = 4.23, p &lt; .001, d = 0.92. Additionally, when we compared the responses from the foreground and the background conditions directly, we found that participants still had a significant bias toward foreground targets for both presentation durations-250 ms: t( <ref type="formula">47</ref> The pattern was somewhat different when the fixation dot was in the background. We found that participants responded "yes" in the foreground condition more than in the control condition-250 ms: t(47) = 6.37, p &lt; .001, d = 1.33; 330 ms: t(47) = 3.97, p &lt; .001, d = 0.87-and in the background condition more than in the control condition-250 ms: t(47) = 6.38, p &lt; .001, d = 1.20; 330 ms: t(47) = 5.90, p &lt; .001, d = 1.27. When we compared directly, we found that in neither duration condition did participants show a significant bias for foreground targets-250 ms: t(47) = 0.636, p = .528, d = 0.14; 330 ms: t(47) = -1.50, p = .14, d = -0.32. Instead, it seems that participants were responding to the foreground and background targets in equal measure. Interestingly, although background fixation did eliminate the foreground bias at longer exposure durations, it was never reversed such that background information was favored significantly over foreground information. This suggests that processing of the foreground is mitigated by fixation position but also that even when the background information is fixated, the foreground continues to exert a strong influence on scene understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3</head><p>Although the foreground bias seems to be quite robust, the previous experiments required participants to respond to queries about the presence of objects, which may have inadvertently encouraged participants to strategically focus on the foreground. To examine whether the foreground bias resulted from the task, we conducted a third experiment examining participants' responses to the scene-category name.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants. Two groups of 36 participants each provided informed consent and took part in Experiment 3 for course credit or were given $10 per hour for their time. All participants had normal or corrected-to-normal vision, and none had participated in the previous experiments. The sample size was based on the calculations used in Experiment 1, given that the design and effects of interest were identical.</p><p>Design. Similar to Experiment 1, Experiment 3 had a 2 (presentation duration) × 2 (scene type: normal, chimera) × 3 (target condition: foreground, background, inconsistent control) within-subjects design. As in Experiment 1, scenes in Experiment 3a were presented for 50 ms or 100 ms, and scenes in Experiment 3b were presented for 250 ms or 330 ms.</p><p>Procedure. The procedure was identical to that in Experiments 1 and 2, with the exception of the query: Instead of a target-object word appearing after the scene, a scene-category name was presented. The scene query belonged to one of three conditions: (a) background scene category, (b) foreground scene category, or (c) inconsistent (with either the background or the foreground scene category). The participants' task was to indicate whether the scene-category word matched the image by pressing a button for yes or a button for no.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The mean proportion of times that a participant indicated "yes" that the scene category matched the scene was calculated and used as the dependent variable for all analyses. Because data from each group of participants were collected at different times, analyses for Experiments 3a and 3b were conducted separately; however, exploratory analysis across both experiments can be found in the Supplemental Material.</p><p>The mean proportion of "yes" responses across the scene-type and scene conditions in Experiment 3a are shown in the top row of Figure <ref type="figure" target="#fig_5">4</ref>. Planned comparisons using paired-samples t tests showed that when participants responded to scene-category names, the patterns of response were similar to those in Experiment 1 (six comparisons, α = .00833). When we compared the foreground and background conditions with the inconsistent condition, we found that at 50 ms, participants responded "yes" to the foreground condition more than the control condition, t(35) = 5.93, p &lt; .001, d = 1.47, but interestingly, we did not see a significant difference in responses between the background and control conditions, t(35) = 1.30, p = .20, d = 0.29. Interestingly, the pattern for 100 ms changed; there were significantly more "yes" responses in both the foreground and background conditions than in the control condition, t(35) = 11.07, p &lt; .001, d = 2.94, and t(35) = 5.073, p &lt; .001, d = 0.95, respectively. To assess the foreground bias, we compared responses to foreground and background conditions and found a significantly greater proportion of responses for the foreground than the background condition for both the 50-ms duration, t(35) = 4.78, p &lt; .001, d = 1.24, and the 100-ms duration, t(35) = 5.67, p &lt; .001, d = 1.53. Thus, even when the judgment was about the scene, the foreground bias persisted. To determine whether this bias would be affected by longer exposure, we showed scenes for 250 ms and 330 ms.</p><p>The mean proportion of "yes" responses across the scene-type and scene conditions in Experiment 3b are shown in the bottom row of Figure <ref type="figure" target="#fig_5">4</ref>. When scenes were shown for 250 ms and 330 ms, planned comparisons using paired-samples t tests (six comparisons, α = .00833) showed a similar pattern of results as in the 100-ms duration condition. When we compared responses in the foreground and background conditions with responses in the inconsistent condition for the 250-ms duration condition, we found significantly more "yes" responses for both the foreground condition, t( <ref type="formula">35</ref> t(35) = 14.82, p &lt; .001, d = 2.92; background: t(35) = 6.52, p &lt; .001, d = 1.27. To assess the foreground bias, we compared responses to foreground and background conditions and found a significantly greater proportion of responses for the foreground than the background conditions for both the 250-ms duration, t(35) = 3.50, p &lt; .002, d = 1.24, and the 330-ms duration, t(35) = 4.66, p &lt; .001, d = 0.93. Thus, even with longer presentation durations and when the scene category was judged, the foreground bias persisted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>Across three experiments, we found that when given conflicting scene information across depth, participants were initially more influenced by the foreground than background of a scene. Experiment 1 showed that the foreground bias was present for 50-ms and 100-ms exposure durations but dissipated at longer durations. In Experiment 2, when the fixation position overlapped with a scene's background, the foreground bias persisted at brief exposure durations (50 ms), but with longer presentation durations, it was weak (100 ms) or absent (250 ms and 330 ms). It is interesting to note that we never saw participants show a preference for the background, even when they fixated it directly. In Experiment 3, we modified the task to encourage focus on the whole scene and found that the task only slightly modified the pattern of results. The foreground bias remained, but the background was also correctly interpreted when the image was shown for a longer duration (100 ms). Interestingly, across experiments, we never saw a reverse effect favoring background information, suggesting that the foreground bias was robust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Central bias versus foreground bias</head><p>The central bias reflects the tendency to direct fixations to the center of an image <ref type="bibr" target="#b1">(Bindemann, 2010;</ref><ref type="bibr" target="#b37">Tatler, 2007)</ref>. Researchers have posited that there are two potential sources <ref type="bibr" target="#b1">(Bindemann, 2010)</ref>. First, the central position allows for the maximal perception of information across the whole scene and, thus, represents an optimal viewing position (e.g., <ref type="bibr" target="#b27">McConkie et al., 1988)</ref>. In Experiment 2, we examined the central bias on the basis of this optimal-viewing-position interpretation. If central bias accounts for the effect because the foreground overlapped with the center, then we would expect the foreground bias to disappear (and be dominated by the information at the fixation position). On the other hand, if the central bias were orthogonal to the foreground bias and both have an effect, then we would expect processing differences between the foreground and background of scenes to persist. Our results are consistent with the latter. Although we do not dispute that the central bias may play a role, the findings show that the foreground bias is an important separate effect.</p><p>The central bias has also been described as an inherent property of the scene itself, where information at the center is driving the effect <ref type="bibr" target="#b1">(Bindemann, 2010;</ref><ref type="bibr" target="#b37">Tatler, 2007)</ref>. For instance, semantically important information is often centered in photographic images <ref type="bibr" target="#b35">(Rensink et al., 1997)</ref>. To test this directly would require a change in the contents of each scene so that no foreground information is in the center (e.g., by changing viewpoints; <ref type="bibr" target="#b11">Castelhano &amp; Pollatsek, 2010;</ref><ref type="bibr" target="#b12">Castelhano et al., 2009)</ref>. Although we did not have this manipulation, we did a further post hoc examination of the Experiment 1a data with scenes in which the foreground was not in the center. We found that the pattern of the means was consistent with the results across all experiments, although fewer data points meant that the pattern of results was more uneven (for the analyses, see the Supplemental Material). For instance, for 100-ms scene durations, we found a significant difference between responses in the foreground-target condition and control condition and between the foreground-and background-target conditions, but not between the background-target condition and the control condition. Although post hoc analyses suggest that the foreground bias is robust, further investigation is necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention allocation and scene-gist perception</head><p>Many previous studies have shown that the focus of attention is initially diffuse and becomes more focused with time <ref type="bibr">(Castelhano &amp; Henderson, 2003</ref><ref type="bibr" target="#b37">, 2007;</ref><ref type="bibr" target="#b22">Henderson et al., 2003;</ref><ref type="bibr" target="#b36">Schyns &amp; Oliva, 1994)</ref>. When one considers Experiment 2, one interpretation of the pattern across duration conditions is that processing is influenced by information at fixation over time. Alternatively, one could interpret the same pattern as the ever-increasing influence of background information because more processing time is possible. For instance, the pattern shows a decrease in responses to the foreground target as more time for processing is allowed, presumably incorporating the contradiction between the foreground and the background. Research on how information prioritization across depth changes over time would be needed to delineate how this bias and attentional processes interact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spatial-information processing in scenes</head><p>The current study is a first step in examining how the z-axis of scenes impacts initial processing. Researchers have begun to examine information across different depths in scenes <ref type="bibr" target="#b2">(Bonner &amp; Epstein, 2017</ref><ref type="bibr">, 2018;</ref><ref type="bibr" target="#b24">Josephs &amp; Konkle, 2019)</ref>. Taken together with current findings, it seems that the immediately surrounding scene space within which we can plan and execute actions (actionable space) may be prioritized early on and processed differently from more distant scene regions.</p><p>In the depth-perception literature, many researchers categorize the information available at different depths, linking distance to specific types of processing <ref type="bibr" target="#b0">( Armbrüster et al., 2008;</ref><ref type="bibr" target="#b15">Costantini et al., 2011;</ref><ref type="bibr" target="#b16">Cutting &amp; Vishton, 1995;</ref><ref type="bibr" target="#b34">Previc, 1998)</ref>. For instance, by dividing space into peripersonal, actionable, and vista spaces <ref type="bibr" target="#b15">(Costantini et al., 2011;</ref><ref type="bibr" target="#b16">Cutting &amp; Vishton, 1995)</ref>, researchers have found that different cues are extracted with increasing depth, such as motion perspective (i.e., motion parallax), height (i.e., in the field), and relative density (i.e., texture gradient). Thus, there are functionally different types of information available across depth. Furthermore, this categorization of spatial proximity introduces an interesting framework from which to consider the nexus of processing scene context, objects, and actions (e.g., <ref type="bibr" target="#b2">Bonner &amp; Epstein, 2017;</ref><ref type="bibr" target="#b10">Castelhano &amp; Pereira, 2018;</ref><ref type="bibr" target="#b13">Castelhano &amp; Witherspoon, 2016;</ref><ref type="bibr" target="#b23">Josephs et al., 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Influence of the foreground</head><p>The current study suggests that the foreground bias may extend to later processing. Although the response bias for the foreground dissipated with increased exposure, it was never reversed, even when the background was directly fixated or when the task changed to focus on the scene as a whole. Thus, it seems that the influence of the foreground continued. This is consistent with the few studies examining foreground and background processing in other tasks. For instance, <ref type="bibr" target="#b26">Mazza et al. (2005)</ref> found in a change-detection task that changes were detected more quickly in the scene foreground than the scene background. More recently, we found that during visual search, target objects were found faster when they were located in the foreground than in the background (even when object size was controlled; <ref type="bibr" target="#b25">Man et al., 2019)</ref>. Together, these studies suggest that prioritizing the foreground may continue to exert influence in later processing, but further research is needed to delineate its extent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>The current results have implications for models of scene representations and the representations of an observer's immediate surrounding space. The present study suggests that consideration of different categories of space across depth offers a framework within which different types of scene processing can be understood. With increased accessibility to techniques such as virtual reality environments, we believe that this theoretical approach could offer new insights into exploring visual processing in the real world and processing differences across the z-axis of scenes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transparency</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflicting Interests</head><p>The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article.</p><p>type of scenes they were. We found that although backgrounds were categorized significantly more accurately, t(18) = 4.26, p &lt; .01, than foregrounds, both were categorized at a high level of accuracy (95% correct vs. 89% correct, respectively). 2. For each contrast, we report Cohen's d <ref type="bibr" target="#b14">(Cohen, 1988)</ref> based on the within-subjects formula.</p><p>3. Because of the limited number of chimera scenes, we had two items per condition. This rather low number of data points per condition was not ideal but was offset by increasing the number of participants per condition, using a completely within-subjects design, and adopting conservative analyses <ref type="bibr" target="#b29">(Murphy et al., 2014)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Example stimuli from two indoor-scene categories. The top row shows the normal versions of a kitchen and an office scene, and the bottom row shows the chimera versions of the scenes. The chimera versions were created by matching two images from separate categories and then swapping the foreground objects.</figDesc><graphic coords="3,49.50,69.00,504.00,356.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc>) = 6.15, p &lt; .001, d = 1.35, and the 100-ms duration, t(35) = 12.35, p &lt; .001, d = 3.03.The mean proportion of "yes" responses across the scene-type and target conditions in Experiment 1b are shown in the bottom row of Figure2. As above, we conducted planned comparisons across target conditions at each duration condition (250 ms and 330 ms) for the chimera scenes (six comparisons, α = .00833). Participants were able to distinguish the foreground target from the inconsistent control target in both the 250-ms duration condition, t(35) = 8.49, p &lt; .001, d = 2.33, and the 330-ms duration condition, t(35) = 10.41, p &lt; .001, d = 2.63. Additionally, participants were able to distinguish the background target from the inconsistent control target in both the 250-ms duration condition, t(35) = 3.70, p = .001, d = 1.00, and the 330-ms duration condition, t(35) = 5.01, p &lt; .001, d = 1.36, in contrast to the results of Experiment 1a. When the foreground and background conditions were contrasted directly, results showed that participants remained significantly biased toward the foreground in both the 250-ms duration condition, t(35) = 5.07, p &lt; .001, d = 1.21, and the 330-ms duration condition, t(35) = 4.23, p &lt; .001, d = 0.87.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Mean proportion of "yes" responses for normal and chimera scenes for each of the target conditions in Experiment 1a (top row) and Experiment 1b (bottom row). Results are shown separately for each of the four exposure durations. Error bars represent standard errors of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Mean proportion of "yes" responses for normal and chimera scenes for each of the target and fixation conditions in Experiment 2a (top row) and Experiment 2b (bottom row). Results are shown separately for each of the four exposure durations. Error bars represent standard errors of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><figDesc>) = 4.15, p &lt; .001, d = 0.85; 330 ms: t(47) = 4.46, p &lt; .001, d = 0.85.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Mean proportion of "yes" responses for normal and chimera scenes for each of the target conditions in Experiment 3 a (top row) and Experiment 3b (bottom row). Results are shown separately for each of the four exposure durations. Error bars represent standard errors of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><figDesc>Action Editor: Patricia J. Bauer Editor: Patricia J. Bauer Author Contributions M. S. Castelhano conceived and designed the study. S. Fernandes analyzed and interpreted the data under the supervision of M. S. Castelhano. S. Fernandes drafted the manuscript, and M. S. Castelhano provided critical revisions. Both authors approved the final manuscript for submission.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank <rs type="person">Ellen O'Donoghue</rs>, <rs type="person">Louisa Man</rs>, <rs type="person">Morgan Vallati</rs>, <rs type="person">Elysée Kukwabantu</rs>, and <rs type="person">Shane Kennedy</rs> for their help with data collection.</p></div>
			</div>
			<div type="funding">
<div><head>Funding</head><p>This work was supported by a <rs type="funder">Natural Sciences and Engineering Research Council of Canada</rs> grant, a <rs type="funder">Canadian Foundation</rs> <rs type="grantName">for Innovation grant</rs>, and an <rs type="funder">Ontario Ministry of Research and Innovation Early Researcher Award</rs>, all to <rs type="person">M. S. Castelhano</rs>.</p></div>
<div><head>Open Practices</head><p>All data have been made publicly available via OSF and can be accessed at <ref type="url" target="https://osf.io/4d9u6/">https://osf.io/4d9u6/</ref>. The design and analysis plans for the experiments were not preregistered. This article has received the badge for Open Data. More information about the Open Practices badges can be found at <ref type="url" target="http://www.psychologicalscience.org/publications/badges">http://www.psychologicalscience.org/publications/  badges</ref>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_EXahJnF">
					<orgName type="grant-name">for Innovation grant</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplemental Material</head><p>Additional supporting information can be found at <ref type="url" target="http://journals.sagepub.com/doi/suppl/10.1177/0956797620984464">http://  journals.sagepub.com/doi/suppl/10.1177/0956797620984464</ref> Notes 1. We rendered the foreground and the background images separately (background only or foreground only) and asked a separate group of participants (N = 20) to categorize which</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Depth perception in virtual reality: Distance estimations in peri-and extrapersonal space</title>
		<author>
			<persName><forename type="first">C</forename><surname>Armbrüster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wolter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kuhlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Spijkers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fimm</surname></persName>
		</author>
		<idno type="DOI">10.1089/cpb.2007.9935</idno>
		<ptr target="https://doi.org/10.1089/cpb.2007.9935" />
	</analytic>
	<monogr>
		<title level="j">CyberPsychology &amp; Behavior</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="15" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scene and screen center bias early eye movements in scene viewing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bindemann</surname></persName>
		</author>
		<idno type="DOI">10.1016/J.VISRES.2010.08.016</idno>
		<ptr target="https://doi.org/10.1016/J.VISRES.2010.08.016" />
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="2577" to="2587" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Coding of navigational affordances in the human visual system</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Bonner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Epstein</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1618228114</idno>
		<ptr target="https://doi.org/10.1073/pnas.1618228114" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="4793" to="4798" />
			<date type="published" when="2017">2017</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Computational mechanisms underlying cortical responses to the affordance properties of visual scenes</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Bonner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Epstein</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1006111</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1006111" />
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1006111</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Psychophysics Toolbox</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Brainard</surname></persName>
		</author>
		<idno type="DOI">10.1163/156856897X00357</idno>
		<ptr target="https://doi.org/10.1163/1568568" />
	</analytic>
	<monogr>
		<title level="j">Spatial Vision</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="433" to="436" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<idno type="DOI">10.1163/156856897X00357</idno>
		<imprint>
			<biblScope unit="page" from="97X" to="00357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Examining the hierarchical nature of scene representations in memory</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Castelhano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Theriault</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0000660</idno>
		<ptr target="https://doi.org/10.1037/xlm0000660" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1619" to="1633" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Flashing scenes and moving windows: An effect of initial scene gist on eye movements</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Castelhano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Henderson</surname></persName>
		</author>
		<idno type="DOI">10.1167/3.9.67</idno>
		<ptr target="https://doi.org/10.1167/3.9.67" />
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">67</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Initial scene representations facilitate eye movement guidance in visual search</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Castelhano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Henderson</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-1523.33.4.753</idno>
		<ptr target="https://doi.org/10.1037/0096-1523.33.4.753" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="753" to="763" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The influence of color on the perception of scene gist</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Castelhano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Henderson</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-1523.34.3.660</idno>
		<ptr target="https://doi.org/10.1037/0096-1523.34.3.660" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="660" to="675" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The influence of scene context on parafoveal processing of objects</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Castelhano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Pereira</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470218.2017.1310263</idno>
		<ptr target="https://doi.org/10.1080/17470218.2017.1310263" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="229" to="240" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Extrapolating spatial layout in scene representations</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Castelhano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pollatsek</surname></persName>
		</author>
		<idno type="DOI">10.3758/MC.38.8.1018</idno>
		<ptr target="https://doi.org/10.3758/MC.38.8.1018" />
	</analytic>
	<monogr>
		<title level="j">Memory Cognition</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1018" to="1025" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Integration of multiple views of scenes</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Castelhano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pollatsek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rayner</surname></persName>
		</author>
		<idno type="DOI">10.3758/APP.71.3.490</idno>
		<ptr target="https://doi.org/10.3758/APP.71.3.490" />
	</analytic>
	<monogr>
		<title level="j">Attention, Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="490" to="502" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">How you use it matters: Object function guides attention during visual search in scenes</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Castelhano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Witherspoon</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797616629130</idno>
		<ptr target="https://doi.org/10.1177/0956797616629130" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="606" to="621" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Statistical power analysis for the behavioral sciences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Erlbaum</publisher>
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">When objects are close to me: Affordances in the peripersonal space</title>
		<author>
			<persName><forename type="first">M</forename><surname>Costantini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ambrosini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Scorolli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Borghi</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-011-0054-4</idno>
		<ptr target="https://doi.org/10.3758/s13423-011-0054-4" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="302" to="308" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Perceiving layout and knowing distances: The integration, relative potency, and contextual use of different information about depth</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Cutting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Vishton</surname></persName>
		</author>
		<editor>W.</editor>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<idno type="DOI">10.1016/B978-012240530-3/50005-5</idno>
		<ptr target="https://doi.org/10.1016/B978-012240530-3/50005-5" />
		<title level="m">Handbook of perception and cognition</title>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">S</forename><surname>Epstein</surname></persName>
		</editor>
		<editor>
			<persName><surname>Rogers</surname></persName>
		</editor>
		<imprint>
			<publisher>Academic Press</publisher>
			<biblScope unit="page" from="69" to="117" />
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Complete Home Designer</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Data Becker</publisher>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
	<note>Computer software</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">G*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences</title>
		<author>
			<persName><forename type="first">F</forename><surname>Faul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Erdfelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-G</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buchner</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03193146</idno>
		<ptr target="https://doi.org/10.3758/BF03193146" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="175" to="191" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Recognition of natural scenes from global properties: Seeing the forest without representing the trees</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cogpsych.2008.06.001</idno>
		<ptr target="https://doi.org/10.1016/j.cogpsych.2008.06.001" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="176" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">High-level scene perception</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hollingworth</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.psych.50.1.243</idno>
		<ptr target="https://doi.org/10.1146/annurev.psych.50.1.243" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="243" to="271" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Eye movements and picture processing during recognition</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Castelhano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Falk</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03194809</idno>
		<ptr target="https://doi.org/10.3758/BF03194809" />
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="725" to="734" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Gist in time: Scene semantics and structure enhance recall of searched objects</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Josephs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Draschkow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Võ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-H</forename></persName>
		</author>
		<idno type="DOI">10.1016/J.ACTPSY.2016.05.013</idno>
		<ptr target="https://doi.org/10.1016/J.ACTPSY.2016.05.013" />
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="page" from="100" to="108" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Perceptual dissociations among views of objects, scenes, and reachable spaces</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Josephs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Konkle</surname></persName>
		</author>
		<idno type="DOI">10.1037/xhp0000626</idno>
		<ptr target="https://doi.org/10.1037/xhp0000626" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="715" to="728" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The foreground bias: Differing impacts across depth on visual search in scenes</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L Y</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Krzyś</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Castelhano</surname></persName>
		</author>
		<idno type="DOI">10.31234/OSF.IO/W6J4A</idno>
		<ptr target="https://doi.org/10.31234/OSF.IO/W6J4A" />
	</analytic>
	<monogr>
		<title level="j">PsyArXiv</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Foregroundbackground segmentation and attention: A change blindness study</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mazza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Turatto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Umiltà</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00426-004-0174-9</idno>
		<ptr target="https://doi.org/10.1007/s00426-004-0174-9" />
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="201" to="210" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Eye movement control during reading: I. The location of initial eye fixations on words</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Mcconkie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Kerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Reddix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zola</surname></persName>
		</author>
		<idno type="DOI">10.1016/0042-6989(88)90137-X</idno>
		<ptr target="https://doi.org/10.1016/0042-6989(88)90137-X" />
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1107" to="1118" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The influence of scene context on object recognition is independent of attentional focus</title>
		<author>
			<persName><forename type="first">J</forename><surname>Munneke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Brentari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Peelen</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2013.00552</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2013.00552" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">552</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Statistical power analysis</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Myors</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wolach</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781315773155</idno>
		<ptr target="https://doi.org/10.4324/9781315773155" />
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Routledge</publisher>
		</imprint>
	</monogr>
	<note>4th ed.</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">How to reinforce perception of depth in single two-dimensional pictures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nagata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pictorial communication in virtual and real environments</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Ellis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Kaiser</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Grunwald</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="543" to="563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Francis</forename><surname>Taylor</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Peripheral guidance in scenes: The interaction of scene context and object content</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Castelhano</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0037524</idno>
		<ptr target="https://doi.org/10.1037/a0037524" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2056" to="2072" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Meaning in visual search</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Potter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="page" from="965" to="966" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The neuropsychology of 3-D space</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Previc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="164" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">To see or not to see: The need for attention to perceive changes in scenes</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Rensink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>O'regan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9280.1997.tb00427.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-9280.1997.tb00427.x" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="368" to="373" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Evidence for time-and spatial-scale-dependent scene recognition</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Schyns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="195" to="200" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The central fixation bias in scene viewing: Selecting an optimal viewing position independently of motor biases and image feature distributions</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Tatler</surname></persName>
		</author>
		<idno type="DOI">10.1167/7.14.4</idno>
		<ptr target="https://doi.org/10.1167/7.14" />
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">14</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Speed of processing in the human visual system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thorpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fize</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Marlot</surname></persName>
		</author>
		<idno type="DOI">10.1038/381520a0</idno>
		<ptr target="https://doi.org/10.1038/381520a0" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="issue">6582</biblScope>
			<biblScope unit="page" from="520" to="522" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Incidental and intentional visual memory: What memories are and are not affected by encoding tasks?</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1080/13506285.2010.486280</idno>
		<ptr target="https://doi.org/10.1080/13506285.2010.486280" />
	</analytic>
	<monogr>
		<title level="j">Visual Cognition</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1348" to="1367" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The changing landscape: High-level influences on eye movement guidance in scenes</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Castelhano</surname></persName>
		</author>
		<idno type="DOI">10.3390/vision3030033</idno>
		<ptr target="https://doi.org/10.3390/vision3030033" />
	</analytic>
	<monogr>
		<title level="j">Vision</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">33</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
