<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Self in the Mind&apos;s Eye: Revealing How We Truly See Ourselves Through Reverse Correlation</title>
				<funder ref="#_YeGs3eY">
					<orgName type="full">NOMIS Foundation</orgName>
				</funder>
				<funder ref="#_yrmYuN5">
					<orgName type="full">European Research Council</orgName>
					<orgName type="abbreviated">ERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Lara</forename><surname>Maister</surname></persName>
							<email>l.maister@bangor.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">Bangor University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sophie</forename><surname>De Beukelaer</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">The Warburg Institute</orgName>
								<orgName type="department" key="dep2">School of Advanced Study</orgName>
								<orgName type="institution">University of London</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matthew</forename><forename type="middle">R</forename><surname>Longo</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Psychological Sciences</orgName>
								<orgName type="institution" key="instit1">Birkbeck</orgName>
								<orgName type="institution" key="instit2">University of London</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Manos</forename><surname>Tsakiris</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">The Warburg Institute</orgName>
								<orgName type="department" key="dep2">School of Advanced Study</orgName>
								<orgName type="institution">University of London</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution" key="instit1">Royal Holloway</orgName>
								<orgName type="institution" key="instit2">University of London</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">Department of Behavioural and Cognitive Sciences</orgName>
								<orgName type="department" key="dep2">Faculty of Humanities</orgName>
								<orgName type="department" key="dep3">Education and Social Sciences</orgName>
								<orgName type="institution">University of Luxembourg</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">Bangor University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The Self in the Mind&apos;s Eye: Revealing How We Truly See Ourselves Through Reverse Correlation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">152436FBFBC3AAF1101F8307470ADF8A</idno>
					<idno type="DOI">10.1177/09567976211018618</idno>
					<note type="submission">Received 7/8/20; Revision accepted 4/23/21</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-06-03T13:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>self-representation</term>
					<term>body</term>
					<term>appearance</term>
					<term>reverse correlation</term>
					<term>personality</term>
					<term>self-face</term>
					<term>open data</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>How we represent and experience our self is a longstanding topic of intense interest for the psychological sciences and a recurring theme in the history of culture, demonstrating humanity's fascination with depicting selfhood. The creation of self-portraits has long been understood to be not only a representation of the actual physical appearance of the artist but also an exploration of the artist's identity, emotions, and beliefs <ref type="bibr" target="#b19">(Hall, 2014)</ref>. This dual nature of self-representation maps onto a longstanding distinction between physical and psychological self-representations <ref type="bibr" target="#b21">(Hu et al., 2016;</ref><ref type="bibr" target="#b31">Northoff et al., 2006)</ref>. The physical self contains sensory information pertaining to both the representation and perception of the body <ref type="bibr" target="#b5">(Carruthers, 2008)</ref> and is distinct from the psychological self, which contains semantic, propositional, and affective information such as self-knowledge, beliefs, and attitudes <ref type="bibr" target="#b21">(Hu et al., 2016)</ref>.</p><p>An important yet understudied constituent of the physical self is the mental representation of our body's perceptual appearance <ref type="bibr" target="#b32">(Pitron et al., 2018)</ref>, including our size, shape, and facial characteristics <ref type="bibr" target="#b5">(Carruthers, 2008)</ref>. These are likely to be stored and retrieved in a pictorial, depictive format <ref type="bibr" target="#b7">(Chang et al., 2017)</ref>, essentially a mental picture of the self. How we picture ourselves in our mind's eye has fundamental socioeconomical and clinical implications. Our perception of our own physical qualities is tightly related to our self-esteem <ref type="bibr" target="#b17">(Feingold, 1992)</ref> and also affects a spectrum of social behaviors ranging from choice of romantic partners <ref type="bibr" target="#b16">(Feingold, 1988)</ref> to use of appearance-modification 1018618P SSXXX10.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>practices such as plastic surgery <ref type="bibr" target="#b10">(Crerand et al., 2006)</ref>. Holding distorted self-representations can be distressing and is linked to serious clinical disorders, such as body dysmorphia and anorexia <ref type="bibr" target="#b22">(Kaplan et al., 2013)</ref>.</p><p>The theory that our mental representation of our physical appearance may give us clues into the more psychological aspects of the self is not a new one (e.g., see <ref type="bibr" target="#b3">Blanke, 2007)</ref>. Although this question has not yet been directly empirically tested with regard to the self, evidence suggests that we spontaneously use the physical appearance of others to make physiognomic inferences regarding their psychological attributes, such as personality traits, and social-group membership <ref type="bibr" target="#b40">(Todorov et al., 2015)</ref>. Therefore, according to external observers, the body's physical appearance reflects not merely the physical but also the psychological attributes of an individual. Here, we investigated whether and how the representation of the self's physical appearance is related to the psychological self in a similar way.</p><p>In a unique approach to this problem, we developed a novel implementation of a reverse-correlation task <ref type="bibr" target="#b26">(Mangini &amp; Biederman, 2004)</ref>, which allowed us to visually represent the rich mental representation of one's physical appearance (referred to hereafter as a "self-portrait") and assess its accuracy and underlying mechanisms (cf. <ref type="bibr" target="#b30">Moon et al., 2020)</ref>. Reverse correlation has already provided a revealing window into internal mental representations of other people's faces <ref type="bibr" target="#b13">(Dotsch &amp; Todorov, 2012)</ref>, other people's body shapes <ref type="bibr" target="#b25">(Lick et al., 2013)</ref>, and most recently, one's own face <ref type="bibr" target="#b30">(Moon et al., 2020)</ref>. A strength of this technique is that it provides a depictive representation of the physical self that matches the native format in which the representation is likely to be stored and retrieved <ref type="bibr" target="#b23">(Kosslyn, 2005)</ref>. It also enabled us to measure the representation with a qualitatively different level of fidelity than previous methods have achieved-a level that preserves holistic perceptual information and may support direct identity recognition. Finally, it is primarily unconstrained and data driven and therefore provides an unbiased reflection of the physical self in the mind's eye. This allowed us to avoid a key limitation of traditional self-recognition paradigms <ref type="bibr" target="#b15">(Epley &amp; Whitchurch, 2008;</ref><ref type="bibr" target="#b41">Verosky &amp; Todorov, 2010)</ref> in which the use of true, or only mildly distorted, images of the participant's real face as stimuli may unintentionally correct participants' stored mental self-face representations during measurement to be closer to reality. This limitation is also characteristic of studies exploring traditional self-portraiture (e.g., <ref type="bibr" target="#b3">Blanke, 2007)</ref>; not only are these studies restricted to artist populations and confounded by artistic skill and style, but also the majority of artists create self-portraits from a physical reference, for example, from a photograph or while viewing themselves in a mirror, again preventing the direct assessment of an internal stored representation.</p><p>We therefore aimed to elucidate whether and how physical self-representations of one's face (Experiment 1) and one's body (Experiment 2) interact with more psychological self-representations, such as beliefs and attitudes toward ourselves, by directly measuring the accuracy of representations of our appearance and, furthermore, to qualitatively and quantitatively assess the nature of systematic distortions. By comparing these internal representations with participants' real facial and body characteristics, we were able to objectively measure the accuracy of their mental self-portraits. We predicted that these physical self-representations would contain accurate identity information because of the high familiarity and frequent exposure to one's own face and body as well as the widely reported enhancements in visual memory for self-related stimuli <ref type="bibr" target="#b38">(Sui &amp; Humphreys, 2015)</ref>. However, we also expected that they would contain some incorrect information reflecting biases or error because of the reconstructive nature of visual memory <ref type="bibr" target="#b23">(Kosslyn, 2005)</ref>. Crucially, we predicted that individual patterns of error in the physical self-representation would be significantly related to psychological aspects of the self, such as beliefs about one's personality traits or attitudes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statement of Relevance</head><p>Do we really know what we look like? Given the number and sophistication of procedures for digital or physical manipulation of our appearance and the increasing prevalence of body-image-related disorders, the study of physical self-representation appears more relevant than ever. Yet the way in which we picture ourselves in our mind's eye remains poorly understood. Here, we succeeded in creating a viewable visual image of individuals' mental "self-portraits" of their faces and bodies in an unbiased, data-driven way. We found that individual differences in the accuracy of these portraits were linked to social self-esteem. Furthermore, we reveal how individuals imprint their psychological traits on these internal images, leading to biased and exaggerated mental selfimages to match their beliefs about themselves. Our findings show the close interaction between different aspects of self-representation and raise intriguing possibilities for understanding bodyimage disorders and our cultural practices of portraying the self.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Design. In the primary phase, we used a reverse-correlation task to obtain a self-portrait from each participant. We also obtained their self-reported ratings of various psychological aspects of self-representation (their beliefs about their own personality traits and their state selfesteem). In the secondary phase of data collection, we asked a new sample of independent participants to rate the self-portraits and photographs of the participants' real faces on the same personality traits.</p><p>Participants. For the primary data collection, 77 White adult university students (34 male; age: M = 24.3 years, SD = 3.9) were recruited through volunteer and opportunity sampling. Ethnicity was not specifically selected for, but because of the analysis of facial appearance in this experiment, homogeneous samples were required. At the end of the recruitment phase, there was not a sufficient number of participants of any other single ethnic origin to create a full sample. This sample size, reflecting the number of participants we successfully managed to recruit across a fixed-duration recruitment period of 2 months, provided high power (&gt; 99.9%, 95% confidence interval [CI] = [99.6, 100.0]) to detect an estimated medium-size effect for the fixed effect of self-reported personality traits in the linear mixed-effects model. This test was chosen for the power analysis because it directly assessed the central hypothesis, namely, that beliefs about oneself (in this case, beliefs about one's personality traits) would be related to corresponding visual features of the self-portrait. Power calculations were based on Monte Carlo simulations using the simr package (Version 1.0.5; <ref type="bibr" target="#b18">Green &amp; MacLeod, 2016)</ref> in the R programming environment. Participants gave written informed consent, and the experiment was approved by the ethics committee of Bangor University's School of Psychology. Participants attended a laboratory-based testing session; they first completed the reverse-correlation task, then completed personality and self-rating measures, and finally had a passport-style photograph taken of their face. For the secondary data-collection phase, 112 participants (35 male; age: M = 34.8 years, SD = 11.0) were recruited online using the participant recruitment platform Prolific (<ref type="url" target="https://www.prolific.co/">https://www.prolific.co/</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Measures.</head><p>Reverse-correlation task. For the reverse-correlation task <ref type="bibr" target="#b13">(Dotsch &amp; Todorov, 2012)</ref>, stimuli were generated using the rcicr package <ref type="bibr">(Version 0.3.4.1;</ref><ref type="bibr" target="#b12">Dotsch, 2016)</ref> in R; rcicr randomly generates patterns of sinusoidal noise superimposed over a "base face," resulting in a differentlooking face with each random noise pattern. The base face was an average composite image, either male or female depending on the gender of the participant, obtained from an existing database <ref type="bibr" target="#b11">(DeBruine &amp; Jones, 2017)</ref>. Five hundred random noise patterns, and their corresponding inverted patterns, were generated, creating 500 perceptually opposing pairs of facial images. Each stimulus pair was presented side by side to participants on a computer monitor, one pair per trial (see Fig. <ref type="figure">1</ref>; for details, see the supplementary material at <ref type="url" target="https://osf.io/sh8qg/">https://osf  .io/sh8qg/</ref>). Images resulting from each participant's performance on the reverse-correlation task were generated with the rcicr package. For each participant, all selected face images were averaged to produce a final image, which provided a visual representation of the perceptual information used to make a "self" judgment. The videos on this project's OSF page (<ref type="url" target="https://osf.io/9jrpu/">https://osf.io/9jrpu/</ref>) show the progressive creation of the self-portrait across 500 trials for two example participants.</p><p>Questionnaires. A small battery of questionnaires was used to assess self-rated personality traits, self-esteem, and facial attributes. To assess personality traits, we used a short 10-item form of the widely employed Big Five Inventory <ref type="bibr" target="#b34">(Rammstedt &amp; John, 2007)</ref>, providing a subscore for each of the five personality traits; the higher the score, the more strongly participants believed they held that specific personality trait (in the case of the selfratings) or the more strongly the external raters perceived that trait in a face's features (in the case of the external "other" ratings of the real faces and self-portraits). To assess self-esteem, we used the 20-item State Self-Esteem Scale <ref type="bibr" target="#b20">(Heatherton &amp; Polivy, 1991)</ref>. It produces three correlated factors: performance self-esteem, social self-esteem, and appearance self-esteem.</p><p>Photograph. At the end of the session, we took a passport-style facial photograph of each participant with a neutral facial expression, direct gaze, and frontal positioning. The faces were subsequently cropped around the hairline to remove extraneous features. For further details of postprocessing, see <ref type="url" target="https://osf.io/sh8qg/">https://osf.io/sh8qg/</ref>.</p><p>Secondary data collection. Ratings from a third-person perspective were obtained for each participant's real face and their self-portraits. Each rater saw two images from each of a subgroup of 18 to 20 participants (M = 19.3, SD = 0.83) to reduce rater workload and fatigue. These images were randomly allocated, with the restriction that the same external raters rated both the selfportrait and the real face of the same primary participants. Each image received scores from a mean of 28.08 raters (SD = 2.00). In separate presentations, raters completed the 10-item Big Five Inventory for each image. This measure was presented in the same format as was used for the primary participants, but instead of items beginning with the words "I see myself as someone who . . . ," raters saw the words "This person looks like they . . ." Faces and questions were presented in a fully randomized order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We answered four central research questions. First, does the self-portrait look like the participant? To test this question, we compared each participant's real face with their self-portrait using similarity scores and classification accuracy from both a face-recognition algorithm and human raters. Second, can external observers reliably infer personality traits from self-portraits? Interrater reliability scores were calculated for personality traits rated by external raters for both the self-portraits and real face photographs. Third, are self-portraits influenced by the psychological self? To test this, we analyzed the relationship between perceived personality features of the self-portraits and self-reported personality traits while controlling for personality features present in the participants' real faces. Fourth, which individual traits might be related to differences between participants in self-portrait accuracy? We assessed the relationship between each participant's self-similarity score and their self-reported personality traits and self-esteem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Does the self-portrait look like the participant?</head><p>Accuracy of each participant's resulting self-portrait was assessed objectively using a face-recognition algorithm (OpenFace; Version 2.0; <ref type="bibr" target="#b1">Amos et al., 2016)</ref>, which provides a self-specific dissimilarity score between each individual's self-portrait and a photograph of their real In the primary phase of data collection, passport-style photos were taken of each participant's face (a) and then cropped around the hairline to remove extraneous features. The participant then completed a reverse-correlation task (b), in which they chose between pairs of randomly generated faces to create a "self-portrait" face that they felt looked like their own. Afterward, they filled out questionnaires (c) measuring their personality traits (BFI-10) and state self-esteem (SSES). In the second phase of data collection, 112 independent raters were shown the participant's real face and self-portrait face (d), and they used the BFI-10 to rate how strongly they perceived each personality trait in both of the faces.</p><p>face (for further details, see <ref type="url" target="https://osf.io/sh8qg/">https://osf.io/sh8qg/</ref>). We also performed cross-individual comparisons between each participant's self-portrait and all the other participants' real faces in the sample to produce non-self-dissimilarity scores. The self-dissimilarity scores were significantly lower, at the group level, than cross-individual non-self-dissimilarity scores (self: M = 1.43, SD = 0.35; non-self: M = 1.77; SD = 0.16, 95% CI for the mean difference = [-0.41, -0.26]), paired-samples t(76) = -8.69, p &lt; .001, Cohen's d = 0.99. This confirmed that participants' self-portraits contained self-identifying facial information.</p><p>To assess to what extent interindividual differences in real facial structure could explain the interindividual differences in facial features of the portraits across our sample, we constructed two representationaldissimilarity matrices (RDMs) by calculating all pairwise dissimilarity scores between (a) each participant's selfportrait with every other participant's self-portrait and (b) each participant's real face with every other participant's real face. These were created from same-gender comparisons only (N = 2,928 comparisons) to remove the potential confounding effect of same versus different genders on dissimilarity scores. Using a linear regression analysis, we found that the real-face RDM significantly predicted the portrait RDM, β = 0.06, 95% CI = [0.03, 0.09], t(2926) = 3.63, p &lt; .001, demonstrating that the physical similarity structure of the real faces of the sample was represented in the self-portraits. Although highly significant, this effect was small (r 2 = .004). This indicates that although self-portraits contained accurate self-specific facial information, substantial variance was not accounted for by individuals' real facial features.</p><p>To validate the findings from the face-recognition algorithm, we tested whether human raters could correctly identify facial identity from the self-portraits in an independent sample of 40 individuals who completed a twoalternative forced-choice classification task (for further details, see Experiment 1b at <ref type="url" target="https://osf.io/sh8qg/">https://osf.io/sh8qg/</ref>). A one-sample t test confirmed that the mean accuracy score across raters for each portrait (M = .57, SD = .16, 95% CI = [.53, .61]) was significantly higher than chance level (.50), t(76) = 3.93, p &lt; .001, Cohen's d = 0.45. For comparison, classification accuracy was also derived for the OpenFace algorithm using a simulated experiment identical to that which the human participants completed. Accuracy was numerically higher than the human accuracy scores (M = .62, SD = .31, 95% CI = [.56, .69]) and again significantly higher than chance performance, t(76) = 3.59, p &lt; .001, Cohen's d = 0.41. A bootstrapped hypothesis test across 10,000 samples showed that the difference in accuracy between the algorithm and the human participants was not significant (estimated p = .076).</p><p>Can external observers reliably infer personality traits from self-portraits? Interrater reliability was calculated using average intraclass correlation coefficients (ICCs) on the ratings of each personality trait obtained from the secondary data-collection phase. Consistency in ratings was assessed across each group of external raters. For each personality-trait score averaged across external raters, the ICC ranged from fair to excellent <ref type="bibr" target="#b8">(Cicchetti, 1994)</ref>-for the self-portraits (averaged across personality traits): M = .68, SD = .11; for the real faces: M = .76, SD = .07 (for details, see Table <ref type="table">S1</ref> in the supplementary material at <ref type="url" target="https://osf.io/sh8qg/">https://osf.io/sh8qg/</ref>). This confirmed that the personality scores obtained by averaging across external raters were sufficiently reliable for further analysis and that the self-portraits contained visual information that reliably supported personality judgments. Thus, self-portraits contain self-specifying information related to individuals' real facial characteristics, but it is also clear that there is substantial variance in self-portraits' facial features that deviated from individuals' real faces.</p><p>Are self-portraits influenced by the psychological self? To test whether one source of this variance could be associated with individuals' beliefs about their personality traits, we used a linear mixed-effects analysis <ref type="bibr" target="#b2">(Baayen et al., 2008)</ref> to assess whether the personality traits evident in self-portraits (as measured by the external personality ratings) were predicted by participants' self-reported personality traits (as measured using the Big Five Inventory; <ref type="bibr" target="#b34">Rammstedt &amp; John, 2007)</ref>. Critically, this analysis controlled for the external ratings of the personality traits inferred from participants' real faces. This was necessary to allow us to disentangle a true effect of self-reported personality traits on self-portrait ratings from a situation in which participants were merely producing accurate, unbiased self-portraits but possessed real facial features that matched their self-reported personalities. For full details of this analysis and conceptual replication, see <ref type="url" target="https://osf.io/sh8qg/">https://osf.io/sh8qg/</ref>.</p><p>We first derived an optimal null-hypothesis model containing explanatory and control variables predicting external ratings of self-portraits, including external personality ratings of the real faces (Akaike information criterion [AIC] = 194.4). Using a systematic modelcomparison procedure, we demonstrated that an alternative-hypothesis model that additionally included self-ratings of the five personality traits explained significantly more variance in external personality ratings derived from participants' self-portraits than the nullhypothesis model did (null hypothesis: AIC = 194.4, alternative hypothesis: AIC = 192.17), χ 2 (1) = 4.23, p = .040. In this winning model, the variable indexing participants' self-reported personality traits had a positive parameter estimate, b = 0.03 (SE = 0.02), t(359.6) = 2.04, F(1, 359.6) = 4.17, p = .042 (see Fig. <ref type="figure" target="#fig_1">2a</ref>), indicating that the higher participants rated themselves on a certain personality trait, the more facial features associated with that trait were present in their self-portrait, even when the model controlled for the actual presence of those features in participants' real faces (see Table <ref type="table">S2</ref> in the supplementary material at <ref type="url" target="https://osf.io/sh8qg/">https://osf.io/sh8qg/</ref>). A control model, in which self-ratings on the five personality traits were randomly shuffled within each participant, performed poorly (AIC = 196.4, χ 2 &lt; .001, p &gt; .999), and the parameter estimate of the randomly shuffled variable assessing participants' self-reported personality traits was nonsignificant, β ≤ -0.001, t(358.9) = -0.06, p = .95. This suggests that individual personality traits were indeed meaningfully linked with specific configurations of facial features in the self-portraits.</p><p>Finally, we investigated individual differences in overall portrait accuracy in relation to self-rated character traits by investigating whether the accuracy of selfportraits relates to self-reported personality traits or selfesteem. An exploratory analysis was run using a hierarchical multiple linear regression on the self-dissimilarity scores, as calculated from the face-recognition algorithm. An important consideration at this point was to ensure that we were investigating the accuracy of only the selfspecific information contained in the self-portraits. Each self-portrait contained generic facial features common to many faces, as well as self-specific content. By controlling for the similarity between each participant's selfportrait and all the other real faces in the sample, we adjusted the self-dissimilarity scores of the self-portraits to reflect accuracy of self-specific content, ensuring that the averageness of the self-portrait did not lead to biases in the self-dissimilarity scores.</p><p>Therefore, at the first step, the mean cross-individual dissimilarity scores between each participant's selfportrait and all other same-gender real faces were entered, β = 0.50, 95% CI = [0.07, 0.93], t(75) = 2.30, p = .024, to ensure that we were analyzing self-specific accuracy as our dependent variable. At the second step, individual-difference variables of interest were added (the five personality self-ratings, to test whether selfbeliefs regarding personality were associated with selfface representation, and the three self-esteem subscales, to assess whether more attitudinal aspects of selfconcept were associated with self-representation). The winning model from the stepwise procedure included social self-esteem as a significant negative predictor of self-dissimilarity, β = -0.13, 95% CI = [-0.23, -0.04], t(74) = 2.68, p = .009, which survived Bonferroni correction for familywise multiple comparisons. The higher the participant's self-esteem with regard to social interactions, the more accurate (i.e., true to life) their self-portraits were (see Fig. <ref type="figure" target="#fig_1">2b</ref>). No other predictor variables were included in the winning model. However, this result could have been influenced by the attractiveness of participants' real faces. If participants tend to select the more attractive faces when performing the reverse-correlation task, by default those with more attractive real faces will generate selfportraits that gain a lower self-dissimilarity score than those who have less attractive real faces. Given that more attractive individuals may have higher self-esteem, this could explain the reported relationship between self-esteem and self-portrait accuracy. To test this alternative explanation, we conducted two further analyses. First, a correlational analysis between social self-esteem and real-face attractiveness revealed that these two variables were not significantly correlated, r(75) = .178, p = .121. Second, when we controlled for real facial attractiveness in the first step of the original hierarchical linear regression, the significance of social self-esteem as a predictor of self-portrait accuracy remained unchanged, β = -0.13, 95% CI = [-0.23, -0.03], t(73) = 2.55, p = .013. Therefore, it is unlikely that the existing findings can be explained by a confounding effect of real facial attractiveness. Another alternative explanation involves the averageness of participants' real faces. For participants with highly average real facial features, the reverse-correlation task could have generated portraits that were highly similar to their real face by chance, giving artificially low self-dissimilarity scores with the self-portrait. This could lead to a potential confound because facial averageness may be directly linked with self-rated character traits such as self-esteem. To ensure that this was not the case, we retested the key result while controlling for real-face averageness, as calculated by the mean cross-individual dissimilarity scores between the participants' real faces and all other same-gender real faces in the sample. This confirmed that the relationship between social selfesteem and self-dissimilarity remained significant even when we additionally controlled for real-face averageness, β = -0.14, 95% CI = [-0.23, -0.04], t(73) = 2.75, p = .007. Real-face averageness was not significantly related to self-dissimilarity in this analysis, β = -0.38, 95% CI = [-0.84, 0.08], t(74) = -1.63, p = .107. Furthermore, a separate analysis demonstrated that real-face averageness was not significantly related to social selfesteem, β = -0.16, 95% CI = [-1.20, 0.89], t(75) = -0.30, p = .763.</p><p>Taken together, the results show that at the group level, self-portraits were accurate enough to support recognition. Importantly, the self-portraits also contained visual clues to each person's self-reported personality traits, which were reliably detected by external observers. Finally, the higher the participants' self-esteem with regard to social interactions, the more accurate their self-portraits were.</p><p>Experiment 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Design. We used the same reverse-correlation procedure as in Experiment 1 but replaced the face stimuli with body silhouettes (similar to the procedure of <ref type="bibr" target="#b25">Lick et al., 2013)</ref> and a self-reported body self-esteem questionnaire, which reflected emotional attitudes toward the body and therefore provided us with an estimate of a relevant aspect of the psychological self. One further addition was made to Experiment 2: Not only did we obtain a body self-portrait from the reverse-correlation procedure, but also we repeated the task to generate each participant's perceptual representation of a body shape that was typical for an individual of the participant's age and gender. This allowed us to investigate whether affective representations of the self were related solely to perceptions of one's own appearance or whether they were related also to the way one's personal norms were perceived as well as whether these effects were similar in terms of direction and magnitude.</p><p>Participants. Forty university students (age: M = 23.9 years, SD = 4.1, range = 18-35 years) were recruited through volunteer and opportunity sampling. They were from a mixture of ethnic origins. Recruitment was restricted to young women because of the high incidence of body-image concerns in this demographic <ref type="bibr" target="#b39">(Tiggemann &amp; Lynch, 2001</ref>) and the differences between the stereotypical desirable and undesirable body shapes for men and women <ref type="bibr" target="#b9">(Cohn &amp; Adler, 1992)</ref>. This sample size provided adequate power (81.4%, 95% CI = [78.9, 83.8]) to detect an estimated medium-size effect (slope: β = 0.35; <ref type="bibr" target="#b0">Acock, 2014)</ref> for the fixed main effect of body self-esteem in the linear mixed-effects model. This test was chosen for the power analysis because it directly assessed the central hypothesis, namely, that attitudes toward oneself (body self-esteem, in this case) would be related to visual features of the body self-portrait. Participants completed the two reverse-correlation tasks and then the Body Esteem Scale for Adolescents and Adults <ref type="bibr" target="#b27">(Mendelson et al., 2001)</ref>. Their body dimensions were then measured, and they were debriefed and paid. One participant scored greater than 2 standard deviations from the mean when the hip size was estimated from the reverse-correlated portrait and was excluded from the final sample as an outlier. This left 39 participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Measures.</head><p>Reverse-correlation task. The reverse-correlation task closely followed that in Experiment 1 but with body silhouette images (for details and examples of the stimuli, see <ref type="url" target="https://osf.io/sh8qg/">https://osf.io/sh8qg/</ref> and Fig. <ref type="figure" target="#fig_2">3</ref>). Participants completed two reverse-correlation tasks (consisting of a self task and a typical task) using these noise-distorted body silhouettes. In the self task, participants were required to select the image that looked most similar to their own actual body shape. In each trial of the typical task, they were asked instead to select the image that looked most similar to the actual body shape of a "typical or average person of your age and gender." In total, participants completed 400 trials of the self task and 400 trials of the typical task, split across four blocks of 200 trials each in an A-B-B-A pattern, which was counterbalanced across participants.</p><p>The resulting data from each task were preprocessed separately, as in Experiment 1, to generate two images per participant: one reflecting their perceptual representation of their own body shape and one reflecting their perceptual representation of a typical body shape for someone of their age and gender. Body Esteem Scale for Adolescents and Adults. The 23-item Body Esteem Scale for Adolescents and Adults <ref type="bibr" target="#b27">(Mendelson et al., 2001)</ref> questionnaire measured participants' affective attitudes toward their bodies. Each item loaded onto one of three subscales: appearance (measuring general feelings about one's appearance), weight (measuring satisfaction with one's body weight), and attribution (evaluations attributed to other people about one's body and appearance). Higher scores reflect more positive body attitudes.</p><p>Real body measurement. Participants were weighed on a digital scale, and their height was measured. Several key body-part measurements were also takenspecifically, the waist width and the hip width. Because the study focused on two-dimensional visual representations of the body viewed from the front (as participants would see themselves in the mirror), we measured width from frontal view using calipers, than circumference, although it is reasonable to suppose that these two measurements are closely correlated. Body measurements were taken at the end of the testing session after all other tasks had been completed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We first asked whether the body portrait looks like the participant. Because there are many body dimensions that could have been quantified, we first defined a region of interest around the hip area to focus our analysis (an area particularly associated with bodyimage dissatisfaction in young women; <ref type="bibr" target="#b29">Monteath &amp; McCabe, 1997)</ref>. A psychometric curve-fitting procedure allowed us to ascertain hip width for each participant's reverse-correlated body-shape portraits (see Fig. <ref type="figure" target="#fig_2">3d</ref>). The point of subjective equality (PSE; reflecting the position on the horizontal axis where the average luminance of the pixels was at the midpoint of the scale) was ascertained for each curve as an estimate of the edge location of each hip. The PSE value for the left hip was inverted so that lower values indicated a narrower hip for both left and right hips. The two PSE values were then averaged to produce an estimate of perceived hip width for each classification image.</p><p>Simple correlations were first calculated between self-perceived hip width from the self-portraits and the participants' real hip measurements, which revealed no significant relationship, r(37) = .05, p = .759. Neither were participants' real hip widths related to the difference between the self-portrait and typical portrait (selfportrait -typical-portrait hip width), r(37) = .16, p = .341, suggesting that unlike the facial self-portraits, the body-shape portraits had negligible direct relationships with individuals' actual body shapes (for a Bayesian analysis supporting no relationship, see <ref type="url" target="https://osf.io/sh8qg/">https://osf.io/  sh8qg/</ref>).</p><p>We next asked whether body portraits are influenced by attitudes toward the self. Linear mixed-effects models were employed in which the dependent variable was the hip width of the self and typical body images generated by the reverse-correlation procedure. We first derived a null-hypothesis model (AIC = 249.4), containing three predictor terms: (a) participants' real hip measurements, (b) whether they were judging their own or a typical body (image type), and (c) their interaction. Although these terms were not significant predictors of hip width of the self and typical body images, they were included to provide the strongest test for our hypothesis.</p><p>An alternative-hypothesis model that included an interaction between image type and self-esteem significantly improved model fit, AIC = 236.9, χ 2 = 16.54, p = .0003. In the most parsimonious winning model, including self-esteem, image type, and their interaction, selfesteem significantly predicted hip width of the self and typical body images, positively for the typical body (β = 0.27, SE = 0.08), t(71.0) = 3.59, p = .0006, but negatively for the self body (β = -0.14, SE = 0.08), t(71.0) = -1.91, p = .060. The interaction term was strongly significant (β = 0.41, SE = 0.09), t(37.0) = 4.37, p &lt; .0001 (see Fig. <ref type="figure" target="#fig_3">4</ref>; see also Table <ref type="table">S4</ref> in the supplementary material at <ref type="url" target="https://osf.io/sh8qg/">https://osf.io/sh8qg/</ref>), suggesting that participants with negative attitudes toward their own bodies produced self-portraits with larger hips and produced typical portraits with slimmer hips, compared with participants who had positive attitudes (for full details, see <ref type="url" target="https://osf.io/sh8qg/">https://osf.io/sh8qg/</ref>).</p><p>Experiment 2 shows that attitudes toward one's own body (i.e., body self-esteem) did indeed shape the physical-body self-representation. Individuals who were unhappy with their body's appearance visually represented their hips as wider, even when models controlled for real body shape. In addition, when testing for the influence of body satisfaction on participants' visual representations of what typical bodies look like, we found the opposite relationship; the more unhappy an individual is with their own body, the slimmer they visualize a typical body in their mind's eye.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>We investigated how we see ourselves in our mind's eye by creating visual images of individual participants' mental representations of both their faces and their body shapes in a data-driven, unconstrained way, minimizing participant biases and experimenter assumptions. This technique produced rich, holistic, and multidimensional visual representations of the face and body, which we found not only carried accurate information about physical appearance but also provided novel insights into the way in which participants' thoughts and feelings about themselves can color their self-image.</p><p>We observed clear interactions between the physical and psychological aspects of the self: Self-portraits of both the face and the body were significantly related to higher level, more abstract self-beliefs and attitudes. In Experiment 1, representations of one's facial appearance were influenced by beliefs regarding one's personality traits; for example, if a participant believed they were highly extraverted, they also held an internal representation of their face that had exaggerated stereotypically extraverted facial features compared with their true appearance. In Experiment 2, we demonstrated similar results for perceptual representations of body shape: Participants with negative attitudes toward their bodies also held visual representations of their body's physical appearance as wider and typical peers as slimmer, compared with participants who had more positive attitudes.</p><p>Until now, there has been little investigation of the interaction between physical and psychological selves, and most of the work that has been done has focused on the bottom-up effects of multisensory and sensorimotor contingencies on higher-level psychological self-representations <ref type="bibr" target="#b33">(Preston &amp; Ehrsson, 2014)</ref>. Our work uniquely focuses on self-representations stored in long-term memory to point to a close, interactive relationship between physical and psychological representations of the self, consistent with an interactive hierarchical model of self-representation (as proposed by <ref type="bibr" target="#b37">Sugiura, 2013)</ref>. Higher level self-beliefs and attitudes may influence the perceptual quality of the self-portraits (via a top-down modulation during the reconstruction of these images; see <ref type="bibr" target="#b23">Kosslyn, 2005)</ref>, but conversely, the perceptual features of the physical self-representation might also lead to congruent inferences about one's self-beliefs and attitudes. Indeed, evidence from studies on social perception supports a bidirectional causal relationship for our representations of others <ref type="bibr" target="#b14">(Dotsch et al., 2008;</ref><ref type="bibr" target="#b40">Todorov et al., 2015)</ref>; therefore, a similar bidirectional relationship with regard to self-representations may also be likely.</p><p>Although the results with regard to the relationship between physical and psychological self-representations were similar for faces and bodies, there were interesting differences. Participants' representations of their facial  <ref type="bibr">39)</ref> showing the relationship between perceived hip width and body self-esteem, separately for the self and a typical other. Perceived hip width is derived from the images resulting from the reverse-correlation paradigm, giving the horizontal pixel position of hip boundaries. Body self-esteem score reflects the total score achieved on the Body Esteem Scale for Adolescents and Adults; higher scores reflect higher self-esteem. Individual data points reflect predicted values from the fitted model. The slopes depict the best-fitting regressions, and the shaded regions represent 95% pointwise confidence intervals drawn around the estimated effect.</p><p>appearance were clearly related to their real facial characteristics, showing a significant level of self-specificity. Classification studies, both using human participants and simulated using a face-recognition algorithm, confirmed that identity could be correctly classified from the self-portraits at well-above-chance levels. In contrast, participants' perceptual representations of their bodies were less related to real body characteristics (e.g., actual body size) and were more strongly influenced by affective attitudes toward the self. This is consistent with previous evidence using single-dimension measures of body parts <ref type="bibr" target="#b3">(Ben-Tovim et al., 1990</ref>) and brings into question the wide literature attempting to characterize perceptual body representations in eating disorders in terms of overestimation or underestimation biases (for a review, see <ref type="bibr" target="#b28">Mölbert et al., 2017)</ref>. However, it will be important to replicate the findings of both experiments using larger samples of more diverse participants before drawing conclusions. The generalizability of the present study may be limited. In Experiment 1, only young Caucasian adults were tested, and therefore it is necessary to follow up with studies using a wider range of ethnicities. Furthermore, in Experiment 2, only young adult women were tested, and their body size may have been relatively homogeneous compared with the general population. Interestingly, individual differences in objective accuracy of the facial self-portraits were correlated with self-esteem, specifically with regard to social confidence. The higher an individual's social self-esteem, the more objectively accurate their self-portrait was. This raises interesting considerations regarding the causal role of social interaction in the development and maintenance of self-representations. Social interactions are an important source of information about our appearance, via feedback on our appearance and via social comparisons <ref type="bibr" target="#b6">(Cash et al., 1983)</ref>. Therefore, individuals with higher social self-esteem may have engaged in more frequent, close social interactions and thus received more social input about their appearance, leading to more accurate self-perception. Alternatively, individuals with more accurate perception of their appearance may also have smoother, more reciprocal, and more predictable social relationships, leading to greater social confidence. For example, having an accurate perception of one's own attractiveness may lead to more successful romantic interactions and a lower chance of being rebuffed by someone poorly matched (see Le <ref type="bibr" target="#b24">Lec et al., 2017)</ref>, leading to higher social selfesteem. Both of these potential explanations appeal to a long-term relationship between self-esteem and the development of an accurate self-face representation. However, it is important to note that in our study, we assessed state self-esteem rather than trait self-esteem. Although it is likely that state and trait self-esteem measures are highly correlated (e.g., see <ref type="bibr" target="#b20">Heatherton &amp; Polivy, 1991)</ref>, future research may explore whether this finding holds for more stable aspects of self-esteem.</p><p>Our results are consistent with the findings of a very recent study, which also used the reverse-correlation technique to create visual self-face representations <ref type="bibr" target="#b30">(Moon et al., 2020)</ref>. In this study, links were found between the valence of the self-face representations generated, as rated by external observers, and various self-reported traits. Self-esteem, explicit self-evaluation, and extraversion were found to be linked to more positive or pleasant-appearing self-portraits, and social anxiety was related to more negative or unpleasantappearing self-portraits. The authors concluded that the valence of self-face representations created in this manner was able to reflect the attitude toward self. In the present study, consistent with Moon et al.'s findings, our results also showed a significant association between self-reported psychological traits and the physical features of the self-face representation. However, our results further refine our understanding of this relationship by demonstrating that self-reported personality traits were not merely linked with the perceptual valence of self-face representations, as in Moon et al.'s study, but that individual personality traits were linked to specific facial configurations in the selfportraits that were recognizable as such by independent raters.</p><p>Our study further extends existing knowledge in several key ways. First, although <ref type="bibr" target="#b30">Moon et al. (2020)</ref> measured participants' perceptions of self-similarity with their own self-portraits, no work has yet been done to explore the actual accuracy of self-representations or to provide a well-controlled, unbiased assessment of their links to self-beliefs and attitudes. Here, we confirmed the validity of the reverse-correlation method in self-face representation research, demonstrating that the resulting images contain enough visual information to support recognition using subjective ratings from an independent sample of raters as well as objectively using simulated experiments implementing a face-recognition algorithm. Furthermore, when exploring whether these self-face representations are influenced by higher level self-processing, we controlled for real facial features, which is crucial to avoid confounds and to provide a valid, strict test of our hypothesis. Finally, we extended our investigation to consider not only face representations but also body shapes, which enriched and generalized our findings to lend support to a broader mechanism whereby beliefs and attitudes influence perceptual body representations.</p><p>In this study, we used a combination of objective, algorithm-based techniques and subjective personality ratings from human observers to analyze both the selfportraits and real photographs. It is possible that the human ratings of the real photographs may have been informed by superficial features of the faces, such as makeup, facial hair, and grooming habits, despite the participants providing the ratings being instructed to ignore such features. However, it is important to note that the effects of this potential source of information could not explain the key results reported here. Such effects would serve only to increase the correlation found between the personality ratings of participants' real faces and their self-reported personalities. Importantly, it could not alter the relationship between the personality ratings of the self-portraits and the selfreported personality ratings, which is key for our hypothesis, because superficial features such as facial hair and makeup were not represented in the reverse-correlation images. This issue further reiterates the importance of carefully controlling for participants' real facial ratings, which we ensured was done in each key analysis.</p><p>Both the approach we used to produce the selfportraits and our findings are highly relevant to our understanding of clinical disorders of body image, such as anorexia nervosa and body dysmorphia. Previous studies into these disorders have normally focused on online perception of the body or have used distorted images of the patients' own bodies as stimuli, which did not allow for unbiased measurement <ref type="bibr" target="#b35">(Smeets et al., 1999)</ref>. Our approach could be used as a unique, direct method of assessing distortions in visual memory in these patients, allowing us to reveal whether they stem from higher level self-beliefs and attitudes or even a disorder in the link between these attitudes and the physical self-representation. This approach will also allow us to compare the effects of different treatments (e.g., those targeting perceptual distortions and those targeting emotional or cognitive aspects of the disorder) as well as assess the effects of treatment across time.</p><p>In conclusion, we present a novel way to visually depict how people see themselves in their mind's eye and, in doing so, revealed visual clues to people's deeply held self-beliefs and attitudes. Our mental images of our own appearance are fundamental to our understanding of some of the most severe mental disorders that are clustered under the term of body-image disorders. In addition, at a time when our culture is powered by images at an unprecedented level, and our obsession with our own image is evidenced in our social media use <ref type="bibr" target="#b36">(Storr, 2018)</ref>, our approach and the novel insights presented here pave the way for future explorations, in a data-driven, unconstrained, and richly detailed way, of how we mentally see ourselves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transparency</head><p>Action Editor: Steven W. Gangestad Editor: Patricia J. Bauer</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>Fig.1. Design of Experiment 1. In the primary phase of data collection, passport-style photos were taken of each participant's face (a) and then cropped around the hairline to remove extraneous features. The participant then completed a reverse-correlation task (b), in which they chose between pairs of randomly generated faces to create a "self-portrait" face that they felt looked like their own. Afterward, they filled out questionnaires (c) measuring their personality traits (BFI-10) and state self-esteem (SSES). In the second phase of data collection, 112 independent raters were shown the participant's real face and self-portrait face (d), and they used the BFI-10 to rate how strongly they perceived each personality trait in both of the faces.</figDesc><graphic coords="4,122.00,368.97,69.98,62.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Key results from Experiment 1 (N = 77). Results from the linear mixed-effects models analysis (a) show the fixed effect of self-reported personality traits (as rated by participants themselves) on the intensity of the corresponding personality traits perceived in the facial features of the self-portraits (as reported by external raters). The black line indicates the populationlevel mean. The blue lines indicate the marginal effects for each individual participant, allowing for random variation of intercepts as dictated by the best-fitting linear mixed-effects model. The scatterplot (b) illustrates the relationship between individual differences in self-portrait dissimilarity (statistically controlling for the effect of non-self same-gender dissimilarity) and social self-esteem. The higher the participant's self-esteem with regard to their social interactions, the more accurate their self-portrait. The solid line shows the best-fitting regression, and the shaded region reflects the 95% confidence interval.</figDesc><graphic coords="6,332.65,99.70,194.30,183.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Design of Experiment 2. Participants completed two reverse-correlation tasks (a), in each of which they were shown pairs of randomly generated body silhouettes and indicated whether the shape was similar to their own body or a typical body. Several body measurements (b) were taken to assess the participants' real body dimensions. Participants then completed a 23-item questionnaire (c) assessing their affective attitudes toward their bodies. The illustration (d) shows the curve-fitting procedure used to estimate location of body boundaries in the classification images for self-and typical-body reverse-correlated portraits. Two hip regions of interest were selected (20 × 10 pixels, indicated by red rectangles), and a logistic function was fitted to the luminance change of the pixels in each region of interest. The point of subjective equality (PSE; reflecting the position on the horizontal axis where the average luminance of the pixels was at the midpoint of the scale) was ascertained for each curve as an estimate of the edge location of each hip, indicated by the red arrows. The PSE value for the left hip was inverted so that lower values indicated a narrower hip for both left and right hips. The two PSE values were then averaged to produce an estimate of perceived hip width for each classification image. The graphs present sample data from one participant.</figDesc><graphic coords="8,79.35,341.18,134.18,68.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Results from the linear mixed-effects models analysis of Experiment 2 (N =39)  showing the relationship between perceived hip width and body self-esteem, separately for the self and a typical other. Perceived hip width is derived from the images resulting from the reverse-correlation paradigm, giving the horizontal pixel position of hip boundaries. Body self-esteem score reflects the total score achieved on the Body Esteem Scale for Adolescents and Adults; higher scores reflect higher self-esteem. Individual data points reflect predicted values from the fitted model. The slopes depict the best-fitting regressions, and the shaded regions represent 95% pointwise confidence intervals drawn around the estimated effect.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank <rs type="person">Judita Rudokaite</rs> and <rs type="person">Samuel Maister</rs> for help with data collection and programming, respectively.</p></div>
			</div>
			<div type="funding">
<div><p>Funding <rs type="person">M. R. Longo</rs> was supported by a grant from the <rs type="funder">European Research Council</rs> (<rs type="grantNumber">ERC-2013-StG-336050</rs>) under the <rs type="programName">Seventh Framework Programme</rs>. <rs type="person">M. Tsakiris</rs> was supported by the <rs type="funder">NOMIS Foundation</rs> <rs type="grantName">Distinguished Scientist Award</rs> for the "<rs type="projectName">Body &amp; Image in Arts &amp; Science</rs>" project.</p></div>
<div><head>Open Practices</head><p>All data, analysis scripts, and supplementary material have been made publicly available via OSF and can be accessed at <ref type="url" target="https://osf.io/9jrpu">https://osf.io/9jrpu</ref>. The design and analysis plan for the experiments were not preregistered. This article has received the badge for Open Data. More information about the Open Practices badges can be found at <ref type="url" target="http://www.psychologicalscience.org/publications/badges">http://www  .psychologicalscience.org/publications/badges</ref>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_yrmYuN5">
					<idno type="grant-number">ERC-2013-StG-336050</idno>
					<orgName type="program" subtype="full">Seventh Framework Programme</orgName>
				</org>
				<org type="funded-project" xml:id="_YeGs3eY">
					<orgName type="grant-name">Distinguished Scientist Award</orgName>
					<orgName type="project" subtype="full">Body &amp; Image in Arts &amp; Science</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflicting Interests</head><p>The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A gentle introduction to Stata</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Acock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Stata Press</publisher>
		</imprint>
	</monogr>
	<note>4th ed.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">OpenFace: A general-purpose face recognition library with mobile applications</title>
		<author>
			<persName><forename type="first">B</forename><surname>Amos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ludwiczuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Satyanarayanan</surname></persName>
		</author>
		<ptr target="http://cmusatyalab.github.io/openface/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mixedeffects modeling with crossed random effects for subjects and items</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Baayen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Bates</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jml.2007.12.005</idno>
		<ptr target="https://doi.org/10.1016/j.jml.2007.12.005" />
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="390" to="412" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Body size estimates: Body image or body attitude measures?</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Ben-Tovim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Blanke</surname></persName>
		</author>
		<idno type="DOI">10.1002/1098-108X(199001)9:1&lt;57::AID-EAT2260090107&gt;3.0.CO;2-S</idno>
		<ptr target="https://doi.org/10.1002/1098-108X(199001)9:1&lt;57::AID-EAT2260090107" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Eating Disorders</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Bogousslavsky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Hennerici</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="29" />
			<date type="published" when="1990">1990. 2007</date>
		</imprint>
	</monogr>
	<note>I and me: Self-portraiture in brain damage</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><surname>Karger</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Types of body representation and the sense of embodiment</title>
		<author>
			<persName><forename type="first">G</forename><surname>Carruthers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Consciousness and Cognition</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1302" to="1316" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Contrast effects and self-evaluations of physical attractiveness</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Cash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Cash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Butters</surname></persName>
		</author>
		<idno type="DOI">10.1177/0146167283093004</idno>
		<ptr target="https://doi.org/10.1177/0146167283093004" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="351" to="358" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
	<note>Mirror, mirror, on the wall. . .?</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Memory and perception-based facial image reconstruction</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nemrodov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nestor</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-017-06585-2</idno>
		<ptr target="https://doi.org/10.1038/s41598-017-06585-2" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6499</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Guidelines, criteria, and rules of thumb for evaluating normed and standardized assessment instruments in psychology</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Cicchetti</surname></persName>
		</author>
		<idno type="DOI">10.1037/1040-3590.6.4.284</idno>
		<ptr target="https://doi.org/10.1037/1040-3590.6.4.284" />
	</analytic>
	<monogr>
		<title level="j">Psychological Assessment</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="284" to="290" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Female and male perceptions of ideal body shapes: Distorted views among Caucasian college students</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Adler</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1471-6402.1992.tb00240.x</idno>
		<ptr target="https://doi.org/10.1111/j.1471-6402.1992.tb00240.x" />
	</analytic>
	<monogr>
		<title level="j">Psychology of Women Quarterly</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="69" to="79" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Body dysmorphic disorder and cosmetic surgery</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Crerand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Sarwer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Plastic and Reconstructive Surgery</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="167" to="180" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Young adult white faces with manipulated versions</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Debruine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Jones</surname></persName>
		</author>
		<idno type="DOI">10.6084/m9.figshare.4220517.v1</idno>
		<ptr target="https://doi.org/10.6084/m9.figshare.4220517.v1" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Dotsch</surname></persName>
		</author>
		<ptr target="https://github.com/rdotsch/rcicr" />
		<title level="m">rcicr: Reverse-correlation image-classification toolbox</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reverse correlating social face perception</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dotsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Todorov</surname></persName>
		</author>
		<idno type="DOI">10.1177/1948550611430272</idno>
		<ptr target="https://doi.org/10.1177/1948550611430272" />
	</analytic>
	<monogr>
		<title level="j">Social Psychological and Personality Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="562" to="571" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Ethnic out-group faces are biased in the prejudiced mind</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dotsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H J</forename><surname>Wigboldus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Langner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Knippenberg</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9280.2008.02186.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-9280.2008.02186.x" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="978" to="980" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mirror, mirror on the wall: Enhancement in self-recognition</title>
		<author>
			<persName><forename type="first">N</forename><surname>Epley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Whitchurch</surname></persName>
		</author>
		<idno type="DOI">10.1177/0146167208318601</idno>
		<ptr target="https://doi.org/10.1177/0146167208318601" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1159" to="1170" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Matching for attractiveness in romantic partners and same-sex friends</title>
		<author>
			<persName><forename type="first">A</forename><surname>Feingold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="226" to="235" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Good-looking people are not what we think: Conceptualization and measurement of attractiveness</title>
		<author>
			<persName><forename type="first">A</forename><surname>Feingold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="304" to="341" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">SIMR: An R package for power analysis of generalized linear mixed models by simulation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Macleod</surname></persName>
		</author>
		<idno type="DOI">10.1111/2041-210X.12504</idno>
		<ptr target="https://doi.org/10.1111/2041-210X.12504" />
	</analytic>
	<monogr>
		<title level="j">Methods in Ecology and Evolution</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="493" to="498" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The self-portrait: A cultural history</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Thames &amp; Hudson</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Development and validation of a scale for measuring state self-esteem</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Heatherton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Polivy</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.60.6.895</idno>
		<ptr target="https://doi.org/10.1037/0022-3514.60.6.895" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="895" to="910" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Distinct and common aspects of physical and psychological self-representation in the brain: A meta-analysis of self-bias in facial and self-referential judgements</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sui</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neubiorev.2015.12.003</idno>
		<ptr target="https://doi.org/10.1016/j.neubiorev.2015.12.003" />
	</analytic>
	<monogr>
		<title level="j">Neuroscience and Biobehavioral Reviews</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="197" to="207" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Own-body perception in body dysmorphic disorder</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Rossell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Enticott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Castle</surname></persName>
		</author>
		<idno type="DOI">10.1080/13546805.2012.758878</idno>
		<ptr target="https://doi.org/10.1080/13546805.2012.758878" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Neuropsychiatry</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="594" to="614" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mental images and the brain</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kosslyn</surname></persName>
		</author>
		<idno type="DOI">10.1080/02643290442000130</idno>
		<ptr target="https://doi.org/10.1080/02643290442000130" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Neuropsychology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="333" to="347" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The outof-my-league effect</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Lec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Alexopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Boulu-Reshef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fayant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-P</forename><surname>Zenasni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lubart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jacquemet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X16000534</idno>
		<ptr target="https://doi.org/10.1017/S0140525X16000534" />
	</analytic>
	<monogr>
		<title level="j">Behavioral &amp; Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Reverse-correlating mental representations of sex-typed bodies: The effect of number of trials on image quality</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Lick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Carpinella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Preciado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Spunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2013.00476</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2013.00476" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">476</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Making the ineffable explicit: Estimating representations for face classifications</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mangini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Biederman</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15516709cog2802_4</idno>
		<ptr target="https://doi.org/10.1207/s15516709cog2802_4" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">6102</biblScope>
			<biblScope unit="issue">213</biblScope>
			<biblScope unit="page" from="209" to="226" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Body-Esteem Scale for Adolescents and Adults</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Mendelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mendelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>White</surname></persName>
		</author>
		<idno type="DOI">10.1207/S15327752JPA7601_6</idno>
		<ptr target="https://doi.org/10.1207/S15327752JPA7601_6" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality Assessment</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="90" to="106" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Depictive and metric body size estimation in anorexia nervosa and bulimia nervosa: A systematic review and meta-analysis</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Mölbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Mohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brozzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Martus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-O</forename><surname>Karnath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zipfel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Giel</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cpr.2017.08.005</idno>
		<ptr target="https://doi.org/10.1016/j.cpr.2017.08.005" />
	</analytic>
	<monogr>
		<title level="j">Clinical Psychology Review</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="21" to="31" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The influence of societal factors on female body image</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Monteath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Mccabe</surname></persName>
		</author>
		<idno type="DOI">10.1080/00224549709595493</idno>
		<ptr target="https://doi.org/10.1080/00224549709595493" />
	</analytic>
	<monogr>
		<title level="j">Journal of Social Psychology</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="708" to="727" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The mirror of mind: Visualizing mental representations of self through reverse correlation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">G</forename><surname>Ko</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2020.01149</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2020.01149" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">1149</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Self-referential processing in our brain-a meta-analysis of imaging studies on the self</title>
		<author>
			<persName><forename type="first">G</forename><surname>Northoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heinzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Greck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bermpohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dobrowolny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Panksepp</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2005.12.002</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2005.12.002" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="440" to="457" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">How do the body schema and the body image interact?</title>
		<author>
			<persName><forename type="first">V</forename><surname>Pitron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alsmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De Vignemont</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.concog.2018.08.007</idno>
		<ptr target="https://doi.org/10.1016/j.concog.2018.08.007" />
	</analytic>
	<monogr>
		<title level="j">Consciousness and Cognition</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="352" to="358" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Illusory changes in body size modulate body satisfaction in a way that is related to non-clinical eating disorder psychopathology</title>
		<author>
			<persName><forename type="first">C</forename><surname>Preston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Ehrsson</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0085773</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0085773" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">85773</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Measuring personality in one minute or less: A 10-item short version of the Big Five Inventory in English and German</title>
		<author>
			<persName><forename type="first">B</forename><surname>Rammstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">P</forename><surname>John</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jrp.2006.02.001</idno>
		<ptr target="https://doi.org/10.1016/j.jrp.2006.02.001" />
	</analytic>
	<monogr>
		<title level="j">Journal of Research in Personality</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="203" to="212" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Body size perception in anorexia nervosa: A signal detection approach</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A M</forename><surname>Smeets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ingleby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Hoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E M</forename><surname>Panhuysen</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0022-3999(99)00005-7</idno>
		<ptr target="https://doi.org/10.1016/S0022-3999(99)00005-7" />
	</analytic>
	<monogr>
		<title level="j">Journal of Psychosomatic Research</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="465" to="477" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Storr</surname></persName>
		</author>
		<title level="m">Selfie: How we became so self-obsessed and what it&apos;s doing to us</title>
		<imprint>
			<publisher>Picador</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Associative account of self-cognition: Extended forward model and multi-layer structure</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiura</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2013.00535</idno>
		<ptr target="https://doi.org/10.3389/fnhum.2013.00535" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">535</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The integrative self: How self-reference integrates perception and memory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Humphreys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="719" to="728" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Body image across the life span in adult women: The role of self-objectification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tiggemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Lynch</surname></persName>
		</author>
		<idno type="DOI">10.1037/0012-1649.37.2.243</idno>
		<ptr target="https://doi.org/10.1037/0012-1649.37.2.243" />
	</analytic>
	<monogr>
		<title level="j">Developmental Psychology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="243" to="253" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Social attributions from faces: Determinants, consequences, accuracy, and functional significance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Todorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Olivola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dotsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mende-Siedlecki</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-psych-113011-143831</idno>
		<ptr target="https://doi.org/10.1146/annurev-psych-113011-143831" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="519" to="545" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Differential neural responses to faces physically similar to the self as a function of their valence</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Verosky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Todorov</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2009.10.017</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2009.10.017" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1690" to="1698" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
