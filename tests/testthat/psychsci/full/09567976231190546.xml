<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Changing What You Like: Modifying Contour Properties Shifts Aesthetic Valuations of Scenes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Delaram</forename><surname>Farzanfar</surname></persName>
							<email>delaram.farzanfar@mail.utoronto.ca</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">Department of Psychology</orgName>
								<orgName type="department" key="dep3">Department of Psychology</orgName>
								<orgName type="institution" key="instit1">University of Toronto</orgName>
								<orgName type="institution" key="instit2">University of Toronto</orgName>
								<orgName type="institution" key="instit3">University of Toronto</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">Department of Psychology</orgName>
								<orgName type="department" key="dep3">Department of Psychology</orgName>
								<orgName type="institution" key="instit1">University of Toronto</orgName>
								<orgName type="institution" key="instit2">University of Toronto</orgName>
								<orgName type="institution" key="instit3">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dirk</forename><forename type="middle">B</forename><surname>Walther</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">Department of Psychology</orgName>
								<orgName type="department" key="dep3">Department of Psychology</orgName>
								<orgName type="institution" key="instit1">University of Toronto</orgName>
								<orgName type="institution" key="instit2">University of Toronto</orgName>
								<orgName type="institution" key="instit3">University of Toronto</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">Department of Psychology</orgName>
								<orgName type="department" key="dep3">Department of Psychology</orgName>
								<orgName type="institution" key="instit1">University of Toronto</orgName>
								<orgName type="institution" key="instit2">University of Toronto</orgName>
								<orgName type="institution" key="instit3">University of Toronto</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Changing What You Like: Modifying Contour Properties Shifts Aesthetic Valuations of Scenes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6C6D1DDD2318D2532D938BAF993DF853</idno>
					<idno type="DOI">10.1177/09567976231190546</idno>
					<note type="submission">Received 12/1/22; Revision accepted 6/3/23</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-05-20T20:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>visual aesthetics</term>
					<term>contour properties</term>
					<term>line drawings</term>
					<term>valuation</term>
					<term>empirical aesthetics</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To what extent do aesthetic experiences arise from the human ability to perceive and extract meaning from visual features? Ordinary scenes, such as a beach sunset, can elicit a sense of beauty in most observers. Although it appears that aesthetic responses can be shared among humans, little is known about the cognitive mechanisms that underlie this phenomenon. We developed a contour model of aesthetics that assigns values to visual properties in scenes, allowing us to predict aesthetic responses in adults from around the world. Through a series of experiments, we manipulate contours to increase or decrease aesthetic value while preserving scene semantic identity. Contour manipulations directly shift subjective aesthetic judgments. This provides the first experimental evidence for a causal relationship between contour properties and aesthetic valuation. Our findings support the notion that visual regularities underlie the human capacity to derive pleasure from visual information.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Aesthetic considerations impact human behavior <ref type="bibr" target="#b13">(Chatterjee &amp; Vartanian, 2014;</ref><ref type="bibr" target="#b57">Vessel et al., 2019)</ref>. Visual information elicit a sense of aesthetic pleasure in perceivers <ref type="bibr" target="#b9">(Biederman &amp; Vessel, 2006;</ref><ref type="bibr" target="#b10">Brielmann &amp; Pelli, 2018;</ref><ref type="bibr" target="#b12">Chatterjee, 2022;</ref><ref type="bibr" target="#b43">Palmer et al., 2013)</ref>. Across different cultures, artists similarly arrange visual features and use heuristics to communicate information <ref type="bibr" target="#b11">(Cavanagh, 2005;</ref><ref type="bibr" target="#b34">Mamassian, 2008;</ref><ref type="bibr" target="#b49">Sayim &amp; Cavanagh, 2011)</ref>. Mere lines carry information about category membership <ref type="bibr" target="#b62">(Walther et al., 2011)</ref> and affect <ref type="bibr" target="#b3">(Bar &amp; Neta, 2006;</ref><ref type="bibr" target="#b17">Damiano et al., 2021)</ref>. General mechanisms of human vision help parse a complex visual scene into attentional targets with the goal of understanding the environment <ref type="bibr" target="#b60">(VÃµ et al., 2019)</ref>. This meaning-making process is facilitated by detecting visual primitives that help with evaluating the potential cost and reward for interacting with different objects and environments <ref type="bibr" target="#b3">(Bar &amp; Neta, 2006;</ref><ref type="bibr" target="#b8">Biederman, 1987;</ref><ref type="bibr" target="#b12">Chatterjee, 2022)</ref>.</p><p>What is the nature of these visual features, and what role do they play in aesthetic judgments? We investigate the contributions of contour properties and their spatial relations in aesthetic judgments of natural scenes. It is possible to detect to structural regularities in complex visual scenes using biologically-inspired computer vision techniques <ref type="bibr" target="#b47">(Rezanejad et al., 2019;</ref><ref type="bibr" target="#b63">Walther et al., 2023;</ref><ref type="bibr" target="#b64">Walther &amp; Shen, 2014)</ref>. These techniques can help uncover a visual language for aesthetics. Given the universal mechanisms of human vision <ref type="bibr" target="#b25">(Graham &amp; Redies, 2010;</ref><ref type="bibr" target="#b28">Iigaya et al., 2021)</ref>, humans may have evolved an ongoing readiness for aesthetic evaluations, which conferred evolutionary advantages, such as finding a potential mate or ideal habitat <ref type="bibr" target="#b10">(Brielmann &amp; Pelli, 2018;</ref><ref type="bibr" target="#b12">Chatterjee, 2022;</ref><ref type="bibr" target="#b65">Wassiliwizky &amp; Menninghaus, 2021)</ref>.</p><p>People need to identify objects in their environment to act on them <ref type="bibr" target="#b24">(Gibson, 1986)</ref>. Similar objects tend to share visual features that help us recognize their category membership despite variations in their appearance. According to recognition-by-components theory, an extension of Marr's framework for vision <ref type="bibr" target="#b36">(Marr, 1982)</ref>, this process occurs via a set of visual primitives, akin to geometric building blocks of shapes, which are viewpoint invariant (i.e., nonaccidental; <ref type="bibr" target="#b8">Biederman, 1987)</ref>. Importantly, contour junctions are nonaccidental properties that convey information about spatial relationships of objects and surfaces in 3D space. These features help people recognize shapes presented in varying orientations and under perceptually ambiguous situations, and they even underlie our ability to accurately categorize objects and scenes <ref type="bibr" target="#b1">(Attneave, 1954;</ref><ref type="bibr" target="#b11">Cavanagh, 2005;</ref><ref type="bibr" target="#b64">Walther &amp; Shen, 2014;</ref><ref type="bibr" target="#b67">Wilder et al., 2019)</ref>. Viewpoint-invariant visual features are represented along the ventral visual stream and shown to play an important role in detecting shape skeletons and aesthetic qualities <ref type="bibr" target="#b2">(Ayzenberg et al., 2022;</ref><ref type="bibr" target="#b52">Sun &amp; Firestone, 2021)</ref>, as well as affective responses to contour <ref type="bibr" target="#b3">(Bar &amp; Neta, 2006;</ref><ref type="bibr" target="#b17">Damiano et al., 2021;</ref><ref type="bibr" target="#b55">Vartanian et al., 2013)</ref>.</p><p>This article investigates whether nonaccidental properties previously found to underlie the ability to perform general visual perceptual tasks, such as object recognition and scene categorization <ref type="bibr" target="#b8">(Biederman, 1987;</ref><ref type="bibr" target="#b64">Walther &amp; Shen, 2014)</ref>, predict subjective aesthetic valuations. We take an empirical approach to studying the effect of systematic variation in visual features in scenes on observers' aesthetic responses <ref type="bibr" target="#b5">(Berlyne, 1970;</ref><ref type="bibr" target="#b10">Brielmann &amp; Pelli, 2018)</ref>. If visual-processing mechanisms underlie the capacity to derive pleasure from seeing, then understanding the causal relationship between statistical properties of contours and subjective aesthetic valuations of scenes is the first step to understanding aesthetics from below <ref type="bibr" target="#b22">(Fechner, 1876)</ref>.</p><p>In Experiment 1, we built a contour model of aesthetic valuation using individual contour propertiesorientations, lengths, curvature, and junctions. In Experiment 2, contours in each scene were modified to change the aesthetic value of a given scene, generating contour-modified scenes with different aesthetic value. In Experiment 2, we tested whether an independent group of observers perceived contour-modified scenes with high-value contours more aesthetically pleasing than scenes with low-value contours. In Experiment 3, we expanded the range of features in the contour model from Experiment 2 to include quantitative measures of spatial relations between adjacent contours-separation, parallelism, and local mirror symmetry. We then generated new contour-modified scenes and obtained aesthetic valuations of these scenes from a second independent group of observers, controlling for individual differences. We used scene inversion to manipulate access to scene semantic content and explicitly measured it in a separate scene-categorization experiment. Last, we investigated the relative statistical contributions of individual contours and their spatial relations in aesthetic responses. The data, materials, and code for this study are publicly available on the Open Science Framework (<ref type="url" target="https://osf.io/rb2wc/">https://osf.io/rb2wc/</ref>). The study was not preregistered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head><p>In Experiment 1, we asked whether a supervised learning algorithm trained on statistical properties of individual contours can generate accurate predictions of aesthetic values for line drawings and color photographs of scenes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Stimuli. The stimuli consisted of color photographs (n = 475) and line drawings (n = 475) of natural scenes from the Toronto Scenes Dataset available freely on the Open Science Framework (<ref type="url" target="https://osf.io/9squn/">https://osf.io/9squn/</ref>). This image set has been characterized in several previous studies <ref type="bibr" target="#b53">(Torralbo et al., 2013;</ref><ref type="bibr" target="#b62">Walther et al., 2011;</ref><ref type="bibr" target="#b64">Walther &amp; Shen, 2014)</ref>. The line drawings were produced by trained artists by tracing the most salient outlines in a set of color photographs <ref type="bibr" target="#b62">(Walther et al., 2011)</ref>. These scenes were rated as good exemplars of six scene categories-offices, mountains, beaches, forests, and cities <ref type="bibr" target="#b53">(Torralbo et al., 2013)</ref>. Line drawings provide explicit access to structural contour properties present in scenes <ref type="bibr" target="#b62">(Walther et al., 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statement of Relevance</head><p>What makes some pictures more pleasing to our eyes than others? Artists and architects have long known that our brains can be tricked into liking some images and environments over others by using carefully curated combinations of visual features. We are beginning to understand that aspects of aesthetic experiences, such as how much a person likes a particular image, can be shared among people with different backgrounds and interests. We also know that the human visual system uses structural regularities in contour-lines that mark the outline of various shapes in a sceneto help us process information efficiently. In this study, we asked whether these structural regularities can be used to predict how pleasant an image looks on average to a group of adults from around the world. By changing different contour properties in images we could control how much people judged an image to be enjoyable to view.</p><p>Participants. In Experiment 1, participants were recruited using Prolific (<ref type="url" target="https://www.prolific.co">https://www.prolific.co</ref>) and provided with an average hourly monetary compensation of between CAD$12 and $15. For line drawings, a total of 75 participants provided ratings. For color photographs, ratings were obtained in a separate experiment with 121 participants providing ratings for a larger set of 1,243 images. The recruited samples were gender balanced (50% females and 50% males). This study was approved by the University of Toronto Research Ethics Board (Protocol No. 30999) and adhered to the tenets of the Declaration of Helsinki. After providing informed consent, participants were redirected to the Inquisit software (<ref type="url" target="https://www.millisecond.com">https://www.millisecond.com</ref>) to begin task administration remotely. Inclusion criteria for participation were fluency in English, an approval rating of &gt; 95%, and past participation in at least 10 studies on the platform. Exclusion criteria were based on recommendations for identifying careless responders in self-report studies <ref type="bibr" target="#b35">(Maniaci &amp; Rogge, 2014;</ref><ref type="bibr" target="#b38">Meade &amp; Craig, 2012)</ref>. Responses were analyzed using several data-screening methods, including 40 Max LongString (maximum number of identical consecutive responses), failure on two out of three attention-check items (e.g., "please press the number 3 on your keyboard"), and an unusually short completion time (i.e., &gt; 3 SDs below the mean). A total of 6 participants were excluded from the analysis. The criteria were based on a pilot study and were set before data collection began.</p><p>Procedure. For line drawings, each participant viewed and rated between 150 and 158 images, chosen pseudorandomly from a set of 475 line drawings in such a way that an equal number of images were drawn from a given scene category. For color photographs, each participant viewed and rated between 213 and 214 images pseudorandomly drawn from a larger set of 1,243 images. There were three versions of the experiment for line drawings and five for photographs. Between 14 to 38 independent ratings were obtained for each scene. After viewing each image, participants provided aesthetic judgments on a 5-point Likert scale in response to the following question: "How much do you enjoy looking at this image?" The response options were 1 = not at all, 2 = barely enjoy, 3 = somewhat enjoy, 4 = enjoy, and 5 = enjoy very much. In addition, subjective ratings for two other measures of fluency and complexity were also obtained but not included in the present analysis. Each experiment consisted of two blocks of images with an opportunity to take a short break after the first block. Images remained on the screen until participants provided a response, with a time limit of 30 s. Presentation time was not limited because of differences in aesthetic judgments as a function of presentation times <ref type="bibr" target="#b56">(Verhavert et al., 2018)</ref>. The average time taken to complete the experiments was between 32 and 50 min. The average trial response time was 2.1 s. The total duration of the experiments included instructions, self-paced breaks, and questionnaires to assess the observer's personal characteristics. Aesthetic judgment responses were converted to normalized scores (z-scores) for a given participant. The mean of responses was subtracted from each response, and this value was divided by the standard deviation of responses. Then, for each image, an average aesthetic value was calculated by obtaining the average z-scores across different individuals.</p><p>Extracting contour properties. Properties of individual scene contours (orientation, length, curvature) and contour junctions (angles and type) were computed on the basis of the methodology described by <ref type="bibr" target="#b64">Walther and Shen (2014)</ref>. Previous studies have used these quantifications of scene-contour properties <ref type="bibr" target="#b17">(Damiano et al., 2021;</ref><ref type="bibr" target="#b67">Wilder et al., 2019)</ref>. The methodology for extracting the statistical distribution of contour properties in real-world scenes is now implemented in a freely available software package, the Mid-Level Vision Toolbox (<ref type="url" target="https://mlvtoolbox.org">https://mlvtool box.org</ref>; <ref type="bibr" target="#b63">Walther et al., 2023)</ref>. Briefly, for a given scene line drawing, 8-bin histograms of a given contour property (e.g., orientation) were constructed to quantify the distribution of this property in a scene. Orientation refers to the counterclockwise angle of the line from the horizontal. The orientation histogram bins ranged from horizontal to vertical and were centered at 0Â° (Orientation 1), 22.5Â° (Orientation 2), 45Â° (Orientation 3), 67.5Â° (Orientation 4), 90Â° (Orientation 5), 112.5Â° (Orientation 6), 135Â° (Orientation 7), and 157.5Â° (Orientation 8). For angles larger than 180Â°, the opposite angles were used. The length of each contour was calculated by summing the lengths of its segments. The length histogram ranged from 2 pixels to the sum of the width and length of the images in pixels. The logarithms of lengths were equally divided into 8 bins (Length 1, Length 2, etc.), ranging from short to long contours. Curvature was parameterized as the change in orientation from one contour segment to the next within a contour, divided by the length of the current contour segment. Curvature histogram bins ranged from 0Â° (Curvature 1) to 90Â° (Curvature 8) per pixel, which means ranging from low curvature (flat) to high curvature (sharp). Contour junctions were classified by their type (X, T, Y, Arrow, Star) and quantified using their number in the scene (i.e., how many times contours intersected with a given angle range). More information about contour classifications can be found in the work of <ref type="bibr" target="#b63">Walther et al. (2023)</ref> and <ref type="bibr" target="#b64">Walther and Shen (2014)</ref>.</p><p>Histograms of all contour properties were normalized for the total number of pixels in each image to make it possible to compare scene properties across images with varying amounts of visual information (e.g., comparing busier and more sparsely populated images). Figure <ref type="figure" target="#fig_1">1</ref> shows the distribution of contour properties in scenes from the original stimulus set.</p><p>Contour properties of objects and scenes have been investigated as the basis of high-level vision processes <ref type="bibr" target="#b8">(Biederman, 1987)</ref>. However, practical difficulties in extracting contours and their properties from photographs have confined such research to hand-coded <ref type="bibr">(Hummel &amp; Biederman, 1992, pp. 480-517)</ref> or semiautomated contours features <ref type="bibr" target="#b19">(Elder &amp; Goldberg, 2002)</ref>.  Individual features have been extracted directly from photographic images, such as rectilinearity <ref type="bibr" target="#b40">(Nasr et al., 2014)</ref> or the distribution of oriented spatial frequencies <ref type="bibr" target="#b41">(Oliva &amp; Torralba, 2001)</ref>. In the context of aesthetics, Iigaya et al. relied on features extracted from deep neural networks <ref type="bibr" target="#b28">(Iigaya et al., 2021)</ref>. To our knowledge, our approach is the first that defines a comprehensive set of contour features in closed mathematical form on the basis of contours in complex, real-world scenes.</p><p>Random forest algorithm. We trained a random forest (RF) regression model (RF Model 1; Fig. <ref type="figure" target="#fig_2">2a</ref>), a supervised learning algorithm, to generate aesthetic-value predictions for scenes, using contour properties as features. Random forest models generate robust predictions in the presence of statistical dependencies and nonparametric data <ref type="bibr" target="#b23">(Fife &amp; D'Onofrio, 2022)</ref>. Random forest models aggregate predictions from several decision trees. The fitensemble function from MATLAB's Statistics and Machine Learning Toolbox was used to train an ensemble of boosted regression trees. Out-of-bag predictions were obtained using the oobPredict function, which computes predicted responses for a given training sample using only those trees that did not contain the sample in their bootstrap training set. For observations that are in the bootstrap training set for all trees, the predicted response is the weighted mean of all of the training responses. The correlation between the predicted and observed values was computed to provide a measure of prediction accuracy. The loss function was also applied to obtain the cumulative classification accuracy using mean squared error (MSE). MSE is the sum of squared residuals using "out-of-bag" observations at the tree level. The MSE provided the cross-validated accuracy of predictions. The contribution of each predictor in the model was assessed using "variable importance" (Fig. <ref type="figure" target="#fig_2">2b</ref>). Variable importance for scene properties was calculated using mean decrease in impurity (Gini index), which compares the reduction in prediction accuracy when the predictor of interest is left out <ref type="bibr" target="#b23">(Fife &amp; D'Onofrio, 2022)</ref>.</p><p>Figure <ref type="figure" target="#fig_2">2c</ref> shows a representative decision tree for RF Model 1. In this model, 100 decision trees generated aesthetic-value predictions for different combinations of contour properties. Each decision tree used a randomly selected subset of images with replacement (bootstrapping) and assigned a predicted aesthetic value for those images. In the model, 29 contour properties were used as predictive features. These included eight normalized histograms for each of the three individual contour features-orientation, length, and curvature-and the number of five classes of contour junctions (T, X, Y, Arrow, Star). The algorithm averaged the predictions from these decision trees to derive a robust aesthetic-value prediction for a given scene (bootstrap aggregation). At the top node of the decision tree shown in Figure <ref type="figure" target="#fig_2">2c</ref>, the algorithm asked whether the number of T junctions in the image exceeded an optimal threshold. This root node split the tree into two branches. Other contour features were then used to split the decision tree further until an aesthetic-value prediction for the random sample was reached at the leaf nodes.</p><p>Extracting color statistics. To test the consistency of statistical properties of contours across line drawings and color photographs of the scenes, we also collected aesthetic ratings of color photographs using the same procedure (Fig. <ref type="figure">3a</ref>). A new random forest model (RF Model Color) was built for the aesthetic responses to color photographs with the addition of nine color statistics as predictors (Fig. <ref type="figure">3b</ref>).</p><p>Color statistics for each photograph were computed in the CIELAB color space <ref type="bibr" target="#b39">(Nakauchi &amp; Tamura, 2022)</ref>. Each color is represented in a space consisting of three indices: lightness (L) and chromaticity (a, b). L represents a change in color intensity from black to white, chromaticity index a corresponds to a change from green to red, and chromaticity index b corresponds to a change from blue to yellow. For each of these indices, three statistics were computed: mean, variance, and skewness of the colorimetric values in the CIELAB color space, as described previously <ref type="bibr" target="#b39">(Nakauchi &amp; Tamura, 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>On a scale from 1 to 5, the average aesthetic rating for the line-drawing stimulus set was 2.9 (SD = 0.5); for color photographs, it was 3.05 (SD = 0.85). Average normalized ratings for intact line drawings and color photographs based on scene categories were for beaches (line drawings = 0.07, SD = 0.42; color photographs = 0.58, SD = 0.34), for cities (line drawings = 0.36, SD = 0.35; color photographs = -0.18, SD = 0.41), for forests (line drawings = -0.4, SD = 0.28; color photographs = 0.35, SD = 0.29), for highways (line drawings = 0.09, SD = 0.30; color photographs = -0.62, SD = 0.29), for mountains (line drawings = -0.24, SD = 0.32; color photographs = 0.71, SD = 0.26), and for offices (line drawings = 0.1, SD = 0.3; color photographs = -0.84, SD = 0.31). Interestingly, human-made scene categories such as cities, offices, and highways were deemed to be liked more when viewed in line-drawing form than in photograph form.</p><p>Scene-contour properties (RF Model 1) predicted subjective aesthetic valuations of intact line drawings  (Figs. <ref type="figure" target="#fig_1">1</ref> and<ref type="figure" target="#fig_2">2</ref>). Cross-validation shows that predicted aesthetic values correlate significantly with observed aesthetic ratings (line drawings: r = .64, p &lt; .001; color photographs: r = .77, p &lt; .001; Fig. <ref type="figure">4b</ref>). The MSE was .031 for line drawings and .058 for color photographs.</p><p>The most robust finding concerning the contribution of contour properties in the model was that T junctions are the most informative visual cues for aesthetic-value predictions in scenes (Fig. <ref type="figure" target="#fig_2">2b</ref>). This result was found for both line drawing (Fig. <ref type="figure" target="#fig_2">2b</ref>) and color photograph (Fig. <ref type="figure">3b</ref>) RF models. See Figure <ref type="figure">3c</ref> for a visualization of the average aesthetic responses for different scene categories in line drawings and photographs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>In Experiment 2, we investigate whether a shift in aesthetic responses in an expected direction can be caused by modifying contour properties according to model predictions from Experiment 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Stimuli. Using the trained RF Model 1, we generated predictions of aesthetic value for individual contours by considering the distribution of contour properties for this one contour in an image. Once we acquired the predicted  aesthetic values, we ranked the contours from lowest to highest with respect to predicted aesthetic value. We then performed a median split of the contours so that equal numbers of contour pixels were contained in the top and the bottom half of the rank list. Contours that were not uniquely assigned to the top or bottom halves were omitted from both. We then rendered contour drawings that contained the bottom or the top half of the contours by predicted aesthetic value. Finally, we generated predictions for the aesthetic appeal for each scene. As anticipated, predictions for scenes consisting of the top-ranked contours were significantly higher than those consisting of the bottom-ranked contours.</p><p>Participants. Seventy-seven participants (52.1% female) were recruited using the same criteria and procedure as described in Experiment 1 (mean age = 25.3 years).</p><p>Individual differences. Several measures that captured the personal characteristics of the observers were included in this study. In Experiment 2, information on age, gender, educational attainment, environmental-type familiarity, mood or affect, creativity, artistic training, and experience was collected. Affect was measured using the Positive and Negative Affect Schedule (PANAS; <ref type="bibr" target="#b66">Watson et al., 1988)</ref>, a validated self-report questionnaire composed of 10-item scales to provide measures of positive affect (e.g., excited, inspired) and negative affect (e.g., afraid, sad). The Divergent Association Task was used to measure creativity, as described in a previous study <ref type="bibr" target="#b42">(Olson et al., 2021)</ref>. This task involves naming ten nouns that differ as much as possible from each other. The average semantic distance between generated nouns was shown to be a reliable marker of creativity <ref type="bibr" target="#b42">(Olson et al., 2021)</ref>. To assess their environmental familiarity, participants responded to the following question: "How would you describe the environment where you grew up?" The response choices included urban, suburban, and rural.</p><p>To assess artistic experience and training, the participants responded to the following questions: "How often are you involved in practicing or learning about visual arts (e.g., painting, drawing, photography, design, architecture, filmmaking)?" and "How many years of artistic training do you have?" We also obtained information on formal education, which is a reliable indicator of an individual's cognitive reserve.</p><p>Statistical analysis. We first used a paired-samples t test to test whether there is a statistically significant difference in mean aesthetic-value judgments ascribed to viewing modified scenes with high-versus low-ranked contours. To model the contribution of interindividual factors in addition to scene condition, we performed a linear mixed-effects model analysis using the lmer package <ref type="bibr" target="#b4">(Bates et al., 2015)</ref> in R. We used age, gender, educational attainment, environmental-type familiarity, positive affect score, negative affect score, creativity score, years of artistic training and experience as fixed-effects predictors of aesthetic ratings, in addition to aesthetic condition. Participant identity was included as a random-effect term, using the following expression: lmer(response ~ condition +. . .+ (1 + condition|participant)). This means that slopes and intercepts of aesthetic responses were allowed to vary across participants. We used Satterthwaite's approximation in the lmerTest package to calculate p values <ref type="bibr" target="#b33">(Kuznetsova et al., 2017)</ref> with 95% confidence intervals (CIs) for fixed effects. The MuMIn package <ref type="bibr" target="#b29">( Johnson et al., 2014)</ref> was used to derive conditional and marginal R 2 . We performed likelihood ratio tests and obtained Akaike Information Criterion (AIC) values to compare the models with fixed effects to the null models with only the random effects. These tests were used to assess the validity of the mixed-effects model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>In Experiment 2, we found that contour-modified scenes that retained the top-ranked contours (M = 2.72, SD = 1.22) were perceived to be more aesthetically pleasing than contour-modified scenes with bottomranked contours preserved (M = 2.37, SD = 1.18), t(398) = 15.73, p &lt; .00001, 95% confidence interval (CI) = [0.30, 0.39], Cohen's d = 0.69. The effect was consistent across different scene categories (Fig. <ref type="figure">4c</ref>).</p><p>The linear mixed-effects model showed a statistically significant effect for aesthetic condition with scenes containing high-ranked contours favored over scenes containing low-ranked contours (high vs. low estimate = 0.33, 95% CI = [0.27, 0.38], t(1, 76) = 12.36, p &lt; 2 Ã 10 -16 ). In this model, affect was a significant predictor of aesthetic responses: Higher scores on the negative-affect index were associated with higher aesthetic ratings (estimate = 0.052, 95% CI = [0.015, 0.09], t(1, 67) = 2.59, p = .01). The marginal (fixed effects) and conditional (fixed and random effects) pseudo-R 2 values for the mixedeffects model were 0.068 and 0.388, respectively. The standard deviation of the random effect for participants was 0.68, showing considerable variation between participants with respect to the fixed effects. Other individual factors such as age-estimate = 0.012, 95% CI = [-0.011, 0.037], t(1, 67) = 0.98, p = .33; gender (male vs. female)-estimate = -0.07, 95% CI = [-0.37, 0.22], t(1, 67) = -0.45, p = .65; creativity-estimate = 0.007, 95% CI = [-0.015, 0.03], t(1, 67) = 0.59, p = .55; artistic training-estimate = 0.049, 95% CI = [-0.10, 0.20], t(1, 67) = 0.58, p = .55; and experience-estimate = -0.009, 95% CI = [-0.088, 0.069], t(1, 67) = -0.22, p = -.22; environmental familiarity-urban versus rural estimate = 0.17, 95% CI = [-0.25, 0.59], t(1, 67) = 0.74, p = .45; suburban versus rural estimate = 0.20, 95% CI = [-0.24, 0.66], t(1, 67) = 0.87, p = .38; and positive affect-estimate = 0.036, 95% CI = [-0.007, 0.08], t(1, 67) = 1.53, p = .12-were not significant predictors of aesthetic responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3</head><p>We showed in Experiment 1 that a random forest model of aesthetic valuation using contour properties as predictors successfully predicted subjective aesthetic judgments of scenes (Fig. <ref type="figure">4b</ref>). In Experiment 2, we found that altering individual contour properties on the basis of model predictions directly changed subjective aesthetic responses to scenes. Following these findings, we aimed to probe further the contributions of higherlevel visual representations in aesthetic responses. Finally, in Experiment 3, we investigated the contributions of spatial-relationship cues and disruption of semantic processing through scene inversion on aesthetic valuations of scenes.</p><p>To understand the role of higher-level visual representations in shifting aesthetic responses in contourmodified scenes, we asked whether the effect of preference for top-ranked contours over bottom-ranked contours persists when semantic processing of the scenes is disrupted (Fig. <ref type="figure">7</ref>). Inversion is thought to disrupt the ability of observers to detect the configuration or semantic aspects of visual stimuli <ref type="bibr" target="#b20">(Epstein et al., 2006)</ref>. Face and scene inversions make object identification, change detection, and extraction of visual properties harder <ref type="bibr" target="#b20">(Epstein et al., 2006;</ref><ref type="bibr" target="#b26">Hayes &amp; Henderson, 2022)</ref>. In Experiment 3, we used scene inversions to explore the impact of disrupting configurational and holistic information processing on aesthetic judgments of contour-modified scenes. If the aesthetic valuation of inverted contour-manipulated scenes were to follow the same pattern as observed in Experiment 2, this would suggest that top-ranked contours are more aesthetically pleasing than bottom-ranked contours even when access to semantic content is reduced through scene inversion. Finally, we verified that the contour manipulations did not disrupt access to semantic information in a categorization experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants. Seventy-seven participants were recruited using the same criteria and procedure described in Experiment 1 (mean age = 24.5 years) for aesthetic-rating experiments. Similarly, 60 participants were recruited in a separate scene-categorization experiment using the same criteria. The recruited samples were gender balanced.</p><p>Extracting contour properties. Spatial relations between adjacent contours for each image were computed on the basis of medial-axis computations for complex scenes, a novel methodology developed by Rezanejad et al. <ref type="bibr" target="#b46">(Rezanejad, 2020;</ref><ref type="bibr" target="#b47">Rezanejad et al., 2019)</ref>. Parallelism refers to the rate of change in the distance between adjacent contours from the medial axis, separation is the contour's distance from the medial axis, and local mirror symmetry reflects the degree to which a part of the image is reflected across a straight axis. We therefore computed a measure of local mirror symmetry from the local curvature of the medial axis. As with individual contour properties, normalized 8-bin histograms of contour spatial relationships for these three measures were constructed (Fig. <ref type="figure">5</ref>). Code for computing these properties is available at <ref type="url" target="http://mlvtoobox.org">http://mlvtoobox.org</ref>  <ref type="bibr" target="#b63">(Walther et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random forest algorithm.</head><p>In this experiment, a new random forest model (RF Model 2) was used to predict average normalized aesthetic ratings for a given scene, using the same procedure as the one used in Experiment 1. In this experiment, histogram bins of spatial relation properties of adjacent contours (separation, parallelism, mirror symmetry) were added to the feature list. A total of 53 features were used as predictors of aesthetic value (Fig. <ref type="figure">6</ref>).</p><p>Stimuli. Following the same procedure for stimuli generation as in Experiment 2, half-split images based on predicted scores from RF Model 2 were generated for this experiment; 132 of these contour-modified scenes were also presented in an inverted condition (i.e., rotated by 180 degrees) with a randomized presentation order (Fig. <ref type="figure">7</ref>).</p><p>Procedure. Aesthetic judgments of contour-modified scenes were collected following the procedure used in Experiments 1 and 2. The experiment was run using Inquisit software with participants recruited from Prolific. There were 950 upright and 132 inverted contour-modified scenes, and they were rated by 18 to 20 observers. Five versions of the experiments were used, so each participant rated a maximum of 266 images.</p><p>In a separate categorization experiment, participants were shown half-split and inverted stimuli in a random presentation order and asked to respond with the category of the scene. Each participant categorized 350 scenes, which contained balanced numbers of images from each scene category (aesthetic and inverted conditions). There were six possible scene categories. The key mapping (e.g., s = forest, d = city, f = mountain, j = highway, k = beach, l = office) was pseudorandomized for different participants. Each participant completed 10 practice trials with feedback before proceeding to the main experiment. Each trial started with the presentation of a fixation cross at the center of the display for 100 ms, followed by the scene image. Category keys were also shown at the bottom of the page as a reminder of the key mapping. Response time was limited to 10 s. Figure <ref type="figure" target="#fig_5">8c</ref> shows a schematic of the categorization  experiment. Categorization accuracy was computed as the fraction of correctly categorized images for each participant and averaged across participants.</p><p>Individual differences. Similar to Experiment 2, several measures that captured the personal characteristics of the observers were included in this study, including age, gender, educational attainment, environmental-type familiarity, and mood or affect. In addition, the aesthetic responsiveness assessment (AReA) was administered, which provides a broad measure of individual differences in responsiveness to aesthetic experiences <ref type="bibr" target="#b50">(Schlotz et al., 2021)</ref>. This measure consists of three separate subscales-aesthetic appreciation, creative behavior, and intense aesthetic experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model comparison.</head><p>A variance partitioning analysis was conducted to examine the correlations among the residuals of RF Model 1 (contour properties) and RF Model 2 (contour properties and spatial relations). We obtained the residuals of Model 1 (Y1) and Model 2 (Y2). A partial-correlation analysis was conducted using Y1, Y2, and aesthetic responses from Experiment 1 (Y). The ppcor package in R was used for this computation <ref type="bibr" target="#b31">(Kim, 2015)</ref>. Partial correlations are used to explore the amount of variance explained by one variable after eliminating the effects of other variables in a model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The random forest model (RF Model 2) trained on individual contour properties and spatial relation cues predicted aesthetic responses. These predictions were significantly correlated with observed aesthetic ratings (r = .62, p &lt; .001). The MSE was .027.</p><p>A two-way analysis of variance showed a significant main effect for both the aesthetic condition, F(1, 494) = 323.77, p &lt; .001, 95% CI = [0.22, 0.29], Cohen's d = 0.10, and the semantic condition (inverted vs. upright estimate = 0.40), 95% CI = [0.35, 0.44], F(1, 573) = 375.81, p &lt; .001. As in Experiment 2, we found that contourmodified scenes that retained the top-ranked contours (M = 2.35, SD = 1.26) were perceived to be more aesthetically pleasing than scenes with bottom-ranked contours preserved (M = 2.11, SD = 1.23; Fig. <ref type="figure" target="#fig_5">8a</ref>). This effect was also found within inverted scenes, M diff = 0.14, 95% CI = [0.04, 0.23], p adj = .002. We also found that aesthetic judgments of upright drawings were more favorable than aesthetic judgments of inverted drawings for both the high aesthetic condition, M diff = 0.45, 95% CI = [0.38, 0.53], p adj &lt; .00001, and the low aesthetic condition, M diff = 0.34, 95% CI = [0.26, 0.42], p adj &lt; .00001 (Fig. <ref type="figure" target="#fig_5">8b</ref>).</p><p>A linear mixed-effects model showed a statistically significant effect for aesthetic condition with highranked contours favored over low-ranked contours (high vs. low estimate = 0.33), 95% CI = [0.27, 0.38], t(1, 76) = 12.36, p &lt; 2 Ã 10 -16 ). The marginal (fixed effects) and conditional (fixed and random effects) pseudo-R 2 values for the mixed-effects model were 0.159 and 0.382, respectively. The standard deviation of the random effect for participants was 0.63, showing considerable variation between participants with respect to the fixed effects. Consistent with results from Experiment 2, affect was a significant predictor of aesthetic responses. Higher scores on negative affect were positively associated with aesthetic ratings, Î² = 0.014, 95% CI = [0.003, 0.03], t(1, 65) = 2.33, p = .02, whereas higher scores on positive affect were negatively associated with aesthetic ratings, Î² = -0.01, 95% CI = [-0.02, -0.002], t(1, 65) = -2.21, p = .03.</p><p>Other individual factors were not significant predictors of aesthetic responses. These included age, Î² = 0.004, 95% CI = [-0.018, 0.026], t(1, 66) = 0.33, p = .74; gender (male vs. female), Î² = 0.32, 95% CI = [0.03, 0.62], t(1, 65) = 2.06, p = .04; gender (other vs. female), Î² = -0.41, 95% CI = [-1.67, 0.84], t(1,66) = -0.60, p = .54; aesthetic responsiveness (creative behavior), Î² = 0.034, 95% CI = [-0.10, 0.20], t(1, 65) = 1.23, p = .21; aesthetic responsiveness (intense aesthetic experience), Î² = 0.05, 95% CI = [-0.10, 0.20], t(1, 65) = 1.82, p = .07; aesthetic appreciation, Î² = -0.009, 95% CI = [-0.10, 0.20], t(1, 65) = -0.56, p = .57; environmental familiarity (urban vs. rural), Î² = 0.17, 95% CI = [-1.25, -0.03], t(1, 67) = 0.74, p = .45; and environmental familiarity (suburban vs. rural), Î² = 0.20, 95% CI = [-0.12, 0.06], t(1, 67) = 0.7, p = .38.</p><p>Comparison of Experiment 2 RF model and Experiment 3 RF model. We found that the RF model consisting of contour properties alone (RF Model 1) explained 87.1% of the variance in aesthetic responses, F(1, 473) = 3,193, p &lt; .001, R 2 = .87. The RF model consisting of both contour properties and spatial relation cues (RF Model 2) similarly explained 86.1% of the variance in aesthetic responses, F(1, 473) = 2,922, p &lt; .001, R 2 = .86. The partial correlation between the RF Model 1 and aesthetic responses after eliminating the effect of RF Model 2 was .35. Thus, contour properties explained 62.7% of the variance once spatial relations (RF Model 2) were accounted for.</p><p>Control experiment for semantic content. The average accuracy in the scene-categorization tasks for the high (M = 0.87, SD = 0.14) versus low (M = 0.86, SD = 0.15) aesthetic conditions was comparable, F(1, 948) = 1.9, p = .168 (high vs. low aesthetic condition difference = .013, 95% CI = [-.005, .031]), showing that access to overall scene semantic content is not differentially altered by these specific contour manipulations. Similarly, for inverted scenes, categorization accuracy was comparable across high (M = 0.82, SD = 0.14) and low (M = 0.81, SD = 0.85) aesthetic conditions, F(1, 98) = 0.21, p = .647 (high vs. low aesthetic condition difference = .015, 95% CI = [-.051, .082]). Interestingly, the average categorizationaccuracy performance was significantly higher for upright (M = 0.87, SD = 0.14) compared with inverted (M = 0.82, SD = 0.17) scenes, F(1, 1048) = 10.64, p = .001 (upright vs. inverted difference = -.05 [95% CI = -.08, -.02]). This confirmed that the scene-inversion manipulation disrupted semantic processing of both low and high aesthetic conditions and that targeted contour manipulations did not change the semantic content of scenes (Fig. <ref type="figure" target="#fig_5">8d</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>We have demonstrated that observers' aesthetic responses to natural scenes can be shifted in a predicted direction by manipulating the properties of contours within a scene. We presented a contour model of visual aesthetics and a method for modifying contour properties according to predicted aesthetic value. We modified contours in scenes while retaining scene identity and showed a causal relationship between participants' aesthetic judgments and contour properties. For different semantic categories of scenes and in different groups of observers, we found that scenes with topranked contours were judged to be more aesthetically pleasing than scenes with bottom-ranked contours, as predicted by the model. We also showed that disrupting access to semantic content through scene inversion does not change the aesthetic advantage of top-ranked contours, indicating that the feature manipulations directly change aesthetic judgments rather than affect semantic processing. This effect was confirmed in a scene-categorization task, which showed that the categorization performance is diminished by a scene-inversion manipulation but not by aesthetic contour manipulations.</p><p>Finally, we found that there is considerable individual variation in the extent to which contour manipulations shift aesthetic evaluations, with observers' negative affect as a predictive individual characteristic.</p><p>In three experiments, we investigated the extent to which individual contour properties (orientation, length, curvature, junctions) and spatial relations between them (separation, parallelism, local mirror symmetry) contributed to subjective aesthetic responses. Our results show that much of the variance explained in responses is attributed to modifications of individual contour properties. Notably, contour junctions, specifically T junctions, were found to be the most potent visual cue for informing subjective aesthetic judgments, consistent with their important role in object and scene perception <ref type="bibr" target="#b8">(Biederman, 1987;</ref><ref type="bibr" target="#b14">Choo &amp; Walther, 2016)</ref>. Different junction types are thought to carry different types of visual information-a property often used by artists in different cultures to create aesthetic effects <ref type="bibr" target="#b11">(Cavanagh, 2005;</ref><ref type="bibr" target="#b49">Sayim &amp; Cavanagh, 2011)</ref>. For example, X junctions signal transparency, whereas T junctions signal occlusion boundaries <ref type="bibr" target="#b11">(Cavanagh, 2005)</ref>. T junctions help with recognizing objects and their configurations in space. These informative visual cues facilitate scene understanding and a subsequent sense of environmental safety, possibly through learned scene grammar <ref type="bibr" target="#b60">(VÃµ et al., 2019)</ref>, spatial schemas <ref type="bibr" target="#b21">(Farzanfar et al., 2023)</ref>, or perceptual fluency <ref type="bibr" target="#b45">(Reber et al., 2004)</ref>. The presence of nonaccidental scene properties likely improves aesthetic valuations by increasing information gain about the 3D structure of the scene and category membership as well as by possibly eliciting a sense of psychological safety. The robust effect of T junctions as a key predictor of aesthetic value in our models suggests that visual cues that resolve perceptual ambiguities and facilitate understanding of scene geometry are important for shaping our aesthetic judgments. We found that aesthetic evaluations are shaped by contour properties but not to the exclusion of individual observers' characteristics. It is noteworthy that affect <ref type="bibr" target="#b66">(Watson et al., 1988</ref>) modulated the relationship between contour and aesthetic valuations in such a way that participants with stronger negative affect were more likely to rate line drawings favorably. Previous studies have shown human preferences for certain contour properties, such as curvature in objects, faces, and architectural scenes <ref type="bibr" target="#b3">(Bar &amp; Neta, 2006;</ref><ref type="bibr" target="#b55">Vartanian et al., 2013)</ref>, but context moderates this effect <ref type="bibr" target="#b15">(Chuquichambi et al., 2022;</ref><ref type="bibr" target="#b16">Dai et al., 2022)</ref>. Another study found that threat judgments can be predicted by contour properties <ref type="bibr" target="#b17">(Damiano et al., 2021)</ref>. Daniel Berlyne conceptualized the arousal potential of visual stimuli as the mediator between collative variables (e.g., novelty and complexity) and aesthetic response <ref type="bibr" target="#b5">(Berlyne, 1970;</ref><ref type="bibr" target="#b51">Silvia, 2005)</ref>. Changes in momentary reports of subjective happiness have also been shown to reflect a state represented by reward prediction-error signals in midbrain dopaminergic neurons <ref type="bibr" target="#b48">(Rutledge et al., 2014)</ref>. These findings suggest that aesthetic responses are coupled with affective responses <ref type="bibr" target="#b13">(Chatterjee &amp; Vartanian, 2014)</ref> in such a way that simple lines can indeed modulate affective responses. In response to viewing line drawings of scenes, we also found that individuals with higher negative baseline affect are more likely to be "pleasantly surprised," as shown by an elevation in their self-reported aesthetic experience. We hypothesize that negative affect increases an individual's potential for arousal and aesthetic responsiveness <ref type="bibr" target="#b50">(Schlotz et al., 2021)</ref>. More research is needed in this area to help us understand whether aesthetic responses are distinct from both reward and affective processing.</p><p>Our results support the notion of a perceptual reward system <ref type="bibr" target="#b9">(Biederman &amp; Vessel, 2006;</ref><ref type="bibr" target="#b59">Vessel et al., 2021)</ref>. Previous studies that have investigated the role of statistical image properties using global quantitative measures such as contrast, entropy, spatial frequency, and self-similarity <ref type="bibr" target="#b25">(Graham &amp; Redies, 2010;</ref><ref type="bibr" target="#b28">Iigaya et al., 2021;</ref><ref type="bibr" target="#b43">Palmer et al., 2013)</ref>. In this study, we found that structural contour properties are remarkably predictive of aesthetic responses to natural scenes. This methodology allowed us to investigate aesthetic valuation beyond the global level of a scene and to focus on target local elements. Specifically, local elements that are defined by the medial axis are represented in the ventral visual stream <ref type="bibr" target="#b2">(Ayzenberg et al., 2022)</ref>. These local regions guide attentional processes that are supported by midlevel vision neural substrates <ref type="bibr" target="#b2">(Ayzenberg et al., 2022;</ref><ref type="bibr" target="#b44">Peirce, 2015)</ref>. Contour properties also help people recognize visual primitives that make it easier to recognize items that share similar features with items encountered in the past and encoded in their semantic memory store. Research has shown that individuals tend to agree more with one another when evaluating real-world scenes than works of art and architecture <ref type="bibr" target="#b58">(Vessel et al., 2018</ref><ref type="bibr" target="#b57">(Vessel et al., , 2019) )</ref> and that viewing nature scenes has restorative effects <ref type="bibr" target="#b6">(Berman et al., 2008;</ref><ref type="bibr" target="#b30">Kaplan &amp; Kaplan, 1989)</ref>. Aesthetic pleasure likely depends on visual properties that conferred evolutionary advantages and played a role in affordances-the possibilities for use and action that an external environment offers <ref type="bibr" target="#b10">(Brielmann &amp; Pelli, 2018;</ref><ref type="bibr" target="#b24">Gibson, 1986;</ref><ref type="bibr" target="#b55">Vartanian et al., 2013)</ref>. Contour regularities may also guide human spatial navigation in the form of spatial schemas <ref type="bibr" target="#b21">(Farzanfar et al., 2023)</ref>; the extent to which aesthetic qualities of space facilitate navigation is an active area for future research.</p><p>Interestingly, we found that aesthetic judgments of natural scenes were lower when line drawings of scenes were evaluated compared with when their photographs were evaluated. Line drawings of cities and other human-made artifacts, on the other hand, were liked more than their photographed counterparts. This interesting finding can be explained by a complexity-fluency trade-off phenomenon <ref type="bibr" target="#b5">(Berlyne, 1970;</ref><ref type="bibr" target="#b18">Donderi, 2006)</ref>. Line drawings contain less information. Therefore, an inherently more complex scene category, such as a city, is more likely to reach the optimal arousal point when presented as a drawing than as a comparably more complex color photograph. By contrast, natural scene categories are liked more as photographs than as line drawings, presumably because the decrease in complexity in the drawings moves them away from the optimal arousal point. Similarly, perceptual grouping cues such as symmetry that increase information gain are associated with aesthetic responses <ref type="bibr" target="#b0">(Arnheim, 1974;</ref><ref type="bibr" target="#b1">Attneave, 1954;</ref><ref type="bibr" target="#b7">Bertamini et al., 1997;</ref><ref type="bibr" target="#b54">Van de Cruys &amp; Wagemans, 2011;</ref><ref type="bibr" target="#b32">Koffka, 1935;</ref><ref type="bibr" target="#b43">Palmer, 1992;</ref><ref type="bibr" target="#b61">Wagemans, 1993)</ref> and have been found to contribute to aesthetic judgments to some degree in our study. Given the facilitative effect of prototypicality on aesthetic valuations across a range of stimuli <ref type="bibr" target="#b10">(Brielmann &amp; Pelli, 2018;</ref><ref type="bibr" target="#b37">Martindale &amp; Moore, 1988;</ref><ref type="bibr" target="#b43">Palmer et al., 2013)</ref>, we propose that visual features that enhance our perception of aesthetic value are likely also involved in category learning.</p><p>We note that the generalizability of our findings is potentially limited to an adult population recruited remotely. We have shown that changes to contour properties and grouping cues directly alter aesthetic responses, even for inverted scenes with disrupted semantic processing. Our experimental method using targeted contour modifications allowed us to show a causal relationship between visual properties and aesthetic responses to scenes, taking prior correlational evidence of regularities in human aesthetic responses to an experimental test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transparency</head><p>Action Editor: M. Natasha Rajah Editor: Patricia J. Bauer</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Visualization of contour properties for five representative line drawings. The bottom row shows the relative frequency of these properties for all stimuli.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Some results from Experiment 1. In (a), a schematic of the construction of the random forest model is shown, from contour properties in Experiment 1. A variable importance plot is illustrated in (b), and a representative decision tree is shown in (c), with predicted aesthetic ratings at the bottom of the graph. AU = arbitrary units.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Fig. 3. More results from Experiment 1. (a) schematic of the construction of the random forest model from image features for color photographs, (b) variable importance plot, and (c) mean aesthetic ratings for line drawings and color photographs for different scene categories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig. 6. Results of Experiment 3. (a) variable importance plot, and (b) schematic of the construction 453 of random the forest model from image features for Experiment 3. AU = arbitrary units.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Results for Experiment 3, including (a) mean aesthetic ratings across categories for each aesthetic condition in Experiment 3 and (b) violin plots showing the distribution of aesthetic judgments for upright and inverted images in both aesthetic conditions (*p &lt; .001). The effect was consistent across scene categories. In (c) is shown a schematic of the scene-categorization experiment, and in (d) is shown mean categorization accuracy for aesthetic and semantic conditions. Errors bars represent 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Visualization of measures of the spatial relation between contours for four representative line drawings. The bottom row shows the distribution of these properties for all stimuli.</figDesc><table><row><cell>Average Number of Pixels Variable Importance (AU)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Average Number of Pixels</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Average Number of Pixels</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Symmetry</cell><cell>Parallelism</cell><cell cols="2">Separation</cell><cell cols="2">Junctions</cell><cell cols="2">Length</cell><cell cols="2">Curvature</cell><cell>Orientation</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">Separation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">Parallelism</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">Symmetry</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fig. 5. T Junctions</cell><cell>Separation 1</cell><cell>Separation 5</cell><cell>Curvature 7</cell><cell>Orientation 1</cell><cell>Symmetry 3</cell><cell>Symmetry 1</cell><cell>X Junctions</cell><cell>Orientation 6</cell><cell>Length 1</cell><cell>Separation 8</cell><cell>Symmetry 2</cell><cell>Separation 4</cell><cell>Separation 6</cell><cell>Length 2</cell><cell>Separation 7</cell><cell>Separation 2</cell><cell>Y Junctions</cell><cell>Length 8</cell><cell>Curvature 8</cell><cell>Curvature 6</cell><cell>Orientation 5</cell><cell>Arrow Junction</cell><cell>Symmetry 6</cell><cell>Length 6</cell><cell>Length 5</cell><cell>Separation 3</cell><cell>Curvature 2</cell><cell>Parallelism 1</cell><cell>Curvature 4</cell><cell>Symmetry 7</cell><cell>Orientation 7</cell><cell>Orientation 8</cell><cell>Orientation 4</cell><cell>Symmetry 8</cell><cell>Parallelism 3</cell><cell>Length 3</cell><cell>Length 7</cell><cell>Orientation 3</cell><cell>Parallelism 6</cell><cell>Orientation 2</cell><cell>Curvature 3</cell><cell>Parallelism 4</cell><cell>Curvature 1</cell><cell>Length 4</cell><cell>Curvature 5</cell><cell cols="2">Parallelism 2</cell><cell>Symmetry 4</cell><cell>Parallelism 8</cell><cell cols="2">Parallelism 7</cell><cell>Symmetry 5</cell><cell>Parallelism 5</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflicting Interests</head><p>The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open Practices</head><p>The data, materials, and code for this study have been made publicly available on the Open Science Framework and can be accessed at <ref type="url" target="https://osf.io/rb2wc/">https://osf.io/rb2wc/</ref>. The study was not preregistered.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Art and visual perception</title>
		<author>
			<persName><forename type="first">R</forename><surname>Arnheim</surname></persName>
		</author>
		<idno type="DOI">10.1525/9780520351271-005</idno>
		<ptr target="https://doi.org/10.1525/9780520351271-005" />
		<imprint>
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Some informational aspects of visual perception</title>
		<author>
			<persName><forename type="first">F</forename><surname>Attneave</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="183" to="193" />
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Skeletal representations of shape in the human visual cortex</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ayzenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Dilks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Lourenco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">164</biblScope>
			<biblScope unit="page">108092</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Humans prefer curved visual objects</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neta</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9280.2006.01759.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-9280.2006.01759.x" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="645" to="648" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">lme4: Linear mixedeffects models using Eigen and S4</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>MÃ¤chler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bolker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Singmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Version</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2014">2015. 2014</date>
		</imprint>
	</monogr>
	<note>Computer software</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Novelty, complexity, and hedonic value</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Berlyne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="279" to="286" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The cognitive benefits of interacting with nature</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Berman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jonides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaplan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1207" to="1212" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Detection of symmetry and perceptual organization: The way a lock-and-key process works</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bertamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Friedenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kubovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="140" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Recognition-by-components: A theory of human image understanding</title>
		<author>
			<persName><forename type="first">I</forename><surname>Biederman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="147" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Perceptual pleasure and the brain: A novel theory explains why the brain craves information and seeks it through the senses</title>
		<author>
			<persName><forename type="first">I</forename><surname>Biederman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Vessel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Scientist</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="247" to="253" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Brielmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Pelli</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2018.06.004</idno>
		<ptr target="https://doi.org/10.1016/j.cub.2018.06.004" />
	</analytic>
	<monogr>
		<title level="j">Aesthetics. Current Biology</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="859" to="R863" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The artist as neuroscientist</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cavanagh</surname></persName>
		</author>
		<idno type="DOI">10.1038/434301a</idno>
		<ptr target="https://doi.org/10.1038/434301a" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">434</biblScope>
			<biblScope unit="issue">7031</biblScope>
			<biblScope unit="page" from="301" to="307" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An early framework for a cognitive neuroscience of visual aesthetics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chatterjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Brain, beauty, &amp; art: Essays bringing neuroaesthetics in focus</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Chatterjee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Cardillo</surname></persName>
		</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neuroaesthetics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vartanian</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2014.03.003</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2014.03.003" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="370" to="375" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Contour junctions underlie neural representations of scene categories in high-level human visual cortex</title>
		<author>
			<persName><forename type="first">H</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Walther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="32" to="44" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">How universal is preference for visual curvature? A systematic review and meta-analysis</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Chuquichambi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vartanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Skov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Corradi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nadal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Silvia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Munar</surname></persName>
		</author>
		<idno type="DOI">10.1111/nyas.14919</idno>
		<ptr target="https://doi.org/10.1111/nyas.14919" />
	</analytic>
	<monogr>
		<title level="j">Annals of the New York Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">1518</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="151" to="165" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Aesthetic judgment of architecture for Chinese observers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fukuda</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0265412</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0265412" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">265412</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Contour features predict valence and threat judgements in scenes</title>
		<author>
			<persName><forename type="first">C</forename><surname>Damiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Cunningham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Visual complexity: A review</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Donderi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="73" to="97" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ecological statistics of Gestalt laws for the perceptual organization of contours</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Elder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Goldberg</surname></persName>
		</author>
		<idno type="DOI">10.1167/2.4.5</idno>
		<ptr target="https://doi.org/10.1167/2.4" />
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cortical correlates of face and scene inversion: A comparison</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Aguirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cooperman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1145" to="1158" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">From cognitive maps to spatial schemas</title>
		<author>
			<persName><forename type="first">D</forename><surname>Farzanfar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Spiers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moscovitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Rosenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="63" to="79" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Fechner</surname></persName>
		</author>
		<title level="m">Preschool of aesthetics</title>
		<imprint>
			<publisher>Breitkopf &amp; HÃ¤rtel</publisher>
			<date type="published" when="1876">1876</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Common, uncommon, and novel applications of random forest in psychological research</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Fife</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Onofrio</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-022-01901-9</idno>
		<ptr target="https://doi.org/10.3758/s13428-022-01901-9" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Advance online</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The ecological approach to visual perception</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Gibson</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780203767764</idno>
		<ptr target="https://doi.org/10.4324/9780203767764" />
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Statistical regularities in art: Relations with visual coding and perception</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Redies</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2010.05.002</idno>
		<ptr target="https://doi.org/10.1016/j.visres.2010.05.002" />
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="1503" to="1509" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Scene inversion reveals distinct patterns of attention to semantically interpreted and uninterpreted features</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">229</biblScope>
			<biblScope unit="page">105231</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dynamic binding in a neural network for shape recognition</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Hummel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Biederman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="480" to="517" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Aesthetic preference for art can be predicted from a mixture of low-and high-level visual features</title>
		<author>
			<persName><forename type="first">K</forename><surname>Iigaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Wahle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tanwisuth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Doherty</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-021-01124-6</idno>
		<ptr target="https://doi.org/10.1038/s41562-021-01124-6" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="743" to="755" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Extension of Nakagawa &amp; Schielzeth&apos;s R2GLMM to random slopes models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods in Ecology and Evolution</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="944" to="946" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaplan</surname></persName>
		</author>
		<title level="m">The experience of nature: A psychological perspective</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">ppcor: An R package for a fast calculation to semi-partial correlation coefficients</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications for Statistical Applications and Methods</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="665" to="674" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Koffka</surname></persName>
		</author>
		<ptr target="https://psycnet.apa.org/record/1935-03991-000" />
		<title level="m">Principles of Gestalt psychology</title>
		<meeting><address><addrLine>Harcourt, Brace</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1935">1935</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">lmerTest package: Tests in linear mixed effects models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kuznetsova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Brockhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Ambiguities and conventions in the perception of visual art</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2008.06.010</idno>
		<ptr target="https://doi.org/10.1016/j.visres.2008.06.010" />
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="2143" to="2153" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Caring about carelessness: Participant inattention and its effects on research</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Maniaci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Rogge</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jrp.2013.09.008</idno>
		<ptr target="https://doi.org/10.1016/j.jrp.2013.09.008" />
	</analytic>
	<monogr>
		<title level="j">Journal of Research in Personality</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="61" to="83" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Vision: A computational investigation into the human representation and processing of visual information</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Priming, prototypicality, and preference</title>
		<author>
			<persName><forename type="first">C</forename><surname>Martindale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Moore</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-1523.14.4.661</idno>
		<ptr target="https://doi.org/10.1037/0096-1523.14.4.661" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="661" to="670" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Identifying careless responses in survey data</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Meade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Craig</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0028085</idno>
		<ptr target="https://doi.org/10.1037/a0028085" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="437" to="455" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Regularity of colour statistics in explaining colour composition preferences in art paintings</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nakauchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tamura</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-022-18847-9</idno>
		<ptr target="https://doi.org/10.1038/s41598-022-18847-9" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">14585</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Thinking outside the box: Rectilinear shapes selectively activate scene-selective cortex</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nasr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Echavarria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Tootell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="6721" to="6735" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Modeling the shape of the scene: A holistic representation of the spatial envelope</title>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1011139631724</idno>
		<ptr target="https://doi.org/10.1023/A:1011139631724" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="145" to="175" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Naming unrelated words predicts creativity</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nahas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chmoulevitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Cropper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Webb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">25</biblScope>
			<date type="published" when="2021">2021</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
	<note>Article e2022340118</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Common region: A new principle of perceptual grouping</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Schloss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sammartino</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-psych-120710-100504</idno>
		<ptr target="https://doi.org/10.1146/annurev-psych-120710-100504" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="77" to="107" />
			<date type="published" when="1992">1992. 2013</date>
		</imprint>
	</monogr>
	<note>Cognitive Psychology</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Understanding mid-level representations in visual processing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Peirce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Article 5</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Processing fluency and aesthetic pleasure: Is beauty in the perceiver&apos;s processing experience?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Reber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Winkielman</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15327957pspr0804_3</idno>
		<ptr target="https://doi.org/10.1207/s15327957pspr0804_3" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Review</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="364" to="382" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Rezanejad</surname></persName>
		</author>
		<title level="m">Medial measures for recognition, mapping and categorization</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
		<respStmt>
			<orgName>McGill University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Rezanejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Downs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wilder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jepson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Siddiqi</surname></persName>
		</author>
		<ptr target="https://openaccess.thecvf.com/content_CVPR_2019/html/Rezanejad_Scene_Categorization_From_Contours_Medial_Axis_Based_Salience_Measures_CVPR_2019_paper.html" />
		<title level="m">Scene categorization from contours: Medial axis based salience measures</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A computational and neural model of momentary subjective well-being</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Rutledge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Skandali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1407535111</idno>
		<ptr target="https://doi.org/10.1073/pnas.1407535111" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">33</biblScope>
			<biblScope unit="page" from="12252" to="12257" />
			<date type="published" when="2014">2014</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">What line drawings reveal about the visual brain</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sayim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cavanagh</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2011.00118</idno>
		<ptr target="https://doi.org/10.3389/fnhum.2011.00118" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">118</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The Aesthetic Responsiveness Assessment (AReA): A screening tool to assess individual differences in responsiveness to art in English and German</title>
		<author>
			<persName><forename type="first">W</forename><surname>Schlotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wallot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Omigie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Masucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoelzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Vessel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology of Aesthetics, Creativity, and the Arts</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="682" to="696" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Emotional responses to art: From collation and arousal to cognition and emotion</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Silvia</surname></persName>
		</author>
		<idno type="DOI">10.1037/1089-2680.9.4.342</idno>
		<ptr target="https://doi.org/10.1037/1089-2680.9.4.342" />
	</analytic>
	<monogr>
		<title level="j">Review of General Psychology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="342" to="357" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Curious objects: How visual complexity guides attention and engagement</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Firestone</surname></persName>
		</author>
		<idno type="DOI">10.1111/cogs.12933</idno>
		<ptr target="https://doi.org/10.1111/cogs.12933" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Article e12933</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Good exemplars of natural scene categories elicit clearer patterns than bad exemplars but not greater BOLD activity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Torralbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Caddigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Beck</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0058594</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0058594" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">58594</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Putting reward in art: A tentative prediction error account of visual art</title>
		<author>
			<persName><forename type="first">S</forename><surname>Van De Cruys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wagemans</surname></persName>
		</author>
		<idno type="DOI">10.1068/i0466aap</idno>
		<ptr target="https://doi.org/10.1068/i0466aap" />
	</analytic>
	<monogr>
		<title level="j">I-Perception</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1035" to="1062" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Impact of contour on aesthetic judgments and approachavoidance decisions in architecture</title>
		<author>
			<persName><forename type="first">O</forename><surname>Vartanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Navarrete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Fich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Leder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>ModroÃ±o</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nadal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rostrup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Skov</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1301227110</idno>
		<ptr target="https://doi.org/10.1073/pnas.1301227110" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="10446" to="10453" />
			<date type="published" when="2013">2013</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
	<note>Suppl. 2</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Beauty in the blink of an eye: The time course of aesthetic experiences</title>
		<author>
			<persName><forename type="first">S</forename><surname>Verhavert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wagemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Augustin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="84" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The default-mode network represents aesthetic appeal that generalizes across visual domains</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Vessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Isik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Belfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Stahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Starr</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1902650116</idno>
		<ptr target="https://doi.org/10.1073/pnas.1902650116" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">38</biblScope>
			<biblScope unit="page" from="19155" to="19164" />
			<date type="published" when="2019">2019</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Stronger shared taste for natural aesthetic domains than for artifacts of human culture</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Vessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Starr</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2018.06.009</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2018.06.009" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="page" from="121" to="131" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Scene preferences, aesthetic appeal, and curiosity</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Vessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Biederman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Brain, beauty, &amp; art: Essays bringing neuroaesthetics into focus</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Chatterjee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Cardilo</surname></persName>
		</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="61" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Reading scenes: How scene grammar guides attention and aids perception in real-world environments</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>VÃµ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-H</forename><surname>Boettcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Draschkow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.copsyc.2019.03.009</idno>
		<ptr target="https://doi.org/10.1016/j.copsyc.2019.03.009" />
	</analytic>
	<monogr>
		<title level="j">Attention &amp; Perception</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="205" to="210" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Skewed symmetry: A nonaccidental property used to perceive visual forms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wagemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="364" to="380" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Simple line drawings suffice for functional MRI decoding of natural scene categories</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Caddigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1015666108</idno>
		<ptr target="https://doi.org/10.1073/pnas.1015666108" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="9661" to="9666" />
			<date type="published" when="2011">2011</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The Mid-level Vision Toolbox for computing structural properties of real-world images</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Farzanfar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rezanejad</surname></persName>
		</author>
		<idno type="DOI">10.3389/.2023.1140723/abstract</idno>
		<ptr target="https://www.frontiersin.org/articles/10.3389/.2023.1140723/abstract" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">1140723</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Nonaccidental properties underlie human categorization of complex natural scenes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797613512662</idno>
		<ptr target="https://doi.org/10.1177/0956797613512662" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="851" to="860" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Why and how should cognitive science care about aesthetics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Wassiliwizky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Menninghaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="437" to="449" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Development and validation of brief measures of positive and negative affect: The PANAS scales</title>
		<author>
			<persName><forename type="first">D</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tellegen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1063" to="1070" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Local contour symmetry facilitates scene categorization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wilder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rezanejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Siddiqi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jepson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Walther</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2018.09.014</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2018.09.014" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="page" from="307" to="317" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
