<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Working Memory Content Is Distorted by Its Use in Perceptual Comparisons</title>
				<funder>
					<orgName type="full">Connaught New Researcher Award</orgName>
				</funder>
				<funder>
					<orgName type="full">Natural Sciences and Engineering Research Council</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Keisuke</forename><surname>Fukuda</surname></persName>
							<email>keisuke.fukuda@utoronto.ca</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Mississauga</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">April</forename><forename type="middle">E</forename><surname>Pereira</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Saito</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ty</forename><forename type="middle">Y</forename><surname>Tang</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Arizona State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hiroyuki</forename><surname>Tsubomi</surname></persName>
							<affiliation key="aff5">
								<orgName type="department">Department of Humanities</orgName>
								<orgName type="institution">University of Toyama</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gi-Yeul</forename><surname>Bae</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Arizona State University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Mississauga</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Working Memory Content Is Distorted by Its Use in Perceptual Comparisons</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">158D539082B2A9EAB1CA44DF2B019C24</idno>
					<idno type="DOI">10.1177/09567976211055375</idno>
					<note type="submission">Received 10/16/20; Revision accepted 9/22/21</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-05-20T20:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>working memory</term>
					<term>memory distortion</term>
					<term>individual differences</term>
					<term>open data</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many daily activities rely on our ability to maintain accurate mental representations of the immediate past to guide our behavior. For example, consider a Good Samaritan who witnesses a phone falling out of a passerby's pocket on a busy street. The Good Samaritan would look down to pick up the phone in hopes of returning it to its owner. After doing so, they would need to find the owner again by comparing their memory of the owner's appearance with the other people they see on the street. Past studies have demonstrated that working memory (WM) can actively maintain a small amount of task-relevant information (e.g., the owner's appearance) over a brief delay when the information is not perceptually present (e.g., while looking down on the street to pick up the phone; <ref type="bibr" target="#b19">Luck &amp; Vogel, 2013;</ref><ref type="bibr" target="#b20">Ma et al., 2014)</ref>. However, little is known as to whether WM remains intact as it is used for memoryguided perceptual comparisons.</p><p>Although one might assume that WM remains intact as it is used, past studies have shown that WM can be interfered with by subsequent perceptual inputs introduced during maintenance (e.g.,</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>within the focus of internal attention. Given that the intervening RSVP task used by <ref type="bibr" target="#b30">Teng and Kravitz (2019)</ref> drew attention away from WM maintenance, the memory distortion may be contingent on disruption of active WM maintenance <ref type="bibr" target="#b22">(Makovski et al., 2008;</ref><ref type="bibr" target="#b31">Wang et al., 2018)</ref>. It is also possible that the WM representation was not necessarily distorted but was occasionally replaced by the intervening stimulus instead (i.e., swap errors), making WM reports appear biased <ref type="bibr" target="#b6">(Bays et al., 2009)</ref>. Lastly, because previous studies did not measure the perceived similarity between WM and intervening stimuli, it is not known whether the interference was dictated by the physical similarity or perceived similarity between them.</p><p>We addressed these questions in the present study by having participants remember a single visual feature (i.e., color or shape) in WM and compare it with new stimuli. Therefore, the WM had to be actively maintained so that it could be compared with new stimuli.</p><p>In three experiments, we found that WM reports were distorted, especially when participants perceived the new stimuli as similar to the WM. Critically, we found that this similarity-induced memory bias was larger following perceived similarity than perceived dissimilarity of new stimuli, even after controlling for their physical similarity. We further validated the systematic effect of subjective similarity by demonstrating that memory biases induced by an initial similarity judgment were "canceled out" by an additional judgment that biased the WM in an opposing direction. Computational modeling revealed that the similarity-induced memory bias was better accounted for by representational integration between WM and perceptually similar input than by probabilistic swap errors. Thus, our findings reveal an overlooked window of vulnerability in WM and suggest a general mechanism that determines how a new perceptual input interacts with WM (e.g., <ref type="bibr" target="#b17">Kiyonaga et al., 2017;</ref><ref type="bibr" target="#b25">Rademaker et al., 2019;</ref><ref type="bibr" target="#b29">Sun et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments 1a and 1b</head><p>To examine the consequences of comparing WM with perceptual inputs, we had participants remember a simple stimulus (i.e., shape in Experiment 1a and color in Experiment 1b) and compare it with a new perceptual input (Fig. <ref type="figure" target="#fig_0">1</ref>). Subsequently, participants reported their memory of the original stimulus as precisely as possible. Here, we predicted that the WM report would be biased toward the new input, especially when the new input was subjectively similar to the WM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants. Related experiments examining the memory bias for orientation memory <ref type="bibr" target="#b24">(Rademaker et al., 2015)</ref> reported large effect sizes (Cohen's d &gt; 1.5). Because we used different stimuli, we anticipated a medium to large effect size (Cohen's d = 0.8). A power analysis (conducted in G*Power Version 3.1; <ref type="bibr" target="#b13">Faul et al., 2007)</ref> determined that at least 15 samples would be necessary to detect such an effect with a statistical power of .8. We recruited 16 participants (11 female; mean age = 23.2 years) for Experiment 1a and 16 participants (10 female; mean age = 22.6 years) for Experiment 1b. Participants provided informed consent, and the study was approved by the University of Toronto Research Ethics Board.</p><p>Apparatus, stimuli, and procedure. Stimuli were generated in MATLAB (The MathWorks, Natick, MA) using the Psychophysics Toolbox <ref type="bibr" target="#b8">(Brainard, 1997)</ref> and were presented at 60 Hz on an LCD monitor. Viewing distance was approximately 60 cm. The shape stimulus set used in Experiment 1a contained 360 shapes whose circular continuity was empirically validated <ref type="bibr" target="#b18">(Li et al., 2020)</ref>. The color stimuli used in Experiment 1b comprised 360 equally spaced color values sampled from Commission Internationale de l'Éclairage (CIE) L*a*b* space with a* centered at 20 and b* centered at 38 with a radius of 60. L* was set to 70.</p><p>Participants completed multiple trials in the baseline and perceptual-comparison conditions (Fig. <ref type="figure" target="#fig_0">1b</ref>). In the baseline condition, participants were presented with one stimulus-either a shape (3.8° × 3.8°) or a colored circle (5.2° diameter) for 800 ms. After a 3,200-ms retention interval, participants were presented with a circular stimulus wheel (15.4° diameter). For the shape task, the stimulus wheel was composed of 18 equidistant</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statement of Relevance</head><p>Imagine a person who witnesses a hit-and-run traffic accident. When the witness tries to identify the license plate number of the car involved, a bus occludes their sight of the car. When the bus passes, they need to find the car by comparing the cars they see now with the memory of the car that committed the accident. In doing so, they might assume that their memory of the car remains intact as it is compared with the cars they see now. However, the present study shows that this assumption is simply not valid: As a memory representation of the immediate past (i.e., working memory) is compared with new perceptual information, the memory report becomes systematically biased toward perceptually similar input. Thus, our findings reveal an overlooked vulnerability in working memory and suggest that the witness may misreport the license plate of a similar, but different, car to the police. shapes (20° apart in the shape space). For the color task, it was a color wheel composed of the 360 colors (1° per color). To report the remembered stimulus, they first selected an item that best matched the original stimulus from the stimulus wheel by rotating a line indicator using the left and right arrow keys on the keyboard. After the indicator pointed toward the desired item, participants pressed the space bar to confirm the selection. The selected item then appeared at the center of the screen for optional refinements using the left and right arrow keys. When satisfied, participants indicated their confidence in their report (1 = high confidence, 2 = low confidence, 3 = no confidence) by pressing one of three keys on the keyboard. No time limit was imposed on the memory report in order to emphasize accuracy.</p><p>In the perceptual-comparison condition, a probe stimulus was presented 800 ms after the offset of the original stimulus, and participants indicated whether it looked similar or dissimilar to the original stimulus by pressing a key. The probe stayed on the screen for 1,600 ms. The probe was randomly sampled from 16° to 105° away from the original stimulus on each trial. After an 800-ms delay following the probe presentation, participants reported the original memory item as in the baseline condition. Participants performed 12 experimental blocks, and each block contained 12 baseline and 36 perceptual-comparison trials.</p><p>Analysis. For each trial, a signed response offset was calculated in relation to the probe. A positive sign indicated a response offset toward the probe (for the distribution of raw response offsets, see the supplementary material available at <ref type="url" target="https://osf.io/79kbm/">https://osf.io/79kbm/</ref>). For the baseline trials, the sign of the response offset was randomly assigned. To quantify the magnitude of the bias, we computed the mean of the signed response offsets for each condition. We focused on trials with high-confidence "Similar or Not?" "Remember" "Remember" "Recall" "Adjust"  In each condition, participants were first presented with a target shape that they attempted to remember across a brief maintenance interval. Following the maintenance interval, participants reported the target shape by rotating a line indicator to select from a continuous wheel. Participants then adjusted their selection, if desired, to best match their memory before submitting their report with a confidence rating. In the perceptual-comparison condition, participants also performed a perceptual comparison on a probe shape that was presented during the maintenance interval by indicating whether the probe shape was similar or dissimilar to the target shape. The color task was identical to the shape task except for the stimulus type and the stimulus wheel. memory reports (&gt; 68% of trials, or &gt; 83 trials, in all conditions; for the same pattern of results with all trials included, see the supplementary material available at <ref type="url" target="https://osf.io/79kbm/">https://osf.io/79kbm/</ref>).</p><p>To isolate the effect of perceived similarity on the memory bias, we first identified the probe distances that resulted in both similar and dissimilar judgments on separate trials within subjects (ambivalent probe distances). For each ambivalent probe distance, we calculated the mean bias magnitude following similar and dissimilar judgments separately. The mean bias magnitudes following similar and dissimilar judgments were then averaged across all ambivalent probe distances. This procedure isolated the effect of perceived probe similarity (indicated by participants' judgments) on the bias magnitude while equating the effect of physical probe similarity (determined by the sampling procedure).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Both shape (Experiment 1a) and color (Experiment 1b) memory reports exhibited an attraction bias (&gt; 0°) toward the probe when the probe was judged to be similar to the memory item-shape: M = 7.61°, t( <ref type="formula">15</ref>  <ref type="figure"></ref>and<ref type="figure" target="#fig_3">2f</ref>). We also found some evidence for an attraction bias when the probe was judged to be dissimilar to the original memory itemshape: M = 1.49°, t(15) = 1.48, p = .159, 95% CI = [-0.65°, 3.64°], Cohen's d = 0.37; color: M = 3.03°, t(15) = 2.93, p = .01, 95% CI = [0.83°, 5.12°], Cohen's d = 0.73-but the bias magnitude was significantly smaller than when the probe was judged to be similar-similar shape versus dissimilar shape: M = 5.42°, t(15) = 3.14, p = .007, 95% CI = [1.74°, 9.10°], Cohen's d = 0.78; similar color versus dissimilar color: M = 5.11°, t(15) = 2.98, p = .009, 95% CI = [1.45°, 8.77°], Cohen's d = 0.74. The trials with ambivalent probe distances (shape task: mean range of probe distance = 20.1°-97.7°; color task: mean range of probe distance = 19.3°-97.6°) produced larger attraction biases when the probes were perceived to be similar rather than dissimilar to the original memory itemsshape task: ΔM = 6.19°, t( <ref type="formula">15</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>Experiment 1 demonstrated that WM reports were biased when WM was directly compared with a subjectively similar probe. In Experiment 2, we sought to replicate this similarity-induced memory bias in a modified paradigm. More precisely, participants clicked a mouse to report WM and performed two-alternative forced-choice judgments for perceptual comparisons (Fig. <ref type="figure">3</ref>). More importantly, considering that many behaviors rely on the maintenance of unbiased WM representations, we examined whether the similarityinduced memory bias can be corrected by biasing WM in the opposite direction in a subsequent perceptual judgment. If the bias can be corrected by subsequent perceptual judgments, then its magnitude should be smaller when the similar probes in two consecutive judgments were sampled from opposing directions (i.e., clockwise and counterclockwise) than from the same direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants. On the basis of the results of Experiment 1 (Cohen's d &gt; 0.73), we anticipated a medium to large effect size (Cohen's d = 0.73). A power analysis (conducted in G*Power Version 3.1; <ref type="bibr" target="#b13">Faul et al., 2007)</ref> determined that 22 samples were necessary to detect such an effect with a statistical power of .9. After providing written informed consent to protocols approved by the University of Toronto Research Ethics Board, 32 individuals (24 female; mean age = 19.3 years) participated. The data from four participants were removed because they did not complete the experiment (n = 1), failed to follow instructions (n = 1), or too infrequently made high-confidence memory reports (i.e., &lt; 15% for the baseline conditions; n = 2). As a result, 28 participants' data were analyzed.</p><p>Procedure. The procedure was similar to that of Experiment 1. Participants performed four blocks of the color task and four blocks of the shape task in a pseudorandomized order. In the baseline conditions (Fig. <ref type="figure">3a</ref>), participants remembered the original stimulus over a 500-ms (short delay) or a 5,500-ms (long delay) interval. Two delays were introduced to establish the baseline responseoffset distributions for the perceptual-comparison conditions (for an example of the effect of delay on WM precision, see <ref type="bibr" target="#b26">Rademaker et al., 2018)</ref>. After the delay, participants used a mouse to click on an item that best matched the original stimulus, fine-tuned their response using key presses, and then reported their confidence as in Experiment 1.</p><p>In the perceptual-comparison conditions, participants performed two intervening perceptual comparisons 500 ms after the original stimulus offset. Because subjective similarity of a given perceptual probe varied across trials, we controlled the subjective similarity of a physically similar probe (e.g., 30° away from the target) by presenting it together with a physically dissimilar probe (180° away from the similar probe) and had participants identify the more similar probe from "Confidence?" "Confidence?" "Confidence?" Fig. <ref type="figure">3</ref>. Trial procedures and probe-sampling procedures for Experiment 2. Trial procedures from the color task (a) are shown separately for the baseline (short delay, long delay) and experimental (same-side probe, opposite-side probe) conditions. In each condition, participants were first presented with a target color that they attempted to remember across a brief maintenance interval. Following the maintenance interval, participants reported the target color by clicking on a continuous wheel. Participants then adjusted their selection, if desired, to best match their memory before submitting their report with a confidence rating. In the experimental conditions, participants also performed two consecutive perceptual comparisons during the maintenance interval. In each comparison, participants selected which of two simultaneously presented probe colors was more similar to the target color. The sampling of the similar probes is depicted in (b). In the same-side-probe condition, the similar probes were both sampled from the same side of the circular color space relative to the target. In the opposite-side-probe condition, the similar probes were sampled from opposite sides of the target. The dissimilar probes were sampled 180° from the similar probes in both pairs. The shape task was identical to the color task except for the stimulus type and the stimulus wheel.</p><p>the pair (Fig. <ref type="figure">3</ref>). In each comparison, two probes were presented on each side of the screen (5.2° from the center of the screen), and they reported which probe looked more similar to the original stimulus by pressing either the left or right arrow key. One of the probes was randomly sampled from ±16° to 45° away from the original stimulus (i.e., similar probe). The other probe was sampled 180° away from the similar probe (i.e., dissimilar probe). The two probes remained on the screen for 2,000 ms regardless of the report. After the offset of the first pair of probes, a 500-ms delay followed, and the second pair of probes was presented for another similarity judgment (2,000 ms). After another 500-ms delay, participants reported the original stimulus in the same manner as the baseline conditions.</p><p>The two perceptual-comparison conditions differed in how the similar probes were sampled (Fig. <ref type="figure">3b</ref>). In the same-side-probe condition, similar probes in each pair were sampled from the same side of the stimulus space relative to the memory item. In the opposite-sideprobe condition, similar probes in each pair were sampled from opposite sides of the stimulus space relative to the memory item. Participants completed 40 trials for each condition in a pseudorandomized order.</p><p>Analysis. For each trial, a signed response offset was calculated as the response offset in the direction of the similar probe in the first probe pair (for the distribution of raw response offsets, see the supplementary material available at <ref type="url" target="https://osf.io/79kbm/">https://osf.io/79kbm/</ref>). Thus, a positive value indicates a response offset toward the first similar probe. For the baseline trials, the sign was randomly assigned. The magnitude of the memory bias was quantified as the mean of the signed response offsets for each condition. We focused on trials with high-confidence memory reports (&gt; 58% of trials, or &gt; 25 trials, in all conditions; for the same pattern of results with all trials included, see the supplementary material available at <ref type="url" target="https://osf.io/79kbm/">https://osf.io/79kbm/</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Accuracy in the perceptual-comparison conditions was near ceiling (shape task: M = 0.94, SD = 0.05 for the same-side probe, M = 0.89, SD = 0.07 for the oppositeside probe; color task: M = 0.95, SD = 0.04 for the same-side probe, M = 0.92, SD = 0.04 for the oppositeside probe), thus confirming that subjective similarity of the probe was successfully controlled. As can be seen from Figures <ref type="figure">4a</ref> and<ref type="figure">4c</ref>, the same-side-probe condition and the opposite-side-probe condition exhibited differential signed response offsets. The mean signed response offset for the same-side-probe condition exhibited a significant positive signed offset-shape task: M = 5.64°, t(27) = 7.17, p &lt; .001, 95% CI = [4.02°, 7.25°], Cohen's d = 1.36 (Fig. <ref type="figure">4b</ref>); color task: M = 6.11°, t(27) = 6.30, p &lt; .001, 95% CI = [4.12°, 8.09°], Cohen's d = 1.19 (Fig. <ref type="figure">4d</ref>)-indicating that the memory reports were attracted toward the similar probes. In contrast, the mean signed response offset for the opposite-sideprobe condition exhibited a nonsignificant negative signed offset for shape, M = -0.36°, t(27) = -0.78, p = .441, 95% CI = [-1.32°, 0.59°], Cohen's d = -0.15, and a small but significant negative signed offset for color, M = -1.29°, t(27) = 2.20, p = .037, 95% CI = [-2.49°, -0.09°], Cohen's d = -0.42, indicating that the memory reports were, if anything, biased away from the first similar probe. The magnitude of the bias (i.e., absolute values) for the same-side-probe condition was statistically greater than the magnitude of the bias for the opposite-side-probe conditions-shape task: ΔM = 5.27°, t( <ref type="formula">27</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modeling of the Similarity-Induced Memory Bias</head><p>Experiment 2 not only replicated the similarity-induced memory bias in a modified paradigm but also demonstrated that it could be corrected by an additional similarity judgment. One important question remains regarding the computational mechanism underlying the similarity-induced memory bias. One possibility is that a WM is integrated with a probe if the probe is subjectively similar to the WM (Fig. <ref type="figure">5a</ref>; for a similar conceptualization, see <ref type="bibr" target="#b12">Dubé et al., 2014)</ref>. This integration can be accomplished via the formation of a joint density of the two, resulting in a biased WM representation toward a similar probe <ref type="bibr" target="#b5">(Bae et al., 2015)</ref>. Alternatively, the two representations may be independently represented in WM, but participants may occasionally report the probe item instead of the memory item by mistake, especially when the probe is similar to the memory item (Fig. <ref type="figure">5b</ref>). Importantly, this mixture density can also produce a shifted response distribution depending on the frequency of the mistake (see the supplementary material available at <ref type="url" target="https://osf.io/79kbm/">https://osf.io/79kbm/</ref>). We compared these competing models by fitting them to the data obtained in Experiment 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Detailed descriptions of each model can found in the supplementary material (<ref type="url" target="https://osf.io/79kbm/">https://osf.io/79kbm/</ref>). Here, we provide a summary.</p><p>For both the joint-density model and the mixturedensity model, we assumed that both the memory (X M ) and the probe (X P ) representations follow von Mises probe distances) and the average simulated response errors across all the simulated responses.</p><p>The mixture-density model (Equation <ref type="formula">4</ref>) combines the two distributions via a mixture parameter (a). Namely, this model assumes that the final memory reports are either memory-based or probe-based. The proportion of each is determined by the mixture parameter:</p><formula xml:id="formula_0">p X S S p X S p X S Mix M P M M P P 1 | , | | ( )= ( )+ - ( ) ( ) α α (4)</formula><p>All the other aspects of this model were identical to the joint-density model except that this model has an additional free parameter (a). Alpha was set to vary between 0 (0% memory-based reports) and 1 (100% memory-based reports).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Figure <ref type="figure" target="#fig_5">6a</ref> shows simulated response-offset distributions from the joint-density model and the mixture-density model along with observed human data (Experiments 1a and 1b). The peak of the simulated response distribution from the joint-density model was shifted positively, as in the human data. However, the distributions from the mixture-density model were positively skewed without this shift. This result suggests that the observed biases in the human data were more likely to be driven by representational integration than probabilistic confusion. Formal model comparisons using measurements of the sum of log-likelihood, Akaike information criterion, and Bayesian information criterion unanimously indicated Probability Probe Item p(x P  s P , κ P )</p><formula xml:id="formula_1">Joint Density p(x M  s M , κ M )p(x P  s P , κ P ) a p(x M  s M , κ M ) X X X X X X Memory Item p(x M  s M , κ M ) Probability p(x P  s P , κ P ) αp(x M  s M , κ M ) + (1 -α)p(x P  s P , κ P ) b</formula><p>Mixture Density Probe Item Memory Item Fig. <ref type="figure">5</ref>. Two competing models of similarity-induced memory bias. In the joint-density model (a), noisy representation of a working memory item (X M ) is assumed to follow a von Mises distribution centered at the sample stimulus (S M , dashed black vertical line) with some precision (κ M , left). Noisy representation of a probe item is also assumed to follow a von Mises distribution centered at the probe stimulus (S P , dashed blue vertical line) with some precision (κ P , center). When observers decide that the memory item and the probe item are perceptually similar, then the two items are integrated to produce a joint distribution (shown in red, right). As a result, the mean of the joint distribution is biased toward the probe item, as indicated by the dashed red vertical line. In the mixture-density model (b), the initial memory representation and the probe representation are assumed to follow von Mises distributions as in the joint-density model. However, this model assumes that some proportion of the memory reports is based on the probe representation. This can be accounted for by the mixture parameter (a). The original memory representation in this model is not biased, but the mean of the mixture distribution can be shifted toward the probe item (dashed red vertical line). Note that the schematics for both models depict the corresponding representational consequences for one trial with a given probe distance. For a simulation of multiple trials with varying probe distances as tested in the actual experiments, see the supplementary material available at <ref type="url" target="https://osf.io/79kbm/">https://osf.io/79kbm/</ref>. that the joint-density model was preferred (Table <ref type="table" target="#tab_1">1</ref>). To provide additional support for the joint-density model, we computed the correlation between the simulated and observed bias magnitudes as a function of the 18 discretized probe distances. First, we found that both the observed and simulated bias magnitudes increased as the physical probe distance increased (observed: r = .66, p &lt; .002 for color; r = .55, p = .018 for shape; simulated: r = .94, p &lt; .001 for color; r = .94, p &lt; .001 for shape). More importantly, the simulated bias magnitudes predicted the observed bias magnitudes for both stimuli, even though the model was not fitted separately for each distance (r = .75, p &lt; .001 for color; r = .45, p = .037 for shape; Fig. <ref type="figure" target="#fig_5">6b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3</head><p>We found convincing evidence that representational integration likely underlies the similarity-induced memory bias. One novel prediction of the joint-density model is that individuals with lower WM precision should exhibit a larger similarity-induced memory bias because of greater representational overlap between WM and probe representations (Fig. <ref type="figure">5a</ref>; for a simulation, see the supplementary material available at <ref type="url" target="https://osf.io/79kbm/">https:// osf.io/79kbm/</ref>). To test this, we examined the correlation between individuals' WM precision and the magnitude of the similarity-induced memory bias using a variant of the paradigm employed in Experiment 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants. A power analysis based on the effect size obtained in Experiment 2 (r &lt; -.32 between WM precision and the bias magnitude) determined that at least 99 samples would be necessary to detect such an effect with a statistical power of .9. The informed-consent procedure was the same as in previous experiments, and 124 individuals (97 female; mean age = 18.6 years) participated.</p><p>The data from 14 participants were removed on the basis of the same exclusion criteria used in Experiment 2.</p><p>Procedure. The experiment was identical to Experiment 2 except for the following. There was one experimental condition with one intervening similarity judgment and one delay-matched baseline condition. The stimulus onset asynchrony between the memory item and the response wheel was set to 4,000 ms for both conditions. Participants performed four blocks consisting of 15 trials each of the baseline and experimental conditions (30 trials per block) in a pseudorandomized order.</p><p>Analysis. Memory precision was estimated by fitting the concentration parameter (κ) of a von Mises distribution to the response offsets for high-confidence reports in the baseline condition (&gt; 69% of trials, or &gt; 41 trials) to eliminate the effect of guessing. For the bias estimation, we focused on trials with high-confidence response offsets (&gt; 62% of trials, or &gt; 37 trials; see the supplementary material available at <ref type="url" target="https://osf.io/79kbm/">https://osf.io/79kbm/</ref>) for which participants successfully identified the similar probe. The precision estimates were then correlated with the bias estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Participants' accuracy in the perceptual-comparison task was near ceiling (proportion of correct responses: M = .96, SD = .03 for the shape task; M = .97, SD = .03 for the color task), and we replicated the similarityinduced memory bias (see the supplementary material available at <ref type="url" target="https://osf.io/79kbm/">https://osf.io/79kbm/</ref>). More importantly, participants with high visual WM precision exhibited a smaller memory bias than those with low precision, r(107) = -.37, p &lt; .001 for color; r(105) = -.31, p = .001 for shape (Fig. <ref type="figure" target="#fig_6">7</ref>), as predicted by the joint-density model. This pattern was not changed when analyses were conducted with outliers that were initially excluded, r(108) = -.37, p &lt; .001 for color; r(108) = -.33, p &lt; .001 for shape. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>The present study revealed that the use of WM in perceptual comparisons results in a systematic memory bias, thus demonstrating that WM is susceptible to interference even without task-irrelevant disruptions of active maintenance. This memory bias was particularly large when a visual input was subjectively similar to the WM. Model comparisons showed that this similarity-induced memory bias was better characterized as representational integration between the WM and a subjectively similar input (i.e., joint-density model) than probabilistic confusion between the two (i.e., mixture-density model). We also provided empirical support of this representationalintegration account by demonstrating that individuals with lower WM precision exhibited a larger memory bias than those with higher precision. One may argue that the similarity-induced memory bias is solely determined by WM precision, thus questioning the causal role of perceptual comparisons in modulating the bias. More precisely, low-precision WM may be susceptible to greater stimulus-driven interference by a perceptual input, which may also result in perceived similarity between them. In other words, perceived similarity between WM and a perceptual input may be a mere by-product of low WM precision. The present study alone does not provide a strong test for this possibility because we did not measure WM precision prior to the perceptual comparison. However, we tested this possibility in a follow-up study <ref type="bibr" target="#b28">(Saito et al., 2020)</ref> by having participants either ignore or compare intervening perceptual input with a WM representation in different experimental blocks. We found that identical intervening inputs induced a larger memory bias in compare blocks than in ignore blocks, and more importantly, we found that WM precision for the baseline condition (i.e., no intervening input) in both block types was statistically indistinguishable. These results demonstrated that the variability in WM precision alone could not explain the memory bias and, thus, implicated a causal role of similarity judgments in modulating the similarity-induced memory bias.</p><p>The temporal stability of the similarity-induced memory bias also merits further discussion. <ref type="bibr">Wang and colleagues (2018)</ref> demonstrated that a WM representation can be distorted by similar perceptual inputs only when they appear before attention returns to the WM from a secondary task. Although we did not use any secondary task to distract attention away from the original WM representation prior to the onset of the similar probe, it is possible that the similarity-induced memory bias happens only when a WM is compared with a similar input too soon after encoding. We tested this possibility in a follow-up study <ref type="bibr" target="#b27">(Saito et al., 2021)</ref> by directly manipulating the interval between memory encoding and similarity judgments. Here, we replicated the similarity-induced memory bias even when participants performed a similarity judgment between a perceptual input and a memory encoded 24 hr before by retrieving it into WM <ref type="bibr" target="#b0">(Atkinson &amp; Shiffrin, 1968;</ref><ref type="bibr" target="#b10">Cowan, 1999;</ref><ref type="bibr" target="#b16">Fukuda &amp; Woodman, 2017)</ref>. Furthermore, when participants retrieved a memory again 24 hr after a similarity judgment, the memory reports remained biased. This temporal stability of the similarity-induced memory bias is in stark contrast to the memory bias caused by a temporary disruption of active WM maintenance, thus suggesting that it is the direct usage of WM in perceptual comparisons that "locks in" the bias. Future studies will be necessary to determine the neural mechanisms that underlie these two distinct forms of memory biases.</p><p>Our representational-integration account of WM bias might offer a unifying explanation for other WM biases reported in the literature. For instance, past visual experiences can bias subsequently encoded WM-a phenomenon known as serial dependence in visual perception <ref type="bibr" target="#b3">(Bae &amp; Luck, 2019</ref><ref type="bibr">, 2020;</ref><ref type="bibr" target="#b9">Cicchini et al., 2018;</ref><ref type="bibr" target="#b11">Czoschke et al., 2019;</ref><ref type="bibr" target="#b14">C. Fischer et al., 2020;</ref><ref type="bibr" target="#b15">J. Fischer &amp; Whitney, 2014;</ref><ref type="bibr" target="#b17">Kiyonaga et al., 2017)</ref>. Although our finding that WM is biased by subsequently perceived inputs is different from serial dependence in the direction of causality, serial dependence might also be explained by the representational integration triggered by the subjective similarity between lingering WM representations of past visual experience and current WM representations.</p><p>Lastly, future studies should examine at what stage the similarity-induced memory bias occurs. One possibility is that the memory bias might be introduced to WM as soon as its similarity to a novel input is perceived. Alternatively, the WM might stay intact at the time of the perceptual comparison, and the bias might be introduced at the time of memory report. To tease apart these two hypotheses, future studies should incorporate neural-decoding approaches <ref type="bibr" target="#b1">(Bae, 2021;</ref><ref type="bibr" target="#b2">Bae &amp; Luck, 2018;</ref><ref type="bibr" target="#b25">Rademaker et al., 2019)</ref> to track the content of WM as it is maintained, compared with a perceptual input, and eventually reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transparency</head><p>Action Editor: Barbara Knowlton Editor: Patricia J. Bauer</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Stimulus spaces and example trial procedures from Experiments 1a and 1b. The stimulus spaces used for Experiments 1a (shape task) and 1b (color task) are shown in (a). Trial procedures from the shape task (b) are shown separately for the baseline and perceptualcomparison conditions.In each condition, participants were first presented with a target shape that they attempted to remember across a brief maintenance interval. Following the maintenance interval, participants reported the target shape by rotating a line indicator to select from a continuous wheel. Participants then adjusted their selection, if desired, to best match their memory before submitting their report with a confidence rating. In the perceptual-comparison condition, participants also performed a perceptual comparison on a probe shape that was presented during the maintenance interval by indicating whether the probe shape was similar or dissimilar to the target shape. The color task was identical to the shape task except for the stimulus type and the stimulus wheel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>) = 4.70, p &lt; .001, 95% confidence interval (CI) = [4.28°, 10.94°], Cohen's d = 1.18 (Figs. 2a and 2b); color: M = 8.14°, t(15) = 5.47, p &lt; .001, 95% CI = [4.97°, 11.32°], Cohen's d = 1.37 (Figs. 2e</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>) = 3.01, p = .009, 95% CI = [1.81°, 10.58°], Cohen's d = 0.75 (Figs. 2c and 2d); color task: ΔM = 10.92°, t(15) = 4.50, p &lt; .001, 95% CI = [5.75°, 16.08°], Cohen's d = 1.13 (Figs. 2g and 2h).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Results of Experiments 1a (top row) and 1b (bottom row). Probability distributions of signed response offsets for high-confidence (HC) reports (a, e) are shown for the baseline condition and for similar and dissimilar probe judgments in the perceptual-comparison condition. For demonstration purposes, the response proportion for a given signed response offset was computed by calculating the mean response proportion across a 30° window centered around the signed response offset. Positive offsets indicate memory bias toward the first similar probe. The broken lines indicate within-subjects standard errors of the mean. Bias magnitude for HC memory reports (b, f) is shown for similar (pink) and dissimilar (blue) probe judgments. In each violin plot, the thick horizontal line indicates the mean across participants, and the width of the violin indicates the density of the data. Positive values indicate memory bias toward the probe. Probability distributions of signed response offsets for HC reports for ambivalent probe trials (c, g) are shown for the baseline condition and for similar and dissimilar probe judgments in the perceptual-comparison condition. Bias magnitude for HC memory reports for ambivalent probe trials (d, h) is shown for similar (pink) and dissimilar (blue) probe judgments. In each violin plot, the thick horizontal line indicates the mean across participants, and the width of the violin indicates the density of the data. Positive values indicate memory bias toward the probe.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>) = 7.46, p &lt; .001, 95% CI = [3.82°, 6.72°], Cohen's d = 1.41; color task: ΔM = 4.82°, t(27) = 3.88, p &lt; .001, 95% CI = [2.27°, 7.37°], Cohen's d = 0.73.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Observed and simulated memory bias in Experiments 1a (top row) and 1b (bottom row). Probability distributions of signed response errors (a) are shown separately for responses of human participants, predictions of the best-fitting joint-density model, and predictions of the best-fitting mixture-density model for each experiment. Correlations of bias magnitudes (b) between the simulated responses from the joint-density model and the observed responses from human participants in the shape and color tasks are shown for each of the 18 probe distances in each experiment. Positive values indicate a bias toward the probe item. The size of the dots represents the discretized physical distance of the probe (smaller dots = closer probes, larger dots = further probes). Vertical error bars indicate ±1 bootstrapped standard error of the simulated responses. Horizontal error bars indicate ±1 bootstrapped standard error of human data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Results of the color task and shape task in Experiment 3. Each scatterplot depicts the relationship between bias for high-confidence (HC) reports and HC memory precision. Circles indicate individual participant data. Crosses indicate participant data excluded from the correlation as outliers. The solid lines indicate the best-fitting regressions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Model-Fit Comparisons for Experiments 1a and 1b</figDesc><table><row><cell>Experiment and model</cell><cell>∑ log-likelihood</cell><cell>AIC</cell><cell>BIC</cell></row><row><cell>Experiment 1a: shape</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Joint density (κ P )</cell><cell>-179.7096</cell><cell>391.4191</cell><cell>482.6021</cell></row><row><cell>Mixture density (a, κ P )</cell><cell>-294.6754</cell><cell>653.3508</cell><cell>835.7167</cell></row><row><cell>Experiment 1b: color</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Joint density (κ P )</cell><cell>-301.0448</cell><cell>634.0897</cell><cell>723.0092</cell></row><row><cell>Mixture density (a, κ P )</cell><cell>-476.1254</cell><cell>1,016.251</cell><cell>1,194.09</cell></row><row><cell cols="3">Note: Free parameters are given in parentheses (κ P = precision of probe</cell><cell></cell></row><row><cell cols="4">representation; a = mixture parameter). Boldface indicates the preferred model. AIC =</cell></row><row><cell cols="3">Akaike information criterion; BIC = Bayesian information criterion.</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank <rs type="person">Steven J. Luck</rs> for the constructive comments on the manuscript for this article.</p></div>
			</div>
			<div type="funding">
<div><head>Funding</head><p>This research was supported by the <rs type="funder">Natural Sciences and Engineering Research Council</rs> and the <rs type="funder">Connaught New Researcher Award</rs>.</p></div>
<div><head>Open Practices</head><p>All data have been made publicly available via OSF and can be accessed at <ref type="url" target="https://osf.io/5v7sg/">https://osf.io/5v7sg/</ref>. The design and analysis plans for the experiments were not preregistered.</p><p>This article has received the badge for Open Data. More information about the Open Practices badges can be found at <ref type="url" target="http://www.psychologicalscience.org/publications/badges">http://www.psychologicalscience.org/publications/ badges</ref>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>distributions (denoted by φ) centered at the stimulus value (S M , S P ) with some precision (κ M , κ P ):</p><p>p X S X S</p><p>When the probe item (Equation <ref type="formula">2</ref>) is perceived to be similar to the memory item (Equation <ref type="formula">1</ref>), the jointdensity ( JD) model integrates the two representations in the following manner:</p><p>The joint-density model (Equation <ref type="formula">3</ref>) has four parameters. The two parameters for the center of the memory and the probe distributions were set by the actual stimulus values (S M , S P ). The precision parameter for the memory item (κ M ) was obtained by fitting a standard WM model <ref type="bibr" target="#b32">(Zhang &amp; Luck, 2008)</ref> to response offsets in the baseline condition in Experiment 2. However, we fitted the precision for the probe item within the model (κ P ). Thus, the joint-density model has only one free parameter.</p><p>We fitted the joint-density model to each trial and each participant separately for Experiments 1a and 1b data sets. We used only high-confidence memory reports to avoid contamination by guessing or lapses of attention. On a given trial for a given participant, we constructed a joint-density distribution using S M and S P for that trial and κ M for the participant and fitted the model by finding a probe precision (κ P ) that minimized the difference between the average human response error collapsed across all the trials (including all the Author Contributions K. Fukuda, A. E. Pereira, and H. Tsubomi designed the study. A. E. Pereira and J. M. Saito collected the data. K. Fukuda analyzed the data. G.-Y. Bae conducted the modeling analysis. All the authors wrote the manuscript and approved the final manuscript for submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflicting Interests</head><p>The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Human memory: A proposed system and its control processes</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Shiffrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The psychology of learning and motivation: Advances in research and theory</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Spence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Spence</surname></persName>
		</editor>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1968">1968</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="89" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural evidence for categorical biases in location and orientation representations in a working memory task</title>
		<author>
			<persName><forename type="first">G.-Y</forename><surname>Bae</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2021.118366</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2021.118366" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">240</biblScope>
			<biblScope unit="page">118366</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dissociable decoding of spatial attention and working memory from EEG oscillations and sustained potentials</title>
		<author>
			<persName><forename type="first">G.-Y</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Luck</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.2860-17.2017</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.2860-17.2017" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="409" to="422" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reactivation of previous experiences in a working memory task</title>
		<author>
			<persName><forename type="first">G.-Y</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Luck</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797619830398</idno>
		<ptr target="https://doi.org/10.1177/0956797619830398" />
	</analytic>
	<monogr>
		<title level="j">Psycho logical Science</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="587" to="595" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Serial dependence in vision: Merely encoding the previous-trial target is not enough</title>
		<author>
			<persName><forename type="first">G.-Y</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Luck</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-019-01678-7</idno>
		<ptr target="https://doi.org/10.3758/s13423-019-01678-7" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="293" to="300" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Why some colors appear more memorable than others: A model combining categories and particulars in color working memory</title>
		<author>
			<persName><forename type="first">G.-Y</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Olkkonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Allred</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Flombaum</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000076</idno>
		<ptr target="https://doi.org/10.1037/xge0000076" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="744" to="763" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The precision of visual working memory is set by allocation of a shared resource</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Catalao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Husain</surname></persName>
		</author>
		<idno type="DOI">10.1167/9.10.7</idno>
		<ptr target="https://doi.org/10.1167/9.10" />
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Masking of spatial frequency in visual memory depends on distal, not retinal, frequency</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cortese</surname></persName>
		</author>
		<idno type="DOI">10.1016/0042-6989(95)00085-e</idno>
		<ptr target="https://doi.org/10.1016/0042-6989(95)00085-e" />
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="233" to="238" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Psychophysics Toolbox</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Brainard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spatial Vision</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="433" to="436" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The functional role of serial dependence</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Cicchini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mikellidou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Burr</surname></persName>
		</author>
		<idno type="DOI">10.1098/rspb.2018.1722</idno>
		<ptr target="https://doi.org/10.1098/rspb.2018.1722" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">285</biblScope>
			<biblScope unit="page">20181722</biblScope>
			<date type="published" when="1890">2018. 1890</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An embedded-processes model of working memory</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cowan</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9781139174909.006</idno>
		<ptr target="https://doi.org/10.1017/CBO9781139174909.006" />
	</analytic>
	<monogr>
		<title level="m">Models of working memory: Mechanisms of active maintenance and executive control</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Miyake</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Shah</surname></persName>
		</editor>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="62" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Two types of serial dependence in visual working memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Czoschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Beitner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bledowski</surname></persName>
		</author>
		<idno type="DOI">10.1111/bjop.12349</idno>
		<ptr target="https://doi.org/10.1111/bjop.12349" />
	</analytic>
	<monogr>
		<title level="j">British Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="256" to="267" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Similarity-based distortion of visual short-term memory is due to perceptual averaging</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dubé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Kahana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sekuler</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2013.12.016</idno>
		<ptr target="https://doi.org/10.1016/j.visres.2013.12.016" />
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="8" to="16" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">G*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences</title>
		<author>
			<persName><forename type="first">F</forename><surname>Faul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Erdfelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-G</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="175" to="191" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Context information supports serial dependence of multiple visual objects across memory episodes</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Czoschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rahm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bledowski</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-020-15874-w</idno>
		<ptr target="https://doi.org/10.1038/s41467-020-15874-w" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1932">2020. 1932</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Serial dependence in visual perception</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whitney</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.3689</idno>
		<ptr target="https://doi.org/10.1038/nn.3689" />
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="738" to="743" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Visual working memory buffers information retrieved from visual long-term memory</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fukuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Woodman</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1617874114</idno>
		<ptr target="https://doi.org/10.1073/pnas.1617874114" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="5306" to="5311" />
			<date type="published" when="2017">2017</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Serial dependence across perception, attention, and memory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kiyonaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Scimeca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bliss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whitney</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2017.04.011</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2017.04.011" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="493" to="497" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The validated circular shape space: Quantifying the visual similarity of shape</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Barense</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000693</idno>
		<ptr target="https://doi.org/10.1037/xge0000693" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="949" to="966" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Visual working memory capacity: From psychophysics and neurobiology to individual differences</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Luck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Vogel</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2013.06.006</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2013.06.006" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="391" to="400" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Changing concepts of working memory</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Husain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bays</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.3655</idno>
		<ptr target="https://doi.org/10.1038/nn.3655" />
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="347" to="356" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Retention and disruption of motion information in visual short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Magnussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Greenlee</surname></persName>
		</author>
		<idno type="DOI">10.1037//0278-7393.18.1.151</idno>
		<ptr target="https://doi.org/10.1037//0278-7393.18.1.151" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="151" to="156" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Orienting attention in visual working memory reduces interference from memory probes</title>
		<author>
			<persName><forename type="first">T</forename><surname>Makovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sussman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">V</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.34.2.369</idno>
		<ptr target="https://doi.org/10.1037/0278-7393.34.2.369" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="369" to="380" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The retention and disruption of color information in human short-term visual memory</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Nemes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Parry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whitaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Mckeefry</surname></persName>
		</author>
		<idno type="DOI">10.1167/12.1.26</idno>
		<ptr target="https://doi.org/10.1167/12.1.26" />
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The impact of interference on short-term memory for visual orientation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rademaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>De Weerd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Sack</surname></persName>
		</author>
		<idno type="DOI">10.1037/xhp0000110</idno>
		<ptr target="https://doi.org/10.1037/xhp0000110" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1650" to="1665" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Coexisting representations of sensory and mnemonic information in human visual cortex</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rademaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chunharas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Serences</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41593-019-0428-x</idno>
		<ptr target="https://doi.org/10.1038/s41593-019-0428-x" />
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1336" to="1344" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Evidence of gradual loss of precision for simple features and complex objects in visual working memory</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rademaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">E</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Sack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tong</surname></persName>
		</author>
		<idno type="DOI">10.1037/xhp0000491</idno>
		<ptr target="https://doi.org/10.1037/xhp0000491" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="925" to="940" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Comparing visual memories to novel visual input risks lasting memory distortion</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fukuda</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/xr4su</idno>
		<ptr target="https://doi.org/10.31234/osf.io/xr4su" />
	</analytic>
	<monogr>
		<title level="j">PsyArXiv</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Perceptual comparisons modulate memory biases induced by overlapping visual input</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kolisnyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fukuda</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/dqng3</idno>
		<ptr target="https://doi.org/10.31234/osf.io/dqng3" />
	</analytic>
	<monogr>
		<title level="j">PsyArXiv</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Erasing and blurring memories: The differential impact of interference on separate aspects of forgetting</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fidalgo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Barense</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Cant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ferber</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000359</idno>
		<ptr target="https://doi.org/10.1037/xge0000359" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1606" to="1630" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Visual working memory directly alters perception</title>
		<author>
			<persName><forename type="first">C</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Kravitz</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-019-0640-4</idno>
		<ptr target="https://doi.org/10.1038/s41562-019-0640-4" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="827" to="836" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">When shorter delays lead to worse memories: Task disruption makes visual working memory temporarily vulnerable to test interference</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Theeuwes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N L</forename><surname>Olivers</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0000468</idno>
		<ptr target="https://doi.org/10.1037/xlm0000468" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="722" to="733" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Discrete fixed-resolution representations in visual working memory</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Luck</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature06860</idno>
		<ptr target="https://doi.org/10.1038/nature06860" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">453</biblScope>
			<biblScope unit="issue">7192</biblScope>
			<biblScope unit="page" from="233" to="235" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
